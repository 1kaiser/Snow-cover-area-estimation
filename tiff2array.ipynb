{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/1kaiser/Snow-cover-area-estimation/blob/main/tiff2array.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yPdly86dtDqc",
        "outputId": "216623ee-eb65-4762-b051-5a841d20d14d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qKTN6C1btYsH"
      },
      "outputs": [],
      "source": [
        "!cp -r /content/drive/MyDrive/OUT/data/data20230320 /content/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GNadjcbGhnwN"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "image_dir = r'/content/data20230320/'\n",
        "\n",
        "#############################################################################>> files are of their original sizes are kept in a folder with their respective extensions as bands b1, b2, b3 , b4 , b5 ....  and kept as to be listed as image list in a variable.\n",
        "prefix = \"\"\n",
        "end = [\"B11\", \"B12\", \"B02\", \"B03\", \"B04\", \"B05\", \"B06\", \"B07\", \"B8A\", \"B8x\"]\n",
        "DayOY = \"_doy\\[0-9]+_aid0001\"\n",
        "fileExt = r'.tif'\n",
        "expression_b1 = prefix+end[0]\n",
        "expression_b2 = prefix+end[1]\n",
        "expression_b3 = prefix+end[2]\n",
        "expression_b4 = prefix+end[3]\n",
        "expression_b5 = prefix+end[4]\n",
        "expression_b6 = prefix+end[5]\n",
        "expression_b7 = prefix+end[6]\n",
        "expression_b8 = prefix+end[7]\n",
        "expression_b9 = prefix+end[8]\n",
        "expression_b10 = prefix+end[9]\n",
        "\n",
        "imgs_list_b1 = [f for f in os.listdir(image_dir) if f.__contains__(expression_b1)]\n",
        "\n",
        "imgs_list_b1.sort(reverse=True)    \n",
        "print(imgs_list_b1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UTqVV7ENkmAy"
      },
      "outputs": [],
      "source": [
        "path = os.path.join(image_dir, imgs_list_b1[0])\n",
        "path_list = [path.replace(expression_b1, expression_b1),\n",
        "             path.replace(expression_b1, expression_b2),\n",
        "             path.replace(expression_b1, expression_b3),\n",
        "             path.replace(expression_b1, expression_b4),\n",
        "             path.replace(expression_b1, expression_b5),\n",
        "             path.replace(expression_b1, expression_b6),\n",
        "             path.replace(expression_b1, expression_b7),\n",
        "             path.replace(expression_b1, expression_b8),\n",
        "             path.replace(expression_b1, expression_b9),\n",
        "             path.replace(expression_b1, expression_b10)]\n",
        "\n",
        "path_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "vJMBYkichBM8",
        "outputId": "bfc6702d-6e5d-4614-a39f-f4229c02c234"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'B11'"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "path_list[0][-7:-4]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KoOTRHJmrlKR"
      },
      "outputs": [],
      "source": [
        "#this function is for getting the four corners of all the square boxes possible out of the complete image size >>>\n",
        "def get_slice_bboxes( image_height: int, image_width: int, slice_height: int = 2000 , slice_width: int = 2000, overlap_height_ratio: float = 0.0, overlap_width_ratio: float = 0.0 ):\n",
        "  slice_bboxes = []\n",
        "  y_max = y_min = 0\n",
        "\n",
        "  if slice_height and slice_width:\n",
        "      y_overlap = int(overlap_height_ratio * slice_height)\n",
        "      x_overlap = int(overlap_width_ratio * slice_width)\n",
        "  else:\n",
        "      raise ValueError(\"Compute type is not auto and slice width and height are not provided.\")\n",
        "\n",
        "  while y_max < image_height:\n",
        "      x_min = x_max = 0\n",
        "      y_max = y_min + slice_height\n",
        "      while x_max < image_width:\n",
        "          x_max = x_min + slice_width\n",
        "          if y_max > image_height or x_max > image_width:\n",
        "              xmax = min(image_width, x_max)\n",
        "              ymax = min(image_height, y_max)\n",
        "              xmin = max(0, xmax - slice_width)\n",
        "              ymin = max(0, ymax - slice_height)\n",
        "              slice_bboxes.append([xmin, ymin, xmax, ymax])\n",
        "          else:\n",
        "              slice_bboxes.append([x_min, y_min, x_max, y_max])\n",
        "          x_min = x_max - x_overlap\n",
        "      y_min = y_max - y_overlap\n",
        "  return slice_bboxes\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zrFu1SXavti-"
      },
      "outputs": [],
      "source": [
        "#@title Default title text { vertical-output: true }\n",
        "# functions for clipping a single raster to multiple rasters of various shapes\n",
        "from osgeo import gdal\n",
        "\n",
        "save_directory = \"/content/drive/MyDrive/OUT/data/data20230320/inputs/\"\n",
        "!mkdir -p {save_directory} \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "band 0"
      ],
      "metadata": {
        "id": "03V3tNvD1QM-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "here_image = path_list[0]\n",
        "print(here_image)\n",
        "\n",
        "vvv = here_image[-7:-4]\n",
        "ds = gdal.Open(here_image)\n",
        "box_list = get_slice_bboxes(ds.RasterYSize , ds.RasterXSize)\n",
        "\n",
        "count = 0\n",
        "\n",
        "for box in box_list:\n",
        "  print(box, type(box_list))\n",
        "  count = count + 1\n",
        "  gdal.Translate(str(save_directory) + str(vvv) + \".\" + str(count) + '.tif', here_image ,srcWin = box )\n",
        "!runtime.unassign()"
      ],
      "metadata": {
        "id": "b7wm7n3i1KHA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "band 1"
      ],
      "metadata": {
        "id": "VLrHv25t1Uol"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "here_image = path_list[1]\n",
        "print(here_image)\n",
        "\n",
        "vvv = here_image[-7:-4]\n",
        "ds = gdal.Open(here_image)\n",
        "box_list = get_slice_bboxes(ds.RasterYSize , ds.RasterXSize)\n",
        "\n",
        "count = 0\n",
        "\n",
        "for box in box_list:\n",
        "  print(box, type(box_list))\n",
        "  count = count + 1\n",
        "  gdal.Translate(str(save_directory) + str(vvv) + \".\" + str(count) + '.tif', here_image ,srcWin = box )\n",
        "!runtime.unassign()"
      ],
      "metadata": {
        "id": "MgqW1G3H1Wvz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "band 2"
      ],
      "metadata": {
        "id": "tR_V9IZM1WKc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "here_image = path_list[2]\n",
        "print(here_image)\n",
        "\n",
        "vvv = here_image[-7:-4]\n",
        "ds = gdal.Open(here_image)\n",
        "box_list = get_slice_bboxes(ds.RasterYSize , ds.RasterXSize)\n",
        "\n",
        "count = 0\n",
        "\n",
        "for box in box_list:\n",
        "  print(box, type(box_list))\n",
        "  count = count + 1\n",
        "  gdal.Translate(str(save_directory) + str(vvv) + \".\" + str(count) + '.tif', here_image ,srcWin = box )\n",
        "!runtime.unassign()"
      ],
      "metadata": {
        "id": "E_I-Ixzk1a3Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "band 3"
      ],
      "metadata": {
        "id": "DPR_VjGe2L3-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "here_image = path_list[3]\n",
        "print(here_image)\n",
        "\n",
        "vvv = here_image[-7:-4]\n",
        "ds = gdal.Open(here_image)\n",
        "box_list = get_slice_bboxes(ds.RasterYSize , ds.RasterXSize)\n",
        "\n",
        "count = 0\n",
        "\n",
        "for box in box_list:\n",
        "  print(box, type(box_list))\n",
        "  count = count + 1\n",
        "  gdal.Translate(str(save_directory) + str(vvv) + \".\" + str(count) + '.tif', here_image ,srcWin = box )\n",
        "!runtime.unassign()"
      ],
      "metadata": {
        "id": "jqeno17U2LTL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "band 4"
      ],
      "metadata": {
        "id": "9oaEGMPM2SJ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "here_image = path_list[4]\n",
        "print(here_image)\n",
        "\n",
        "vvv = here_image[-7:-4]\n",
        "ds = gdal.Open(here_image)\n",
        "box_list = get_slice_bboxes(ds.RasterYSize , ds.RasterXSize)\n",
        "\n",
        "count = 0\n",
        "\n",
        "for box in box_list:\n",
        "  print(box, type(box_list))\n",
        "  count = count + 1\n",
        "  gdal.Translate(str(save_directory) + str(vvv) + \".\" + str(count) + '.tif', here_image ,srcWin = box )\n",
        "!runtime.unassign()"
      ],
      "metadata": {
        "id": "u9EO93G72Tk5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "band 5"
      ],
      "metadata": {
        "id": "NkrfYdV42VSZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "here_image = path_list[5]\n",
        "print(here_image)\n",
        "\n",
        "vvv = here_image[-7:-4]\n",
        "ds = gdal.Open(here_image)\n",
        "box_list = get_slice_bboxes(ds.RasterYSize , ds.RasterXSize)\n",
        "\n",
        "count = 0\n",
        "\n",
        "for box in box_list:\n",
        "  print(box, type(box_list))\n",
        "  count = count + 1\n",
        "  gdal.Translate(str(save_directory) + str(vvv) + \".\" + str(count) + '.tif', here_image ,srcWin = box )\n",
        "!runtime.unassign()"
      ],
      "metadata": {
        "id": "-pazktaj2Wp1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "band 6"
      ],
      "metadata": {
        "id": "_e40XDPN2gEX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "here_image = path_list[6]\n",
        "print(here_image)\n",
        "\n",
        "vvv = here_image[-7:-4]\n",
        "ds = gdal.Open(here_image)\n",
        "box_list = get_slice_bboxes(ds.RasterYSize , ds.RasterXSize)\n",
        "\n",
        "count = 0\n",
        "\n",
        "for box in box_list:\n",
        "  print(box, type(box_list))\n",
        "  count = count + 1\n",
        "  gdal.Translate(str(save_directory) + str(vvv) + \".\" + str(count) + '.tif', here_image ,srcWin = box )\n",
        "!runtime.unassign()"
      ],
      "metadata": {
        "id": "n2I0dHcK2frI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "band 7"
      ],
      "metadata": {
        "id": "0QkYs09O2kZV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "here_image = path_list[7]\n",
        "print(here_image)\n",
        "\n",
        "vvv = here_image[-7:-4]\n",
        "ds = gdal.Open(here_image)\n",
        "box_list = get_slice_bboxes(ds.RasterYSize , ds.RasterXSize)\n",
        "\n",
        "count = 0\n",
        "\n",
        "for box in box_list:\n",
        "  print(box, type(box_list))\n",
        "  count = count + 1\n",
        "  gdal.Translate(str(save_directory) + str(vvv) + \".\" + str(count) + '.tif', here_image ,srcWin = box )\n",
        "!runtime.unassign()"
      ],
      "metadata": {
        "id": "NZD5h3u02leQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "band 8"
      ],
      "metadata": {
        "id": "ff8eG_Ja2nJn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "here_image = path_list[8]\n",
        "print(here_image)\n",
        "\n",
        "vvv = here_image[-7:-4]\n",
        "ds = gdal.Open(here_image)\n",
        "box_list = get_slice_bboxes(ds.RasterYSize , ds.RasterXSize)\n",
        "\n",
        "count = 0\n",
        "\n",
        "for box in box_list:\n",
        "  print(box, type(box_list))\n",
        "  count = count + 1\n",
        "  gdal.Translate(str(save_directory) + str(vvv) + \".\" + str(count) + '.tif', here_image ,srcWin = box )\n",
        "!runtime.unassign()"
      ],
      "metadata": {
        "id": "iSONd7M62oTU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "band 9"
      ],
      "metadata": {
        "id": "YX3UVG702p6Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "here_image = path_list[9]\n",
        "print(here_image)\n",
        "\n",
        "vvv = here_image[-7:-4]\n",
        "ds = gdal.Open(here_image)\n",
        "box_list = get_slice_bboxes(ds.RasterYSize , ds.RasterXSize)\n",
        "\n",
        "count = 0\n",
        "\n",
        "for box in box_list:\n",
        "  print(box, type(box_list))\n",
        "  count = count + 1\n",
        "  gdal.Translate(str(save_directory) + str(vvv) + \".\" + str(count) + '.tif', here_image ,srcWin = box )\n",
        "!runtime.unassign()"
      ],
      "metadata": {
        "id": "wGOb_VRX2rRO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## test"
      ],
      "metadata": {
        "id": "IGvjOhfq25Hx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3lUV96TiqTux"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import os.path\n",
        "import re\n",
        "\n",
        "from osgeo import gdal\n",
        "from osgeo import gdal_array\n",
        "from osgeo import osr\n",
        "\n",
        "def get_gain_band(input_file):\n",
        "    \"\"\"get GAIN_BAND from meta file (*.tif.txt)\"\"\"\n",
        "     # define file name of *.tif.txt\n",
        "    ifile_txt = re.sub(r'.tif', '.tif.txt', input_file)\n",
        "    ld = open(ifile_txt)\n",
        "    lines = ld.readlines()\n",
        "    ld.close()\n",
        "    \n",
        "    gain_band = []\n",
        "    for line in lines:\n",
        "        if line.find(\"GAIN_BAND\") >= 0:\n",
        "             gain_band.append(float((re.split(' ', line)[1]).strip()))\n",
        "    return gain_band\n",
        "\n",
        "def tif2array(input_file, calc_gain=True):\n",
        "    \"\"\"\n",
        "    read GeoTiff and convert to numpy.ndarray.\n",
        "    Inputs:\n",
        "        input_file (str) : the name of input GeoTiff file.\n",
        "        calc_gain (bool) : wheter calc GAIN to DN  or not (defaul:True).\n",
        "    return:\n",
        "        image(np.array) : image for each bands\n",
        "        dataset : for gdal's data drive.\n",
        "    \"\"\"\n",
        "    dataset = gdal.Open(input_file, gdal.GA_ReadOnly)\n",
        "    # Allocate our array using the first band's datatype\n",
        "    image_datatype = dataset.GetRasterBand(1).DataType\n",
        "    image = np.zeros((dataset.RasterYSize, dataset.RasterXSize, dataset.RasterCount),\n",
        "                     dtype=float)\n",
        "    \n",
        "    if calc_gain == True:\n",
        "        # get gain\n",
        "        gain = get_gain_band(input_file)\n",
        "    \n",
        "    # Loop over all bands in dataset\n",
        "    for b in range(dataset.RasterCount):\n",
        "        # Remember, GDAL index is on 1, but Python is on 0 -- so we add 1 for our GDAL calls\n",
        "        band = dataset.GetRasterBand(b + 1)\n",
        "        # Read in the band's data into the third dimension of our array\n",
        "        if calc_gain == True:\n",
        "            # calc gain value for each bands\n",
        "            image[:, :, b] = band.ReadAsArray() * gain[b]\n",
        "        else:\n",
        "            image[:, :, b] = band.ReadAsArray()\n",
        "    return image, dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CbZUMzKd_PO-"
      },
      "source": [
        "setting up for tif2array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4p1zGV-z-jWr"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "image_dir = r'/content/drive/MyDrive/OUT/data/data20230320/inputs/'\n",
        "\n",
        "#############################################################################>> files are of their original sizes are kept in a folder with their respective extensions as bands b1, b2, b3 , b4 , b5 ....  and kept as to be listed as image list in a variable.\n",
        "prefix = \"\"\n",
        "end = [\"B11\", \"B12\", \"B02\", \"B03\", \"B04\", \"B05\", \"B06\", \"B07\", \"B8A\", \"B8x\"]\n",
        "DayOY = \"_doy\\[0-9]+_aid0001\"\n",
        "fileExt = r'.tif'\n",
        "expression_b1 = prefix+end[0]\n",
        "expression_b2 = prefix+end[1]\n",
        "expression_b3 = prefix+end[2]\n",
        "expression_b4 = prefix+end[3]\n",
        "expression_b5 = prefix+end[4]\n",
        "expression_b6 = prefix+end[5]\n",
        "expression_b7 = prefix+end[6]\n",
        "expression_b8 = prefix+end[7]\n",
        "expression_b9 = prefix+end[8]\n",
        "expression_b10 = prefix+end[9]\n",
        "\n",
        "imgs_list_b1 = [f for f in os.listdir(image_dir) if f.__contains__(expression_b1)]\n",
        "\n",
        "imgs_list_b1.sort(reverse=True)    \n",
        "print(imgs_list_b1)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#extraction of band values from clips to DATAFRAME for to be processing inside the model\n",
        "\n",
        "from osgeo import gdal\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "######################$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$<<< tensorflow model\n",
        "#Copy and execute the following code in a new Google Colab notebook launch to run the model.\n",
        "!python -m pip install tensorflow tensorflow_decision_forests -U -qq\n",
        "\n",
        "# Transfer the model from Google Drive to Colab\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\")\n",
        "!cp \"/content/gdrive/My Drive/simple_ml_for_sheets/Ice height from bands\" ydf_model\n",
        "  \n",
        "# Prepare and load the model with TensorFlow\n",
        "import tensorflow as tf\n",
        "import tensorflow_decision_forests as tfdf\n",
        "\n",
        "tfdf.keras.yggdrasil_model_to_keras_model(\"ydf_model\", \"tfdf_model\")\n",
        "model = tf.keras.models.load_model(\"tfdf_model\")\n",
        "######################$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$<<< tensorflow model\n"
      ],
      "metadata": {
        "id": "qmznxvEmjXoF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YwKtSRMqxW1P"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "for image_no in range(0, len(imgs_list_b1)):\n",
        "  path = os.path.join(image_dir, imgs_list_b1[image_no])\n",
        "  path_list = [path.replace(expression_b1, expression_b1),\n",
        "              path.replace(expression_b1, expression_b2),\n",
        "              path.replace(expression_b1, expression_b3),\n",
        "              path.replace(expression_b1, expression_b4),\n",
        "              path.replace(expression_b1, expression_b5),\n",
        "              path.replace(expression_b1, expression_b6),\n",
        "              path.replace(expression_b1, expression_b7),\n",
        "              path.replace(expression_b1, expression_b8),\n",
        "              path.replace(expression_b1, expression_b9),\n",
        "              path.replace(expression_b1, expression_b10)]\n",
        "\n",
        "  lon , lat = [] , []  \n",
        "  v1 =[]\n",
        "\n",
        "  for i in path_list:\n",
        "    pathout = temp_dir+str(i)\n",
        "    print(pathout)\n",
        "    \n",
        "    if(path_list.index(i)==0):\n",
        "      v1 = tif2array(pathout, 0)[0].reshape(-1,1)\n",
        "      # Open tif file\n",
        "      ds = gdal.Open(pathout)\n",
        "      # GDAL affine transform parameters, According to gdal documentation xoff/yoff are image left corner, a/e are pixel wight/height and b/d is rotation and is zero if image is north up. \n",
        "      xoff, a, b, yoff, d, e = ds.GetGeoTransform()\n",
        "      print(xoff, a, b, yoff, d, e)\n",
        "      def pixel2coord(x, y):\n",
        "        # \"\"Returns global coordinates from pixel x, y coords\"\"\n",
        "        xp = a * x + b * y + xoff\n",
        "        yp = d * x + e * y + yoff\n",
        "        return xp, yp\n",
        "\n",
        "      # get columns and rows of your image from gdalinfo\n",
        "      rows = ds.RasterYSize \n",
        "      colms = ds.RasterXSize \n",
        "      for row in  range(0,rows):\n",
        "        for col in  range(0,colms): \n",
        "          lat.append(pixel2coord(col,row)[0])\n",
        "          lon.append(pixel2coord(col,row)[1])\n",
        "    else:\n",
        "      v1 = np.append(v1, tif2array(pathout, 0)[0].reshape(-1,1), axis = 1)\n",
        "  # agging latitude \"lat\" & longitde \"lon\" column at the end\n",
        "  v1 = np.column_stack((v1, np.column_stack((lat, lon))))\n",
        "\n",
        "\n",
        "  arr = v1\n",
        "  # convert array into dataframe\n",
        "  DF = pd.DataFrame(arr)\n",
        "  # DF.columns = d\n",
        "    # print(DF)\n",
        "  height =[]\n",
        "  for values in range(0, len(DF[0])):\n",
        "    examples = {\n",
        "    \"b11\" : [np.array(DF[0][values])],\n",
        "    \"b12\" : [np.array(DF[1][values])],\n",
        "    \"b2\" : [np.array(DF[2][values])],\n",
        "    \"b3\" : [np.array(DF[3][values])],\n",
        "    \"b4\" : [np.array(DF[4][values])],\n",
        "    \"b5\" : [np.array(DF[5][values])],\n",
        "    \"b6\" : [np.array(DF[6][values])],\n",
        "    \"b7\" : [np.array(DF[7][values])],\n",
        "    \"b8a\" : [np.array(DF[8][values])],\n",
        "    \"b8\" : [np.array(DF[9][values])],\n",
        "    \"lat\" : [np.array(DF[10][values])],\n",
        "    \"lon\" : [np.array(DF[11][values])],\n",
        "    }\n",
        "######################$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$<<< tensorflow model\n",
        "\n",
        "    a = np.array(model.predict_step(examples))\n",
        "######################$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$<<< tensorflow model\n",
        "\n",
        "    height.append(a[0][0])\n",
        "  print(np.asarray(height))\n",
        "  print(height)\n",
        "  height = np.column_stack((np.column_stack((lat, lon)), height))\n",
        "  # saving the predicted heght data to panda dataframe\n",
        "  DHeight = pd.DataFrame(height)\n",
        "  # DF.columns = d\n",
        "  DHeight\n",
        "  # save the dataframe as a csv file\n",
        "  DHeight.to_csv(\"height_\" + str(image_no) + \".csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "8DBy_PklvPPa",
        "outputId": "18a1e722-ee44-436d-cc51-3be36397406e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-0741b74c-d057-44ee-9193-aae1ebb3bd30\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-3.402823e+38</td>\n",
              "      <td>-3.402823e+38</td>\n",
              "      <td>-3.402823e+38</td>\n",
              "      <td>-3.402823e+38</td>\n",
              "      <td>-3.402823e+38</td>\n",
              "      <td>-3.402823e+38</td>\n",
              "      <td>-3.402823e+38</td>\n",
              "      <td>-3.402823e+38</td>\n",
              "      <td>-3.402823e+38</td>\n",
              "      <td>-3.402823e+38</td>\n",
              "      <td>76.972044</td>\n",
              "      <td>32.402299</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-3.402823e+38</td>\n",
              "      <td>-3.402823e+38</td>\n",
              "      <td>-3.402823e+38</td>\n",
              "      <td>-3.402823e+38</td>\n",
              "      <td>-3.402823e+38</td>\n",
              "      <td>-3.402823e+38</td>\n",
              "      <td>-3.402823e+38</td>\n",
              "      <td>-3.402823e+38</td>\n",
              "      <td>-3.402823e+38</td>\n",
              "      <td>-3.402823e+38</td>\n",
              "      <td>76.972133</td>\n",
              "      <td>32.402299</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-3.402823e+38</td>\n",
              "      <td>-3.402823e+38</td>\n",
              "      <td>-3.402823e+38</td>\n",
              "      <td>-3.402823e+38</td>\n",
              "      <td>-3.402823e+38</td>\n",
              "      <td>-3.402823e+38</td>\n",
              "      <td>-3.402823e+38</td>\n",
              "      <td>-3.402823e+38</td>\n",
              "      <td>-3.402823e+38</td>\n",
              "      <td>-3.402823e+38</td>\n",
              "      <td>76.972223</td>\n",
              "      <td>32.402299</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-3.402823e+38</td>\n",
              "      <td>-3.402823e+38</td>\n",
              "      <td>-3.402823e+38</td>\n",
              "      <td>-3.402823e+38</td>\n",
              "      <td>-3.402823e+38</td>\n",
              "      <td>-3.402823e+38</td>\n",
              "      <td>-3.402823e+38</td>\n",
              "      <td>-3.402823e+38</td>\n",
              "      <td>-3.402823e+38</td>\n",
              "      <td>-3.402823e+38</td>\n",
              "      <td>76.972313</td>\n",
              "      <td>32.402299</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-3.402823e+38</td>\n",
              "      <td>-3.402823e+38</td>\n",
              "      <td>-3.402823e+38</td>\n",
              "      <td>-3.402823e+38</td>\n",
              "      <td>-3.402823e+38</td>\n",
              "      <td>-3.402823e+38</td>\n",
              "      <td>-3.402823e+38</td>\n",
              "      <td>-3.402823e+38</td>\n",
              "      <td>-3.402823e+38</td>\n",
              "      <td>-3.402823e+38</td>\n",
              "      <td>76.972403</td>\n",
              "      <td>32.402299</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19180483</th>\n",
              "      <td>-3.402823e+38</td>\n",
              "      <td>-3.402823e+38</td>\n",
              "      <td>-3.402823e+38</td>\n",
              "      <td>-3.402823e+38</td>\n",
              "      <td>-3.402823e+38</td>\n",
              "      <td>-3.402823e+38</td>\n",
              "      <td>-3.402823e+38</td>\n",
              "      <td>-3.402823e+38</td>\n",
              "      <td>-3.402823e+38</td>\n",
              "      <td>-3.402823e+38</td>\n",
              "      <td>77.449678</td>\n",
              "      <td>32.078636</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19180484</th>\n",
              "      <td>-3.402823e+38</td>\n",
              "      <td>-3.402823e+38</td>\n",
              "      <td>-3.402823e+38</td>\n",
              "      <td>-3.402823e+38</td>\n",
              "      <td>-3.402823e+38</td>\n",
              "      <td>-3.402823e+38</td>\n",
              "      <td>-3.402823e+38</td>\n",
              "      <td>-3.402823e+38</td>\n",
              "      <td>-3.402823e+38</td>\n",
              "      <td>-3.402823e+38</td>\n",
              "      <td>77.449768</td>\n",
              "      <td>32.078636</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19180485</th>\n",
              "      <td>-3.402823e+38</td>\n",
              "      <td>-3.402823e+38</td>\n",
              "      <td>-3.402823e+38</td>\n",
              "      <td>-3.402823e+38</td>\n",
              "      <td>-3.402823e+38</td>\n",
              "      <td>-3.402823e+38</td>\n",
              "      <td>-3.402823e+38</td>\n",
              "      <td>-3.402823e+38</td>\n",
              "      <td>-3.402823e+38</td>\n",
              "      <td>-3.402823e+38</td>\n",
              "      <td>77.449858</td>\n",
              "      <td>32.078636</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19180486</th>\n",
              "      <td>-3.402823e+38</td>\n",
              "      <td>-3.402823e+38</td>\n",
              "      <td>-3.402823e+38</td>\n",
              "      <td>-3.402823e+38</td>\n",
              "      <td>-3.402823e+38</td>\n",
              "      <td>-3.402823e+38</td>\n",
              "      <td>-3.402823e+38</td>\n",
              "      <td>-3.402823e+38</td>\n",
              "      <td>-3.402823e+38</td>\n",
              "      <td>-3.402823e+38</td>\n",
              "      <td>77.449947</td>\n",
              "      <td>32.078636</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19180487</th>\n",
              "      <td>-3.402823e+38</td>\n",
              "      <td>-3.402823e+38</td>\n",
              "      <td>-3.402823e+38</td>\n",
              "      <td>-3.402823e+38</td>\n",
              "      <td>-3.402823e+38</td>\n",
              "      <td>-3.402823e+38</td>\n",
              "      <td>-3.402823e+38</td>\n",
              "      <td>-3.402823e+38</td>\n",
              "      <td>-3.402823e+38</td>\n",
              "      <td>-3.402823e+38</td>\n",
              "      <td>77.450037</td>\n",
              "      <td>32.078636</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>19180488 rows × 12 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0741b74c-d057-44ee-9193-aae1ebb3bd30')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0741b74c-d057-44ee-9193-aae1ebb3bd30 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0741b74c-d057-44ee-9193-aae1ebb3bd30');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                    0             1             2             3   \\\n",
              "0        -3.402823e+38 -3.402823e+38 -3.402823e+38 -3.402823e+38   \n",
              "1        -3.402823e+38 -3.402823e+38 -3.402823e+38 -3.402823e+38   \n",
              "2        -3.402823e+38 -3.402823e+38 -3.402823e+38 -3.402823e+38   \n",
              "3        -3.402823e+38 -3.402823e+38 -3.402823e+38 -3.402823e+38   \n",
              "4        -3.402823e+38 -3.402823e+38 -3.402823e+38 -3.402823e+38   \n",
              "...                ...           ...           ...           ...   \n",
              "19180483 -3.402823e+38 -3.402823e+38 -3.402823e+38 -3.402823e+38   \n",
              "19180484 -3.402823e+38 -3.402823e+38 -3.402823e+38 -3.402823e+38   \n",
              "19180485 -3.402823e+38 -3.402823e+38 -3.402823e+38 -3.402823e+38   \n",
              "19180486 -3.402823e+38 -3.402823e+38 -3.402823e+38 -3.402823e+38   \n",
              "19180487 -3.402823e+38 -3.402823e+38 -3.402823e+38 -3.402823e+38   \n",
              "\n",
              "                    4             5             6             7   \\\n",
              "0        -3.402823e+38 -3.402823e+38 -3.402823e+38 -3.402823e+38   \n",
              "1        -3.402823e+38 -3.402823e+38 -3.402823e+38 -3.402823e+38   \n",
              "2        -3.402823e+38 -3.402823e+38 -3.402823e+38 -3.402823e+38   \n",
              "3        -3.402823e+38 -3.402823e+38 -3.402823e+38 -3.402823e+38   \n",
              "4        -3.402823e+38 -3.402823e+38 -3.402823e+38 -3.402823e+38   \n",
              "...                ...           ...           ...           ...   \n",
              "19180483 -3.402823e+38 -3.402823e+38 -3.402823e+38 -3.402823e+38   \n",
              "19180484 -3.402823e+38 -3.402823e+38 -3.402823e+38 -3.402823e+38   \n",
              "19180485 -3.402823e+38 -3.402823e+38 -3.402823e+38 -3.402823e+38   \n",
              "19180486 -3.402823e+38 -3.402823e+38 -3.402823e+38 -3.402823e+38   \n",
              "19180487 -3.402823e+38 -3.402823e+38 -3.402823e+38 -3.402823e+38   \n",
              "\n",
              "                    8             9          10         11  \n",
              "0        -3.402823e+38 -3.402823e+38  76.972044  32.402299  \n",
              "1        -3.402823e+38 -3.402823e+38  76.972133  32.402299  \n",
              "2        -3.402823e+38 -3.402823e+38  76.972223  32.402299  \n",
              "3        -3.402823e+38 -3.402823e+38  76.972313  32.402299  \n",
              "4        -3.402823e+38 -3.402823e+38  76.972403  32.402299  \n",
              "...                ...           ...        ...        ...  \n",
              "19180483 -3.402823e+38 -3.402823e+38  77.449678  32.078636  \n",
              "19180484 -3.402823e+38 -3.402823e+38  77.449768  32.078636  \n",
              "19180485 -3.402823e+38 -3.402823e+38  77.449858  32.078636  \n",
              "19180486 -3.402823e+38 -3.402823e+38  77.449947  32.078636  \n",
              "19180487 -3.402823e+38 -3.402823e+38  77.450037  32.078636  \n",
              "\n",
              "[19180488 rows x 12 columns]"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "arr = v1\n",
        " \n",
        "# display the array\n",
        "# print(arr)\n",
        " \n",
        "# convert array into dataframe\n",
        "\n",
        "d = {'b11','b12','b2', 'b3', 'b4', 'b5', 'b6', 'b7', 'b8a', 'b8', 'lat', 'lon'}\n",
        "\n",
        "DF = pd.DataFrame(arr)\n",
        "# DF.columns = d\n",
        "DF\n",
        "# print(DF)\n",
        "# # save the dataframe as a csv file\n",
        "# DF.to_csv(\"data1.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G2e_gebtY0lF",
        "outputId": "bd72d329-fa7d-4f7e-c2b7-6895fa07c1d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.9/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
            "Instructions for updating:\n",
            "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
            "WARNING:tensorflow:AutoGraph could not transform <function simple_ml_inference_op_with_handle at 0x7fe2f59cee50> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: could not get source code\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING: AutoGraph could not transform <function simple_ml_inference_op_with_handle at 0x7fe2f59cee50> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: could not get source code\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as call_get_leaves, _update_step_xla while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
          ]
        }
      ],
      "source": [
        "#Copy and execute the following code in a new Google Colab notebook launch to run the model.\n",
        "\n",
        "!python -m pip install tensorflow tensorflow_decision_forests -U -qq\n",
        "\n",
        "# Transfer the model from Google Drive to Colab\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\")\n",
        "!cp \"/content/gdrive/My Drive/simple_ml_for_sheets/Ice height from bands\" ydf_model\n",
        "  \n",
        "# Prepare and load the model with TensorFlow\n",
        "import tensorflow as tf\n",
        "import tensorflow_decision_forests as tfdf\n",
        "\n",
        "\n",
        "tfdf.keras.yggdrasil_model_to_keras_model(\"ydf_model\", \"tfdf_model\")\n",
        "model = tf.keras.models.load_model(\"tfdf_model\")\n",
        "\n",
        "# # Make predictions with the model\n",
        "# examples = {\n",
        "#   \"b11\" : DF[0],\n",
        "#   \"b12\" : DF[1],\n",
        "#   \"b2\" : DF[2],\n",
        "#   \"b3\" : DF[3],\n",
        "#   \"b4\" : DF[4],\n",
        "#   \"b5\" : DF[5],\n",
        "#   \"b6\" : DF[6],\n",
        "#   \"b7\" : DF[7],\n",
        "#   \"b8a\" : DF[8],\n",
        "#   \"b8\" : DF[9],\n",
        "#   \"lat\" : DF[10],\n",
        "#   \"lon\" : DF[11],\n",
        "# }\n",
        "# a = model.predict_step(examples)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "70t4-qtPv6Sg",
        "outputId": "196c3294-efca-43d4-dd07-aa51b137ee03"
      },
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-60401a13bbd9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m   \u001b[0;34m\"lon\"\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDF\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m11\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m   }\n\u001b[0;32m---> 17\u001b[0;31m   \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexamples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m   \u001b[0mheight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict_step\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   2077\u001b[0m         \"\"\"\n\u001b[1;32m   2078\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_adapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_x_y_sample_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2079\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2080\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2081\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmake_predict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    559\u001b[0m             \u001b[0mlayout_map_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_subclass_model_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_layout_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mdoc_controls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdoc_in_current_and_subclasses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_autocast\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1127\u001b[0;31m                     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1129\u001b[0m                 with autocast_variable.enable_auto_cast_variables(\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_maybe_cast_inputs\u001b[0;34m(self, inputs, input_list)\u001b[0m\n\u001b[1;32m   2713\u001b[0m         ):\n\u001b[1;32m   2714\u001b[0m             \u001b[0;31m# Only perform expensive `nest` operation when needed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cast_single_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    915\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    915\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_cast_single_input\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m   2729\u001b[0m         \u001b[0;34m\"\"\"Cast a single Tensor or TensorSpec to the compute dtype.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2730\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_cast_single_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2731\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_dtype_object\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2732\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2733\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mop_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1174\u001b[0m       \u001b[0;31m# Fallback dispatch system (dispatch v1):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1175\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1176\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdispatch_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1177\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1178\u001b[0m         \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mcast\u001b[0;34m(x, dtype, name)\u001b[0m\n\u001b[1;32m   1001\u001b[0m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"x\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1002\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mbase_type\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1003\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbase_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1004\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbase_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1005\u001b[0m       \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Casting complex to real discards imaginary part.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36mcast\u001b[0;34m(x, DstT, Truncate, name)\u001b[0m\n\u001b[1;32m   1995\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1996\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1997\u001b[0;31m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[1;32m   1998\u001b[0m         _ctx, \"Cast\", name, x, \"DstT\", DstT, \"Truncate\", Truncate)\n\u001b[1;32m   1999\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "height =[]\n",
        "for i in range(0, len(DF[0])):\n",
        "  examples = {\n",
        "  \"b11\" : [np.array(DF[0][i])],\n",
        "  \"b12\" : [np.array(DF[1][i])],\n",
        "  \"b2\" : [np.array(DF[2][i])],\n",
        "  \"b3\" : [np.array(DF[3][i])],\n",
        "  \"b4\" : [np.array(DF[4][i])],\n",
        "  \"b5\" : [np.array(DF[5][i])],\n",
        "  \"b6\" : [np.array(DF[6][i])],\n",
        "  \"b7\" : [np.array(DF[7][i])],\n",
        "  \"b8a\" : [np.array(DF[8][i])],\n",
        "  \"b8\" : [np.array(DF[9][i])],\n",
        "  \"lat\" : [np.array(DF[10][i])],\n",
        "  \"lon\" : [np.array(DF[11][i])],\n",
        "  }\n",
        "  a = np.array(model.predict_step(examples))\n",
        "  height.append(a[0][0])\n",
        "print(np.asarray(height))\n",
        "print(height)\n",
        "height = np.column_stack((np.column_stack((lat, lon)), height))\n",
        "# saving the predicted heght data to panda dataframe\n",
        "DHeight = pd.DataFrame(height)\n",
        "# DF.columns = d\n",
        "DHeight\n",
        "# print(DF)\n",
        "# # save the dataframe as a csv file\n",
        "# DF.to_csv(\"data1.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "j7K3YzNpIdSV",
        "outputId": "741c8389-2447-4c5f-d80c-b86f12415b7c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2800.0225 2800.0225 2800.0225 2800.0225 2800.0225 2800.0225 2800.0225\n",
            " 2800.0225 2800.0225 2800.0225]\n",
            "[2800.0225, 2800.0225, 2800.0225, 2800.0225, 2800.0225, 2800.0225, 2800.0225, 2800.0225, 2800.0225, 2800.0225]\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-807a9ecc94ab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mheight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumn_stack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumn_stack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;31m# saving the predicted heght data to panda dataframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mDHeight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/numpy/core/overrides.py\u001b[0m in \u001b[0;36mcolumn_stack\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/numpy/lib/shape_base.py\u001b[0m in \u001b[0;36mcolumn_stack\u001b[0;34m(tup)\u001b[0m\n\u001b[1;32m    654\u001b[0m             \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    655\u001b[0m         \u001b[0marrays\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 656\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_nx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    657\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/numpy/core/overrides.py\u001b[0m in \u001b[0;36mconcatenate\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: all the input array dimensions for the concatenation axis must match exactly, but along dimension 0, the array at index 0 has size 19180488 and the array at index 1 has size 10"
          ]
        }
      ],
      "source": [
        "height =[]\n",
        "for i in range(0, len(DF[0])):\n",
        "  examples = {\n",
        "  \"b11\" : [np.array(DF[0][i])],\n",
        "  \"b12\" : [np.array(DF[1][i])],\n",
        "  \"b2\" : [np.array(DF[2][i])],\n",
        "  \"b3\" : [np.array(DF[3][i])],\n",
        "  \"b4\" : [np.array(DF[4][i])],\n",
        "  \"b5\" : [np.array(DF[5][i])],\n",
        "  \"b6\" : [np.array(DF[6][i])],\n",
        "  \"b7\" : [np.array(DF[7][i])],\n",
        "  \"b8a\" : [np.array(DF[8][i])],\n",
        "  \"b8\" : [np.array(DF[9][i])],\n",
        "  \"lat\" : [np.array(DF[10][i])],\n",
        "  \"lon\" : [np.array(DF[11][i])],\n",
        "  }\n",
        "  a = np.array(model.predict_step(examples))\n",
        "  height.append(a[0][0])\n",
        "print(np.asarray(height))\n",
        "print(height)\n",
        "\n",
        "height = np.column_stack((np.column_stack((lat, lon)), height))\n",
        "DHeight = pd.DataFrame(height)\n",
        "# DF.columns = d\n",
        "DHeight\n",
        "# print(DHeight)\n",
        "# # save the dataframe as a csv file\n",
        "# DHeight.to_csv(\"data1.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lZBrg2Otm4MF",
        "outputId": "08b9af2e-4b38-4aee-ff20-6e18dc901912"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "-3.4028230607370965e+38"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.array(DF[0])[1]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "iPFlYQ0sqhdD",
        "outputId": "d326821e-89b5-4bdc-f9fa-869307d964cb"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-6199d1c0204a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mexamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtfdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpd_dataframe_to_tf_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDF\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexamples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict_step\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   2077\u001b[0m         \"\"\"\n\u001b[1;32m   2078\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_adapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_x_y_sample_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2079\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2080\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2081\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmake_predict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/saved_model/function_deserialization.py\u001b[0m in \u001b[0;36mrestored_function_body\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    293\u001b[0m           \"Option {}:\\n  {}\\n  Keyword arguments: {}\".format(\n\u001b[1;32m    294\u001b[0m               index + 1, _pretty_format_positional(positional), keyword))\n\u001b[0;32m--> 295\u001b[0;31m     raise ValueError(\n\u001b[0m\u001b[1;32m    296\u001b[0m         \u001b[0;34m\"Could not find matching concrete function to call loaded from the \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m         \u001b[0;34mf\"SavedModel. Got:\\n  {_pretty_format_positional(args)}\\n  Keyword \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling layer 'inference_core_model' (type InferenceCoreModel).\n\nCould not find matching concrete function to call loaded from the SavedModel. Got:\n  Positional arguments (2 total):\n    * <_VariantDataset element_spec={'b12': TensorSpec(shape=(None,), dtype=tf.float64, name=None), 'b11': TensorSpec(shape=(None,), dtype=tf.float64, name=None), 'lat': TensorSpec(shape=(None,), dtype=tf.float64, name=None), 'b7': TensorSpec(shape=(None,), dtype=tf.float64, name=None), 'b6': TensorSpec(shape=(None,), dtype=tf.float64, name=None), 'b5': TensorSpec(shape=(None,), dtype=tf.float64, name=None), 'lon': TensorSpec(shape=(None,), dtype=tf.float64, name=None), 'b8a': TensorSpec(shape=(None,), dtype=tf.float64, name=None), 'b4': TensorSpec(shape=(None,), dtype=tf.float64, name=None), 'b2': TensorSpec(shape=(None,), dtype=tf.float64, name=None), 'b8': TensorSpec(shape=(None,), dtype=tf.float64, name=None), 'b3': TensorSpec(shape=(None,), dtype=tf.float64, name=None)}>\n    * False\n  Keyword arguments: {}\n\n Expected these arguments to match one of the following 4 option(s):\n\nOption 1:\n  Positional arguments (2 total):\n    * {'b11': TensorSpec(shape=(None,), dtype=tf.float32, name='inputs_b11'),\n 'b12': TensorSpec(shape=(None,), dtype=tf.float32, name='inputs_b12'),\n 'b2': TensorSpec(shape=(None,), dtype=tf.float32, name='inputs_b2'),\n 'b3': TensorSpec(shape=(None,), dtype=tf.float32, name='inputs_b3'),\n 'b4': TensorSpec(shape=(None,), dtype=tf.float32, name='inputs_b4'),\n 'b5': TensorSpec(shape=(None,), dtype=tf.float32, name='inputs_b5'),\n 'b6': TensorSpec(shape=(None,), dtype=tf.float32, name='inputs_b6'),\n 'b7': TensorSpec(shape=(None,), dtype=tf.float32, name='inputs_b7'),\n 'b8': TensorSpec(shape=(None,), dtype=tf.float32, name='inputs_b8'),\n 'b8a': TensorSpec(shape=(None,), dtype=tf.float32, name='inputs_b8a'),\n 'lat': TensorSpec(shape=(None,), dtype=tf.float32, name='inputs_lat'),\n 'lon': TensorSpec(shape=(None,), dtype=tf.float32, name='inputs_lon')}\n    * False\n  Keyword arguments: {}\n\nOption 2:\n  Positional arguments (2 total):\n    * {'b11': TensorSpec(shape=(None,), dtype=tf.float32, name='inputs_b11'),\n 'b12': TensorSpec(shape=(None,), dtype=tf.float32, name='inputs_b12'),\n 'b2': TensorSpec(shape=(None,), dtype=tf.float32, name='inputs_b2'),\n 'b3': TensorSpec(shape=(None,), dtype=tf.float32, name='inputs_b3'),\n 'b4': TensorSpec(shape=(None,), dtype=tf.float32, name='inputs_b4'),\n 'b5': TensorSpec(shape=(None,), dtype=tf.float32, name='inputs_b5'),\n 'b6': TensorSpec(shape=(None,), dtype=tf.float32, name='inputs_b6'),\n 'b7': TensorSpec(shape=(None,), dtype=tf.float32, name='inputs_b7'),\n 'b8': TensorSpec(shape=(None,), dtype=tf.float32, name='inputs_b8'),\n 'b8a': TensorSpec(shape=(None,), dtype=tf.float32, name='inputs_b8a'),\n 'lat': TensorSpec(shape=(None,), dtype=tf.float32, name='inputs_lat'),\n 'lon': TensorSpec(shape=(None,), dtype=tf.float32, name='inputs_lon')}\n    * True\n  Keyword arguments: {}\n\nOption 3:\n  Positional arguments (2 total):\n    * {'b11': TensorSpec(shape=(None,), dtype=tf.float32, name='b11'),\n 'b12': TensorSpec(shape=(None,), dtype=tf.float32, name='b12'),\n 'b2': TensorSpec(shape=(None,), dtype=tf.float32, name='b2'),\n 'b3': TensorSpec(shape=(None,), dtype=tf.float32, name='b3'),\n 'b4': TensorSpec(shape=(None,), dtype=tf.float32, name='b4'),\n 'b5': TensorSpec(shape=(None,), dtype=tf.float32, name='b5'),\n 'b6': TensorSpec(shape=(None,), dtype=tf.float32, name='b6'),\n 'b7': TensorSpec(shape=(None,), dtype=tf.float32, name='b7'),\n 'b8': TensorSpec(shape=(None,), dtype=tf.float32, name='b8'),\n 'b8a': TensorSpec(shape=(None,), dtype=tf.float32, name='b8a'),\n 'lat': TensorSpec(shape=(None,), dtype=tf.float32, name='lat'),\n 'lon': TensorSpec(shape=(None,), dtype=tf.float32, name='lon')}\n    * False\n  Keyword arguments: {}\n\nOption 4:\n  Positional arguments (2 total):\n    * {'b11': TensorSpec(shape=(None,), dtype=tf.float32, name='b11'),\n 'b12': TensorSpec(shape=(None,), dtype=tf.float32, name='b12'),\n 'b2': TensorSpec(shape=(None,), dtype=tf.float32, name='b2'),\n 'b3': TensorSpec(shape=(None,), dtype=tf.float32, name='b3'),\n 'b4': TensorSpec(shape=(None,), dtype=tf.float32, name='b4'),\n 'b5': TensorSpec(shape=(None,), dtype=tf.float32, name='b5'),\n 'b6': TensorSpec(shape=(None,), dtype=tf.float32, name='b6'),\n 'b7': TensorSpec(shape=(None,), dtype=tf.float32, name='b7'),\n 'b8': TensorSpec(shape=(None,), dtype=tf.float32, name='b8'),\n 'b8a': TensorSpec(shape=(None,), dtype=tf.float32, name='b8a'),\n 'lat': TensorSpec(shape=(None,), dtype=tf.float32, name='lat'),\n 'lon': TensorSpec(shape=(None,), dtype=tf.float32, name='lon')}\n    * True\n  Keyword arguments: {}\n\nCall arguments received by layer 'inference_core_model' (type InferenceCoreModel):\n  • args=(\"<PrefetchDataset element_spec={'b12': TensorSpec(shape=(None,), dtype=tf.float64, name=None), 'b11': TensorSpec(shape=(None,), dtype=tf.float64, name=None), 'lat': TensorSpec(shape=(None,), dtype=tf.float64, name=None), 'b7': TensorSpec(shape=(None,), dtype=tf.float64, name=None), 'b6': TensorSpec(shape=(None,), dtype=tf.float64, name=None), 'b5': TensorSpec(shape=(None,), dtype=tf.float64, name=None), 'lon': TensorSpec(shape=(None,), dtype=tf.float64, name=None), 'b8a': TensorSpec(shape=(None,), dtype=tf.float64, name=None), 'b4': TensorSpec(shape=(None,), dtype=tf.float64, name=None), 'b2': TensorSpec(shape=(None,), dtype=tf.float64, name=None), 'b8': TensorSpec(shape=(None,), dtype=tf.float64, name=None), 'b3': TensorSpec(shape=(None,), dtype=tf.float64, name=None)}>\",)\n  • kwargs={'training': 'False'}"
          ]
        }
      ],
      "source": [
        "\n",
        "examples = tfdf.keras.pd_dataframe_to_tf_dataset(DF)\n",
        "a = model.predict_step(examples)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cMJwd4NLZDEV",
        "outputId": "559b6e80-b06a-4241-9040-d8a5eb114547"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[3565.8792]\n",
            " [3565.8792]\n",
            " [3565.8792]]\n"
          ]
        }
      ],
      "source": [
        "print(np.array(a))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPWRD3z219rl32eQ3YXtNSr",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}