{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/1kaiser/Snow-cover-area-estimation/blob/main/tiff2array.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yPdly86dtDqc"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qKTN6C1btYsH"
      },
      "outputs": [],
      "source": [
        "!cp -r /content/gdrive/MyDrive/OUT/data/data20230320 /content/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GNadjcbGhnwN"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "image_dir = r'/content/data20230320/'\n",
        "\n",
        "#############################################################################>> files are of their original sizes are kept in a folder with their respective extensions as bands b1, b2, b3 , b4 , b5 ....  and kept as to be listed as image list in a variable.\n",
        "prefix = \"\"\n",
        "end = [\"B11\", \"B12\", \"B02\", \"B03\", \"B04\", \"B05\", \"B06\", \"B07\", \"B8A\", \"B08\"]\n",
        "DayOY = \"_doy\\[0-9]+_aid0001\"\n",
        "fileExt = r'.tif'\n",
        "expression_b1 = prefix+end[0]\n",
        "expression_b2 = prefix+end[1]\n",
        "expression_b3 = prefix+end[2]\n",
        "expression_b4 = prefix+end[3]\n",
        "expression_b5 = prefix+end[4]\n",
        "expression_b6 = prefix+end[5]\n",
        "expression_b7 = prefix+end[6]\n",
        "expression_b8 = prefix+end[7]\n",
        "expression_b9 = prefix+end[8]\n",
        "expression_b10 = prefix+end[9]\n",
        "\n",
        "imgs_list_b1 = [f for f in os.listdir(image_dir) if f.__contains__(expression_b1)]\n",
        "\n",
        "imgs_list_b1.sort(reverse=True)    \n",
        "print(imgs_list_b1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UTqVV7ENkmAy"
      },
      "outputs": [],
      "source": [
        "path = os.path.join(image_dir, imgs_list_b1[0])\n",
        "path_list = [path.replace(expression_b1, expression_b1),\n",
        "             path.replace(expression_b1, expression_b2),\n",
        "             path.replace(expression_b1, expression_b3),\n",
        "             path.replace(expression_b1, expression_b4),\n",
        "             path.replace(expression_b1, expression_b5),\n",
        "             path.replace(expression_b1, expression_b6),\n",
        "             path.replace(expression_b1, expression_b7),\n",
        "             path.replace(expression_b1, expression_b8),\n",
        "             path.replace(expression_b1, expression_b9),\n",
        "             path.replace(expression_b1, expression_b10)]\n",
        "\n",
        "path_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vJMBYkichBM8"
      },
      "outputs": [],
      "source": [
        "\n",
        "path_list[0][-7:-4]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KoOTRHJmrlKR"
      },
      "outputs": [],
      "source": [
        "#this function is for getting the four corners of all the square boxes possible out of the complete image size >>>\n",
        "def get_slice_bboxes( image_height: int, image_width: int, slice_height: int = 2000 , slice_width: int = 2000, overlap_height_ratio: float = 0.0, overlap_width_ratio: float = 0.0 ):\n",
        "  slice_bboxes = []\n",
        "  y_max = y_min = 0\n",
        "\n",
        "  if slice_height and slice_width:\n",
        "      y_overlap = int(overlap_height_ratio * slice_height)\n",
        "      x_overlap = int(overlap_width_ratio * slice_width)\n",
        "  else:\n",
        "      raise ValueError(\"Compute type is not auto and slice width and height are not provided.\")\n",
        "\n",
        "  while y_max < image_height:\n",
        "      x_min = x_max = 0\n",
        "      y_max = y_min + slice_height\n",
        "      while x_max < image_width:\n",
        "          x_max = x_min + slice_width\n",
        "          if y_max > image_height or x_max > image_width:\n",
        "              xmax = min(image_width, x_max)\n",
        "              ymax = min(image_height, y_max)\n",
        "              xmin = max(0, xmax - slice_width)\n",
        "              ymin = max(0, ymax - slice_height)\n",
        "              slice_bboxes.append([xmin, ymin, xmax, ymax])\n",
        "          else:\n",
        "              slice_bboxes.append([x_min, y_min, x_max, y_max])\n",
        "          x_min = x_max - x_overlap\n",
        "      y_min = y_max - y_overlap\n",
        "  return slice_bboxes\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-uTZc27fBVW"
      },
      "source": [
        "##extraction of clips from original image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "biq2rXg3fF3k"
      },
      "source": [
        "pre requisite"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zrFu1SXavti-"
      },
      "outputs": [],
      "source": [
        "#\n",
        "# functions for clipping a single raster to multiple rasters of various shapes\n",
        "from osgeo import gdal\n",
        "temp_directory = \"/content/temp/\"\n",
        "save_directory = \"/content/gdrive/MyDrive/OUT/data/data20230320inputs/\"\n",
        "!mkdir -p {temp_directory} {save_directory} \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "03V3tNvD1QM-"
      },
      "source": [
        "###band 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b7wm7n3i1KHA"
      },
      "outputs": [],
      "source": [
        "here_image = path_list[0]\n",
        "print(here_image)\n",
        "\n",
        "vvv = here_image[-7:-4]\n",
        "ds = gdal.Open(here_image)\n",
        "box_list = get_slice_bboxes(ds.RasterYSize , ds.RasterXSize)\n",
        "\n",
        "count = 0\n",
        "\n",
        "for box in box_list:\n",
        "  print(box, type(box_list))\n",
        "  count = count + 1\n",
        "  gdal.Translate(str(temp_directory) + str(vvv) + \".\" + str(count) + '.tif', here_image ,srcWin = box )\n",
        "  !mv {temp_directory}/* {save_directory} "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VLrHv25t1Uol"
      },
      "source": [
        "###band 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MgqW1G3H1Wvz"
      },
      "outputs": [],
      "source": [
        "here_image = path_list[1]\n",
        "print(here_image)\n",
        "\n",
        "vvv = here_image[-7:-4]\n",
        "ds = gdal.Open(here_image)\n",
        "box_list = get_slice_bboxes(ds.RasterYSize , ds.RasterXSize)\n",
        "\n",
        "count = 0\n",
        "\n",
        "for box in box_list:\n",
        "  print(box, type(box_list))\n",
        "  count = count + 1\n",
        "  gdal.Translate(str(temp_directory) + str(vvv) + \".\" + str(count) + '.tif', here_image , srcWin = box )\n",
        "  !mv {temp_directory}/* {save_directory} "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tR_V9IZM1WKc"
      },
      "source": [
        "###band 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E_I-Ixzk1a3Z"
      },
      "outputs": [],
      "source": [
        "here_image = path_list[2]\n",
        "print(here_image)\n",
        "\n",
        "vvv = here_image[-7:-4]\n",
        "ds = gdal.Open(here_image)\n",
        "box_list = get_slice_bboxes(ds.RasterYSize , ds.RasterXSize)\n",
        "\n",
        "count = 0\n",
        "\n",
        "for box in box_list:\n",
        "  print(box, type(box_list))\n",
        "  count = count + 1\n",
        "  gdal.Translate(str(temp_directory) + str(vvv) + \".\" + str(count) + '.tif', here_image ,srcWin = box )\n",
        "  !mv {temp_directory}/* {save_directory} "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DPR_VjGe2L3-"
      },
      "source": [
        "###band 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jqeno17U2LTL"
      },
      "outputs": [],
      "source": [
        "here_image = path_list[3]\n",
        "print(here_image)\n",
        "\n",
        "vvv = here_image[-7:-4]\n",
        "ds = gdal.Open(here_image)\n",
        "box_list = get_slice_bboxes(ds.RasterYSize , ds.RasterXSize)\n",
        "\n",
        "count = 0\n",
        "\n",
        "for box in box_list:\n",
        "  print(box, type(box_list))\n",
        "  count = count + 1\n",
        "  gdal.Translate(str(temp_directory) + str(vvv) + \".\" + str(count) + '.tif', here_image ,srcWin = box )\n",
        "  !mv {temp_directory}/* {save_directory} "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9oaEGMPM2SJ-"
      },
      "source": [
        "###band 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u9EO93G72Tk5"
      },
      "outputs": [],
      "source": [
        "here_image = path_list[4]\n",
        "print(here_image)\n",
        "\n",
        "vvv = here_image[-7:-4]\n",
        "ds = gdal.Open(here_image)\n",
        "box_list = get_slice_bboxes(ds.RasterYSize , ds.RasterXSize)\n",
        "\n",
        "count = 0\n",
        "\n",
        "for box in box_list:\n",
        "  print(box, type(box_list))\n",
        "  count = count + 1\n",
        "  gdal.Translate(str(temp_directory) + str(vvv) + \".\" + str(count) + '.tif', here_image ,srcWin = box )\n",
        "  !mv {temp_directory}/* {save_directory} "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NkrfYdV42VSZ"
      },
      "source": [
        "###band 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-pazktaj2Wp1"
      },
      "outputs": [],
      "source": [
        "here_image = path_list[5]\n",
        "print(here_image)\n",
        "\n",
        "vvv = here_image[-7:-4]\n",
        "ds = gdal.Open(here_image)\n",
        "box_list = get_slice_bboxes(ds.RasterYSize , ds.RasterXSize)\n",
        "\n",
        "count = 0\n",
        "\n",
        "for box in box_list:\n",
        "  print(box, type(box_list))\n",
        "  count = count + 1\n",
        "  gdal.Translate(str(temp_directory) + str(vvv) + \".\" + str(count) + '.tif', here_image ,srcWin = box )\n",
        "  !mv {temp_directory}/* {save_directory} "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_e40XDPN2gEX"
      },
      "source": [
        "###band 6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n2I0dHcK2frI"
      },
      "outputs": [],
      "source": [
        "here_image = path_list[6]\n",
        "print(here_image)\n",
        "\n",
        "vvv = here_image[-7:-4]\n",
        "ds = gdal.Open(here_image)\n",
        "box_list = get_slice_bboxes(ds.RasterYSize , ds.RasterXSize)\n",
        "\n",
        "count = 0\n",
        "\n",
        "for box in box_list:\n",
        "  print(box, type(box_list))\n",
        "  count = count + 1\n",
        "  gdal.Translate(str(temp_directory) + str(vvv) + \".\" + str(count) + '.tif', here_image ,srcWin = box )\n",
        "  !mv {temp_directory}/* {save_directory} "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0QkYs09O2kZV"
      },
      "source": [
        "###band 7"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NZD5h3u02leQ"
      },
      "outputs": [],
      "source": [
        "here_image = path_list[7]\n",
        "print(here_image)\n",
        "\n",
        "vvv = here_image[-7:-4]\n",
        "ds = gdal.Open(here_image)\n",
        "box_list = get_slice_bboxes(ds.RasterYSize , ds.RasterXSize)\n",
        "\n",
        "count = 0\n",
        "\n",
        "for box in box_list:\n",
        "  print(box, type(box_list))\n",
        "  count = count + 1\n",
        "  gdal.Translate(str(temp_directory) + str(vvv) + \".\" + str(count) + '.tif', here_image ,srcWin = box )\n",
        "  !mv {temp_directory}/* {save_directory} "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ff8eG_Ja2nJn"
      },
      "source": [
        "###band 8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iSONd7M62oTU"
      },
      "outputs": [],
      "source": [
        "here_image = path_list[8]\n",
        "print(here_image)\n",
        "\n",
        "vvv = here_image[-7:-4]\n",
        "ds = gdal.Open(here_image)\n",
        "box_list = get_slice_bboxes(ds.RasterYSize , ds.RasterXSize)\n",
        "\n",
        "count = 0\n",
        "\n",
        "for box in box_list:\n",
        "  print(box, type(box_list))\n",
        "  count = count + 1\n",
        "  gdal.Translate(str(temp_directory) + str(vvv) + \".\" + str(count) + '.tif', here_image ,srcWin = box )\n",
        "  !mv {temp_directory}/* {save_directory} "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YX3UVG702p6Q"
      },
      "source": [
        "###band 9"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wGOb_VRX2rRO"
      },
      "outputs": [],
      "source": [
        "here_image = path_list[9]\n",
        "print(here_image)\n",
        "\n",
        "vvv = here_image[-7:-4]\n",
        "ds = gdal.Open(here_image)\n",
        "box_list = get_slice_bboxes(ds.RasterYSize , ds.RasterXSize)\n",
        "\n",
        "count = 0\n",
        "\n",
        "for box in box_list:\n",
        "  print(box, type(box_list))\n",
        "  count = count + 1\n",
        "  gdal.Translate(str(temp_directory) + str(vvv) + \".\" + str(count) + '.tif', here_image ,srcWin = box )\n",
        "  !mv {temp_directory}/* {save_directory} "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IGvjOhfq25Hx"
      },
      "source": [
        "## tensorflow band data extraction from model created from google sheets "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3lUV96TiqTux"
      },
      "outputs": [],
      "source": [
        "#\n",
        "#$$$$$$$$$$$$$$$$$%%%%%%%%%%%%%% tif2raster\n",
        "#\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import os.path\n",
        "import re\n",
        "\n",
        "from osgeo import gdal\n",
        "from osgeo import gdal_array\n",
        "from osgeo import osr\n",
        "\n",
        "def get_gain_band(input_file):\n",
        "    \"\"\"get GAIN_BAND from meta file (*.tif.txt)\"\"\"\n",
        "     # define file name of *.tif.txt\n",
        "    ifile_txt = re.sub(r'.tif', '.tif.txt', input_file)\n",
        "    ld = open(ifile_txt)\n",
        "    lines = ld.readlines()\n",
        "    ld.close()\n",
        "    \n",
        "    gain_band = []\n",
        "    for line in lines:\n",
        "        if line.find(\"GAIN_BAND\") >= 0:\n",
        "             gain_band.append(float((re.split(' ', line)[1]).strip()))\n",
        "    return gain_band\n",
        "\n",
        "def tif2array(input_file, calc_gain=True):\n",
        "    \"\"\"\n",
        "    read GeoTiff and convert to numpy.ndarray.\n",
        "    Inputs:\n",
        "        input_file (str) : the name of input GeoTiff file.\n",
        "        calc_gain (bool) : wheter calc GAIN to DN  or not (defaul:True).\n",
        "    return:\n",
        "        image(np.array) : image for each bands\n",
        "        dataset : for gdal's data drive.\n",
        "    \"\"\"\n",
        "    dataset = gdal.Open(input_file, gdal.GA_ReadOnly)\n",
        "    # Allocate our array using the first band's datatype\n",
        "    image_datatype = dataset.GetRasterBand(1).DataType\n",
        "    image = np.zeros((dataset.RasterYSize, dataset.RasterXSize, dataset.RasterCount),\n",
        "                     dtype=float)\n",
        "    \n",
        "    if calc_gain == True:\n",
        "        # get gain\n",
        "        gain = get_gain_band(input_file)\n",
        "    \n",
        "    # Loop over all bands in dataset\n",
        "    for b in range(dataset.RasterCount):\n",
        "        # Remember, GDAL index is on 1, but Python is on 0 -- so we add 1 for our GDAL calls\n",
        "        band = dataset.GetRasterBand(b + 1)\n",
        "        # Read in the band's data into the third dimension of our array\n",
        "        if calc_gain == True:\n",
        "            # calc gain value for each bands\n",
        "            image[:, :, b] = band.ReadAsArray() * gain[b]\n",
        "        else:\n",
        "            image[:, :, b] = band.ReadAsArray()\n",
        "    return image, dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CbZUMzKd_PO-"
      },
      "source": [
        "setting up for tif2array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4p1zGV-z-jWr"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "image_dir = r'/content/gdrive/MyDrive/OUT/data/data20230320inputs/'\n",
        "\n",
        "#############################################################################>> files are of their original sizes are kept in a folder with their respective extensions as bands b1, b2, b3 , b4 , b5 ....  and kept as to be listed as image list in a variable.\n",
        "prefix = \"\"\n",
        "end = [\"B11\", \"B12\", \"B02\", \"B03\", \"B04\", \"B05\", \"B06\", \"B07\", \"B8A\", \"B08\"]\n",
        "DayOY = \"_doy\\[0-9]+_aid0001\"\n",
        "fileExt = r'.tif'\n",
        "expression_b1 = prefix+end[0]\n",
        "expression_b2 = prefix+end[1]\n",
        "expression_b3 = prefix+end[2]\n",
        "expression_b4 = prefix+end[3]\n",
        "expression_b5 = prefix+end[4]\n",
        "expression_b6 = prefix+end[5]\n",
        "expression_b7 = prefix+end[6]\n",
        "expression_b8 = prefix+end[7]\n",
        "expression_b9 = prefix+end[8]\n",
        "expression_b10 = prefix+end[9]\n",
        "\n",
        "imgs_list_b1 = [f for f in os.listdir(image_dir) if f.__contains__(expression_b1)]\n",
        "\n",
        "imgs_list_b1.sort(reverse=True)    \n",
        "print(imgs_list_b1)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qmznxvEmjXoF"
      },
      "outputs": [],
      "source": [
        "#extraction of band values from clips to DATAFRAME for to be processing inside the model\n",
        "\n",
        "from osgeo import gdal\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "######################$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$<<< tensorflow model\n",
        "#Copy and execute the following code in a new Google Colab notebook launch to run the model.\n",
        "!python -m pip install tensorflow tensorflow_decision_forests -U -qq\n",
        "\n",
        "# Transfer the model from Google Drive to Colab\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\")\n",
        "!cp \"/content/gdrive/My Drive/simple_ml_for_sheets/Ice height from bands\" ydf_model\n",
        "  \n",
        "# Prepare and load the model with TensorFlow\n",
        "import tensorflow as tf\n",
        "import tensorflow_decision_forests as tfdf\n",
        "\n",
        "tfdf.keras.yggdrasil_model_to_keras_model(\"ydf_model\", \"tfdf_model\")\n",
        "model = tf.keras.models.load_model(\"tfdf_model\")\n",
        "######################$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$<<< tensorflow model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2512KHSgEqrJ"
      },
      "outputs": [],
      "source": [
        "path = os.path.join(image_dir, imgs_list_b1[6])\n",
        "path_list = [path.replace(expression_b1, expression_b1),\n",
        "            path.replace(expression_b1, expression_b2),\n",
        "            path.replace(expression_b1, expression_b3),\n",
        "            path.replace(expression_b1, expression_b4),\n",
        "            path.replace(expression_b1, expression_b5),\n",
        "            path.replace(expression_b1, expression_b6),\n",
        "            path.replace(expression_b1, expression_b7),\n",
        "            path.replace(expression_b1, expression_b8),\n",
        "            path.replace(expression_b1, expression_b9),\n",
        "            path.replace(expression_b1, expression_b10)]\n",
        "path_list[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4dcId8Lbl9E9"
      },
      "outputs": [],
      "source": [
        "!cp -r {path_list[0]} /content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mPkE6j0QjBPH"
      },
      "outputs": [],
      "source": [
        "os.path.getsize(path_list[10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zj0a0QuMgMcA"
      },
      "outputs": [],
      "source": [
        "for image_no in range(0, len(imgs_list_b1)):\n",
        "  path = os.path.join(image_dir, imgs_list_b1[image_no])\n",
        "  path_list = [path.replace(expression_b1, expression_b1),\n",
        "              path.replace(expression_b1, expression_b2),\n",
        "              path.replace(expression_b1, expression_b3),\n",
        "              path.replace(expression_b1, expression_b4),\n",
        "              path.replace(expression_b1, expression_b5),\n",
        "              path.replace(expression_b1, expression_b6),\n",
        "              path.replace(expression_b1, expression_b7),\n",
        "              path.replace(expression_b1, expression_b8),\n",
        "              path.replace(expression_b1, expression_b9),\n",
        "              path.replace(expression_b1, expression_b10)]\n",
        "\n",
        "  print(path_list)\n",
        "  for i in path_list:\n",
        "    os.path.getsize(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PyRqQ37pLHS7"
      },
      "outputs": [],
      "source": [
        "gdal.Open(path_list[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "24qshMGyLEgb"
      },
      "outputs": [],
      "source": [
        "v1 = tif2array(\"/content/gdrive/MyDrive/OUT/data/data20230320inputs/B03.6.tif\", 0)[0].reshape(-1,1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YwKtSRMqxW1P"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "for image_no in range(0, len(imgs_list_b1)):\n",
        "  path = os.path.join(image_dir, imgs_list_b1[image_no])\n",
        "  path_list = [path.replace(expression_b1, expression_b1),\n",
        "              path.replace(expression_b1, expression_b2),\n",
        "              path.replace(expression_b1, expression_b3),\n",
        "              path.replace(expression_b1, expression_b4),\n",
        "              path.replace(expression_b1, expression_b5),\n",
        "              path.replace(expression_b1, expression_b6),\n",
        "              path.replace(expression_b1, expression_b7),\n",
        "              path.replace(expression_b1, expression_b8),\n",
        "              path.replace(expression_b1, expression_b9),\n",
        "              path.replace(expression_b1, expression_b10)]\n",
        "\n",
        "  lon , lat = [] , []  \n",
        "  v1 =[]\n",
        "\n",
        "  for i in path_list:\n",
        "    pathout = i\n",
        "    print(pathout)\n",
        "    \n",
        "    if(path_list.index(i)==0):\n",
        "      v1 = tif2array(pathout, 0)[0].reshape(-1,1)\n",
        "      # Open tif file\n",
        "      ds = gdal.Open(pathout)\n",
        "      # GDAL affine transform parameters, According to gdal documentation xoff/yoff are image left corner, a/e are pixel wight/height and b/d is rotation and is zero if image is north up. \n",
        "      xoff, a, b, yoff, d, e = ds.GetGeoTransform()\n",
        "      print(xoff, a, b, yoff, d, e)\n",
        "      def pixel2coord(x, y):\n",
        "        # \"\"Returns global coordinates from pixel x, y coords\"\"\n",
        "        xp = a * x + b * y + xoff\n",
        "        yp = d * x + e * y + yoff\n",
        "        return xp, yp\n",
        "\n",
        "      # get columns and rows of your image from gdalinfo\n",
        "      rows = ds.RasterYSize \n",
        "      colms = ds.RasterXSize \n",
        "      for row in  range(0,rows):\n",
        "        for col in  range(0,colms): \n",
        "          lat.append(pixel2coord(col,row)[0])\n",
        "          lon.append(pixel2coord(col,row)[1])\n",
        "    else:\n",
        "      v1 = np.append(v1, tif2array(pathout, 0)[0].reshape(-1,1), axis = 1)\n",
        "  # agging latitude \"lat\" & longitde \"lon\" column at the end\n",
        "  v1 = np.column_stack((v1, np.column_stack((lat, lon))))\n",
        "\n",
        "\n",
        "  arr = v1\n",
        "  # convert array into dataframe\n",
        "  DF = pd.DataFrame(arr)\n",
        "  # DF.columns = d\n",
        "    # print(DF)\n",
        "  height =[]\n",
        "  for values in range(0, len(DF[0])):\n",
        "    examples = {\n",
        "    \"b11\" : [np.array(DF[0][values])],\n",
        "    \"b12\" : [np.array(DF[1][values])],\n",
        "    \"b2\" : [np.array(DF[2][values])],\n",
        "    \"b3\" : [np.array(DF[3][values])],\n",
        "    \"b4\" : [np.array(DF[4][values])],\n",
        "    \"b5\" : [np.array(DF[5][values])],\n",
        "    \"b6\" : [np.array(DF[6][values])],\n",
        "    \"b7\" : [np.array(DF[7][values])],\n",
        "    \"b8a\" : [np.array(DF[8][values])],\n",
        "    \"b8\" : [np.array(DF[9][values])],\n",
        "    \"lat\" : [np.array(DF[10][values])],\n",
        "    \"lon\" : [np.array(DF[11][values])],\n",
        "    }\n",
        "######################$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$<<< tensorflow model\n",
        "\n",
        "    a = np.array(model.predict_step(examples))\n",
        "######################$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$<<< tensorflow model\n",
        "\n",
        "    height.append(a[0][0])\n",
        "  print(np.asarray(height))\n",
        "  print(height)\n",
        "  height = np.column_stack((np.column_stack((lat, lon)), height))\n",
        "  # saving the predicted heght data to panda dataframe\n",
        "  DHeight = pd.DataFrame(height)\n",
        "  # DF.columns = d\n",
        "  DHeight\n",
        "  # save the dataframe as a csv file\n",
        "  DHeight.to_csv(\"height_\" + str(image_no) + \".csv\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C_iDHZ121eNv"
      },
      "source": [
        "# final processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EaCOuudi2UCJ"
      },
      "source": [
        "##**ðŸ’½ google drive connection**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "VNIB-zUW2PjJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc0ecb1c-ee99-4d01-ee18-e891226791bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "MbDz761i2PjK"
      },
      "outputs": [],
      "source": [
        "!cp -r /content/gdrive/MyDrive/OUT/data/data20230320 /content/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "_5VIz4CW2PjK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3395477-873a-4463-e430-93aaadb9d565"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['download.B11.tif']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/data20230320/download.B11.tif',\n",
              " '/content/data20230320/download.B12.tif',\n",
              " '/content/data20230320/download.B02.tif',\n",
              " '/content/data20230320/download.B03.tif',\n",
              " '/content/data20230320/download.B04.tif',\n",
              " '/content/data20230320/download.B05.tif',\n",
              " '/content/data20230320/download.B06.tif',\n",
              " '/content/data20230320/download.B07.tif',\n",
              " '/content/data20230320/download.B8A.tif',\n",
              " '/content/data20230320/download.B08.tif']"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "import os\n",
        "image_dir = r'/content/data20230320/'\n",
        "\n",
        "#############################################################################>> files are of their original sizes are kept in a folder with their respective extensions as bands b1, b2, b3 , b4 , b5 ....  and kept as to be listed as image list in a variable.\n",
        "prefix = \"\"\n",
        "end = [\"B11\", \"B12\", \"B02\", \"B03\", \"B04\", \"B05\", \"B06\", \"B07\", \"B8A\", \"B08\"]\n",
        "DayOY = \"_doy\\[0-9]+_aid0001\"\n",
        "fileExt = r'.tif'\n",
        "expression_b1 = prefix+end[0]\n",
        "expression_b2 = prefix+end[1]\n",
        "expression_b3 = prefix+end[2]\n",
        "expression_b4 = prefix+end[3]\n",
        "expression_b5 = prefix+end[4]\n",
        "expression_b6 = prefix+end[5]\n",
        "expression_b7 = prefix+end[6]\n",
        "expression_b8 = prefix+end[7]\n",
        "expression_b9 = prefix+end[8]\n",
        "expression_b10 = prefix+end[9]\n",
        "\n",
        "imgs_list_b1 = [f for f in os.listdir(image_dir) if f.__contains__(expression_b1)]\n",
        "\n",
        "imgs_list_b1.sort(reverse=True)    \n",
        "print(imgs_list_b1)\n",
        "\n",
        "path = os.path.join(image_dir, imgs_list_b1[0])\n",
        "path_list = [path.replace(expression_b1, expression_b1),\n",
        "             path.replace(expression_b1, expression_b2),\n",
        "             path.replace(expression_b1, expression_b3),\n",
        "             path.replace(expression_b1, expression_b4),\n",
        "             path.replace(expression_b1, expression_b5),\n",
        "             path.replace(expression_b1, expression_b6),\n",
        "             path.replace(expression_b1, expression_b7),\n",
        "             path.replace(expression_b1, expression_b8),\n",
        "             path.replace(expression_b1, expression_b9),\n",
        "             path.replace(expression_b1, expression_b10)]\n",
        "\n",
        "path_list"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sSLCc1yf2dm5"
      },
      "source": [
        "##**ðŸŒŸloading prequisites**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z2IIkkAf1hqx",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title **pre** requisite funcrions **1ï¸âƒ£tif2array, 2ï¸âƒ£get_slice_bboxes**\n",
        "#\n",
        "#$$$$$$$$$$$$$$$$$%%%%%%%%%%%%%% tif2raster\n",
        "#\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import os.path\n",
        "import re\n",
        "\n",
        "from osgeo import gdal\n",
        "from osgeo import gdal_array\n",
        "from osgeo import osr\n",
        "\n",
        "def get_gain_band(input_file):\n",
        "    \"\"\"get GAIN_BAND from meta file (*.tif.txt)\"\"\"\n",
        "     # define file name of *.tif.txt\n",
        "    ifile_txt = re.sub(r'.tif', '.tif.txt', input_file)\n",
        "    ld = open(ifile_txt)\n",
        "    lines = ld.readlines()\n",
        "    ld.close()\n",
        "    \n",
        "    gain_band = []\n",
        "    for line in lines:\n",
        "        if line.find(\"GAIN_BAND\") >= 0:\n",
        "             gain_band.append(float((re.split(' ', line)[1]).strip()))\n",
        "    return gain_band\n",
        "\n",
        "def tif2array(input_file, calc_gain=True):\n",
        "    \"\"\"\n",
        "    read GeoTiff and convert to numpy.ndarray.\n",
        "    Inputs:\n",
        "        input_file (str) : the name of input GeoTiff file.\n",
        "        calc_gain (bool) : wheter calc GAIN to DN  or not (defaul:True).\n",
        "    return:\n",
        "        image(np.array) : image for each bands\n",
        "        dataset : for gdal's data drive.\n",
        "    \"\"\"\n",
        "    dataset = gdal.Open(input_file, gdal.GA_ReadOnly)\n",
        "    # Allocate our array using the first band's datatype\n",
        "    image_datatype = dataset.GetRasterBand(1).DataType\n",
        "    image = np.zeros((dataset.RasterYSize, dataset.RasterXSize, dataset.RasterCount),\n",
        "                     dtype=float)\n",
        "    \n",
        "    if calc_gain == True:\n",
        "        # get gain\n",
        "        gain = get_gain_band(input_file)\n",
        "    \n",
        "    # Loop over all bands in dataset\n",
        "    for b in range(dataset.RasterCount):\n",
        "        # Remember, GDAL index is on 1, but Python is on 0 -- so we add 1 for our GDAL calls\n",
        "        band = dataset.GetRasterBand(b + 1)\n",
        "        # Read in the band's data into the third dimension of our array\n",
        "        if calc_gain == True:\n",
        "            # calc gain value for each bands\n",
        "            image[:, :, b] = band.ReadAsArray() * gain[b]\n",
        "        else:\n",
        "            image[:, :, b] = band.ReadAsArray()\n",
        "    return image, dataset\n",
        "\n",
        "#this function is for getting the four corners of all the square boxes possible out of the complete image size >>>\n",
        "def get_slice_bboxes( image_height: int, image_width: int, slice_height: int = 400 , slice_width: int = 400, overlap_height_ratio: float = 0.0, overlap_width_ratio: float = 0.0 ):\n",
        "  slice_bboxes = []\n",
        "  y_max = y_min = 0\n",
        "\n",
        "  if slice_height and slice_width:\n",
        "      y_overlap = int(overlap_height_ratio * slice_height)\n",
        "      x_overlap = int(overlap_width_ratio * slice_width)\n",
        "  else:\n",
        "      raise ValueError(\"Compute type is not auto and slice width and height are not provided.\")\n",
        "\n",
        "  while y_max < image_height:\n",
        "      x_min = x_max = 0\n",
        "      y_max = y_min + slice_height\n",
        "      while x_max < image_width:\n",
        "          x_max = x_min + slice_width\n",
        "          if y_max > image_height or x_max > image_width:\n",
        "              xmax = min(image_width, x_max)\n",
        "              ymax = min(image_height, y_max)\n",
        "              xmin = max(0, xmax - slice_width)\n",
        "              ymin = max(0, ymax - slice_height)\n",
        "              slice_bboxes.append([xmin, ymin, xmax, ymax])\n",
        "          else:\n",
        "              slice_bboxes.append([x_min, y_min, x_max, y_max])\n",
        "          x_min = x_max - x_overlap\n",
        "      y_min = y_max - y_overlap\n",
        "  return slice_bboxes\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "xAPZQNU91hqx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 713
        },
        "outputId": "357e68a3-8fe7-406b-f70b-7cf2483fc4fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: tensorflow 2.11.0\n",
            "Uninstalling tensorflow-2.11.0:\n",
            "  Would remove:\n",
            "    /usr/local/bin/estimator_ckpt_converter\n",
            "    /usr/local/bin/import_pb_to_tensorboard\n",
            "    /usr/local/bin/saved_model_cli\n",
            "    /usr/local/bin/tensorboard\n",
            "    /usr/local/bin/tf_upgrade_v2\n",
            "    /usr/local/bin/tflite_convert\n",
            "    /usr/local/bin/toco\n",
            "    /usr/local/bin/toco_from_protos\n",
            "    /usr/local/lib/python3.9/dist-packages/tensorflow-2.11.0.dist-info/*\n",
            "    /usr/local/lib/python3.9/dist-packages/tensorflow/*\n",
            "Proceed (Y/n)? y\n",
            "  Successfully uninstalled tensorflow-2.11.0\n",
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:TensorFlow Decision Forests 1.2.0 is compatible with the following TensorFlow Versions: ['2.11.0']. However, TensorFlow 2.12.0 was detected. This can cause issues with the TF API and symbols in the custom C++ ops. See the TF and TF-DF compatibility table at https://github.com/tensorflow/decision-forests/blob/main/documentation/known_issues.md#compatibility-table.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-c9a50eeaf5c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m# Prepare and load the model with TensorFlow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow_decision_forests\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtfdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mtfdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myggdrasil_model_to_keras_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ydf_model\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"tfdf_model\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow_decision_forests/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0mcheck_version\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_version\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__version__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompatible_tf_versions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_decision_forests\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_decision_forests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomponent\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpy_tree\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_decision_forests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomponent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilder\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbuilder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow_decision_forests/keras/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtyping\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCallable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_decision_forests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_decision_forests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwrappers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow_decision_forests/keras/core.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdataset_ops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_decision_forests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomponent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minspector\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minspector\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0minspector_lib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_decision_forests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomponent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtuner\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtuner\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtuner_lib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_decision_forests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcore_inference\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow_decision_forests/component/inspector/inspector.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_decision_forests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomponent\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpy_tree\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_decision_forests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomponent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minspector\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mblob_sequence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0myggdrasil_decision_forests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdata_spec_pb2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow_decision_forests/component/py_tree/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \"\"\"\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_decision_forests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomponent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpy_tree\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcondition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_decision_forests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomponent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpy_tree\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdataspec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_decision_forests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomponent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpy_tree\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow_decision_forests/component/py_tree/condition.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_decision_forests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomponent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpy_tree\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdataspec\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdataspec_lib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0myggdrasil_decision_forests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdata_spec_pb2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0myggdrasil_decision_forests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecision_tree\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdecision_tree_pb2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow_decision_forests/component/py_tree/dataspec.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtyping\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNamedTuple\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0myggdrasil_decision_forests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdata_spec_pb2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0mColumnType\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_spec_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mColumnType\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/yggdrasil_decision_forests/dataset/data_spec_pb2.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m DESCRIPTOR = _descriptor.FileDescriptor(\n\u001b[0m\u001b[1;32m     20\u001b[0m   \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'yggdrasil_decision_forests/dataset/data_spec.proto'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m   \u001b[0mpackage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'yggdrasil_decision_forests.dataset.proto'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/google/protobuf/descriptor.py\u001b[0m in \u001b[0;36m__new__\u001b[0;34m(cls, name, package, options, serialized_options, serialized_pb, dependencies, public_dependencies, syntax, pool, create_key)\u001b[0m\n\u001b[1;32m   1064\u001b[0m   \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1065\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1066\u001b[0;31m   \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1067\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mc\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'_'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1068\u001b[0m       \u001b[0mcapitalize_next\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Couldn't build proto file into descriptor pool: duplicate file name yggdrasil_decision_forests/dataset/data_spec.proto"
          ]
        }
      ],
      "source": [
        "#@title **ðŸŽ›ï¸** Tensorflow  **tensorflow_decision_forests**  library loading\n",
        "#extraction of band values from clips to DATAFRAME for to be processing inside the model\n",
        "\n",
        "from osgeo import gdal\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "######################$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$<<< tensorflow model\n",
        "#Copy and execute the following code in a new Google Colab notebook launch to run the model.\n",
        "!python -m pip install tensorflow tensorflow_decision_forests -U -qq\n",
        "\n",
        "# Transfer the model from Google Drive to Colab\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\")\n",
        "!cp \"/content/gdrive/My Drive/simple_ml_for_sheets/Ice height from bands\" ydf_model\n",
        "  \n",
        "# Prepare and load the model with TensorFlow\n",
        "import tensorflow as tf\n",
        "import tensorflow_decision_forests as tfdf\n",
        "\n",
        "tfdf.keras.yggdrasil_model_to_keras_model(\"ydf_model\", \"tfdf_model\")\n",
        "model = tf.keras.models.load_model(\"tfdf_model\")\n",
        "######################$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$<<< tensorflow model\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wc8QMk8JlyEx",
        "outputId": "a3caaa98-96cb-4eed-e1e6-01b062224b21"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Package                       Version\n",
            "----------------------------- --------------------\n",
            "absl-py                       1.4.0\n",
            "alabaster                     0.7.13\n",
            "albumentations                1.2.1\n",
            "altair                        4.2.2\n",
            "appdirs                       1.4.4\n",
            "argon2-cffi                   21.3.0\n",
            "argon2-cffi-bindings          21.2.0\n",
            "arviz                         0.15.1\n",
            "astropy                       5.2.1\n",
            "astunparse                    1.6.3\n",
            "atomicwrites                  1.4.1\n",
            "attrs                         22.2.0\n",
            "audioread                     3.0.0\n",
            "autograd                      1.5\n",
            "Babel                         2.12.1\n",
            "backcall                      0.2.0\n",
            "beautifulsoup4                4.11.2\n",
            "bleach                        6.0.0\n",
            "blis                          0.7.9\n",
            "bokeh                         2.4.3\n",
            "branca                        0.6.0\n",
            "bs4                           0.0.1\n",
            "CacheControl                  0.12.11\n",
            "cachetools                    5.3.0\n",
            "catalogue                     2.0.8\n",
            "certifi                       2022.12.7\n",
            "cffi                          1.15.1\n",
            "chardet                       3.0.4\n",
            "charset-normalizer            2.0.12\n",
            "click                         8.1.3\n",
            "cloudpickle                   2.2.1\n",
            "cmake                         3.25.2\n",
            "cmdstanpy                     1.1.0\n",
            "colorcet                      3.0.1\n",
            "colorlover                    0.3.0\n",
            "community                     1.0.0b1\n",
            "confection                    0.0.4\n",
            "cons                          0.4.5\n",
            "contextlib2                   0.6.0.post1\n",
            "contourpy                     1.0.7\n",
            "convertdate                   2.4.0\n",
            "cufflinks                     0.17.3\n",
            "cvxopt                        1.3.0\n",
            "cvxpy                         1.3.1\n",
            "cycler                        0.11.0\n",
            "cymem                         2.0.7\n",
            "Cython                        0.29.33\n",
            "dask                          2022.12.1\n",
            "datascience                   0.17.6\n",
            "db-dtypes                     1.0.5\n",
            "dbus-python                   1.2.16\n",
            "debugpy                       1.6.6\n",
            "decorator                     4.4.2\n",
            "defusedxml                    0.7.1\n",
            "distributed                   2022.12.1\n",
            "dlib                          19.24.0\n",
            "dm-tree                       0.1.8\n",
            "docutils                      0.16\n",
            "dopamine-rl                   1.0.5\n",
            "earthengine-api               0.1.345\n",
            "easydict                      1.10\n",
            "ecos                          2.0.12\n",
            "editdistance                  0.5.3\n",
            "en-core-web-sm                3.5.0\n",
            "entrypoints                   0.4\n",
            "ephem                         4.1.4\n",
            "et-xmlfile                    1.1.0\n",
            "etils                         1.1.1\n",
            "etuples                       0.3.8\n",
            "fastai                        2.7.11\n",
            "fastcore                      1.5.28\n",
            "fastdownload                  0.0.7\n",
            "fastjsonschema                2.16.3\n",
            "fastprogress                  1.0.3\n",
            "fastrlock                     0.8.1\n",
            "filelock                      3.10.0\n",
            "firebase-admin                5.3.0\n",
            "fix-yahoo-finance             0.0.22\n",
            "Flask                         2.2.3\n",
            "flatbuffers                   23.3.3\n",
            "folium                        0.14.0\n",
            "fonttools                     4.39.2\n",
            "fsspec                        2023.3.0\n",
            "future                        0.18.3\n",
            "gast                          0.4.0\n",
            "GDAL                          3.3.2\n",
            "gdown                         4.6.4\n",
            "gensim                        4.3.1\n",
            "geographiclib                 2.0\n",
            "geopy                         2.3.0\n",
            "gin-config                    0.5.0\n",
            "glob2                         0.7\n",
            "google                        2.0.3\n",
            "google-api-core               2.11.0\n",
            "google-api-python-client      2.70.0\n",
            "google-auth                   2.16.2\n",
            "google-auth-httplib2          0.1.0\n",
            "google-auth-oauthlib          0.4.6\n",
            "google-cloud-bigquery         3.4.2\n",
            "google-cloud-bigquery-storage 2.19.0\n",
            "google-cloud-core             2.3.2\n",
            "google-cloud-datastore        2.11.1\n",
            "google-cloud-firestore        2.7.3\n",
            "google-cloud-language         2.6.1\n",
            "google-cloud-storage          2.7.0\n",
            "google-cloud-translate        3.8.4\n",
            "google-colab                  1.0.0\n",
            "google-crc32c                 1.5.0\n",
            "google-pasta                  0.2.0\n",
            "google-resumable-media        2.4.1\n",
            "googleapis-common-protos      1.58.0\n",
            "googledrivedownloader         0.4\n",
            "graphviz                      0.20.1\n",
            "greenlet                      2.0.2\n",
            "grpcio                        1.51.3\n",
            "grpcio-status                 1.48.2\n",
            "gspread                       3.4.2\n",
            "gspread-dataframe             3.0.8\n",
            "gym                           0.25.2\n",
            "gym-notices                   0.0.8\n",
            "h5netcdf                      1.1.0\n",
            "h5py                          3.8.0\n",
            "HeapDict                      1.0.1\n",
            "hijri-converter               2.2.4\n",
            "holidays                      0.21.13\n",
            "holoviews                     1.15.4\n",
            "html5lib                      1.1\n",
            "htmlmin                       0.1.12\n",
            "httpimport                    1.3.0\n",
            "httplib2                      0.21.0\n",
            "humanize                      4.6.0\n",
            "hyperopt                      0.2.7\n",
            "idna                          3.4\n",
            "ImageHash                     4.3.1\n",
            "imageio                       2.25.1\n",
            "imagesize                     1.4.1\n",
            "imbalanced-learn              0.10.1\n",
            "imblearn                      0.0\n",
            "imgaug                        0.4.0\n",
            "importlib-metadata            6.1.0\n",
            "importlib-resources           5.12.0\n",
            "imutils                       0.5.4\n",
            "inflect                       6.0.2\n",
            "intel-openmp                  2023.0.0\n",
            "ipykernel                     5.3.4\n",
            "ipython                       7.9.0\n",
            "ipython-genutils              0.2.0\n",
            "ipython-sql                   0.3.9\n",
            "ipywidgets                    7.7.1\n",
            "itsdangerous                  2.1.2\n",
            "jax                           0.4.6\n",
            "jaxlib                        0.4.6+cuda11.cudnn86\n",
            "jieba                         0.42.1\n",
            "Jinja2                        3.1.2\n",
            "joblib                        1.1.1\n",
            "jsonschema                    4.3.3\n",
            "jupyter-client                6.1.12\n",
            "jupyter-console               6.1.0\n",
            "jupyter_core                  5.3.0\n",
            "jupyterlab-pygments           0.2.2\n",
            "jupyterlab-widgets            3.0.5\n",
            "kaggle                        1.5.13\n",
            "keras                         2.12.0\n",
            "keras-vis                     0.4.1\n",
            "kiwisolver                    1.4.4\n",
            "korean-lunar-calendar         0.3.1\n",
            "langcodes                     3.3.0\n",
            "lazy_loader                   0.1\n",
            "libclang                      15.0.6.1\n",
            "librosa                       0.10.0.post2\n",
            "lightgbm                      3.3.5\n",
            "llvmlite                      0.39.1\n",
            "locket                        1.0.0\n",
            "logical-unification           0.4.5\n",
            "LunarCalendar                 0.0.9\n",
            "lxml                          4.9.2\n",
            "Markdown                      3.4.1\n",
            "MarkupSafe                    2.1.2\n",
            "matplotlib                    3.7.1\n",
            "matplotlib-venn               0.11.9\n",
            "miniKanren                    1.0.3\n",
            "missingno                     0.5.2\n",
            "mistune                       0.8.4\n",
            "mizani                        0.8.1\n",
            "mkl                           2019.0\n",
            "mlxtend                       0.14.0\n",
            "more-itertools                9.1.0\n",
            "moviepy                       0.2.3.5\n",
            "mpmath                        1.3.0\n",
            "msgpack                       1.0.5\n",
            "multimethod                   1.9.1\n",
            "multipledispatch              0.6.0\n",
            "multitasking                  0.0.11\n",
            "murmurhash                    1.0.9\n",
            "music21                       5.5.0\n",
            "natsort                       5.5.0\n",
            "nbclient                      0.7.2\n",
            "nbconvert                     6.5.4\n",
            "nbformat                      5.8.0\n",
            "networkx                      3.0\n",
            "nibabel                       3.0.2\n",
            "nltk                          3.8.1\n",
            "notebook                      6.3.0\n",
            "numba                         0.56.4\n",
            "numexpr                       2.8.4\n",
            "numpy                         1.22.4\n",
            "oauth2client                  4.1.3\n",
            "oauthlib                      3.2.2\n",
            "opencv-contrib-python         4.7.0.72\n",
            "opencv-python                 4.7.0.72\n",
            "opencv-python-headless        4.7.0.72\n",
            "openpyxl                      3.0.10\n",
            "opt-einsum                    3.3.0\n",
            "osqp                          0.6.2.post0\n",
            "packaging                     23.0\n",
            "palettable                    3.3.0\n",
            "pandas                        1.4.4\n",
            "pandas-datareader             0.10.0\n",
            "pandas-gbq                    0.17.9\n",
            "pandas-profiling              3.2.0\n",
            "pandocfilters                 1.5.0\n",
            "panel                         0.14.4\n",
            "param                         1.13.0\n",
            "parso                         0.8.3\n",
            "partd                         1.3.0\n",
            "pathlib                       1.0.1\n",
            "pathy                         0.10.1\n",
            "patsy                         0.5.3\n",
            "pep517                        0.13.0\n",
            "pexpect                       4.8.0\n",
            "phik                          0.12.3\n",
            "pickleshare                   0.7.5\n",
            "Pillow                        8.4.0\n",
            "pip                           22.0.4\n",
            "pip-tools                     6.6.2\n",
            "platformdirs                  3.1.1\n",
            "plotly                        5.13.1\n",
            "plotnine                      0.10.1\n",
            "pluggy                        0.7.1\n",
            "pooch                         1.6.0\n",
            "portpicker                    1.3.9\n",
            "prefetch-generator            1.0.3\n",
            "preshed                       3.0.8\n",
            "prettytable                   3.6.0\n",
            "progressbar2                  3.38.0\n",
            "prometheus-client             0.16.0\n",
            "promise                       2.3\n",
            "prompt-toolkit                2.0.10\n",
            "prophet                       1.1.2\n",
            "proto-plus                    1.22.2\n",
            "protobuf                      4.22.1\n",
            "psutil                        5.9.4\n",
            "psycopg2                      2.9.5\n",
            "ptyprocess                    0.7.0\n",
            "py                            1.11.0\n",
            "py4j                          0.10.9.7\n",
            "pyarrow                       9.0.0\n",
            "pyasn1                        0.4.8\n",
            "pyasn1-modules                0.2.8\n",
            "pycocotools                   2.0.6\n",
            "pycparser                     2.21\n",
            "pyct                          0.5.0\n",
            "pydantic                      1.10.6\n",
            "pydata-google-auth            1.7.0\n",
            "pydot                         1.4.2\n",
            "pydot-ng                      2.0.0\n",
            "pydotplus                     2.0.2\n",
            "PyDrive                       1.3.1\n",
            "pyerfa                        2.0.0.2\n",
            "Pygments                      2.6.1\n",
            "PyGObject                     3.36.0\n",
            "pymc                          5.1.2\n",
            "PyMeeus                       0.5.12\n",
            "pymystem3                     0.2.0\n",
            "PyOpenGL                      3.1.6\n",
            "pyparsing                     3.0.9\n",
            "pyrsistent                    0.19.3\n",
            "PySocks                       1.7.1\n",
            "pytensor                      2.10.1\n",
            "pytest                        3.6.4\n",
            "python-apt                    0.0.0\n",
            "python-dateutil               2.8.2\n",
            "python-louvain                0.16\n",
            "python-slugify                8.0.1\n",
            "python-utils                  3.5.2\n",
            "pytz                          2022.7.1\n",
            "pytz-deprecation-shim         0.1.0.post0\n",
            "pyviz-comms                   2.2.1\n",
            "PyWavelets                    1.4.1\n",
            "PyYAML                        6.0\n",
            "pyzmq                         23.2.1\n",
            "qdldl                         0.1.5.post3\n",
            "qudida                        0.0.4\n",
            "regex                         2022.10.31\n",
            "requests                      2.27.1\n",
            "requests-oauthlib             1.3.1\n",
            "requests-unixsocket           0.2.0\n",
            "rpy2                          3.5.5\n",
            "rsa                           4.9\n",
            "scikit-image                  0.19.3\n",
            "scikit-learn                  1.2.2\n",
            "scipy                         1.10.1\n",
            "screen-resolution-extra       0.0.0\n",
            "scs                           3.2.2\n",
            "seaborn                       0.12.2\n",
            "Send2Trash                    1.8.0\n",
            "setuptools                    67.6.0\n",
            "shapely                       2.0.1\n",
            "six                           1.16.0\n",
            "sklearn-pandas                2.2.0\n",
            "smart-open                    6.3.0\n",
            "snowballstemmer               2.2.0\n",
            "sortedcontainers              2.4.0\n",
            "soundfile                     0.12.1\n",
            "soupsieve                     2.4\n",
            "soxr                          0.3.4\n",
            "spacy                         3.5.1\n",
            "spacy-legacy                  3.0.12\n",
            "spacy-loggers                 1.0.4\n",
            "Sphinx                        3.5.4\n",
            "sphinxcontrib-applehelp       1.0.4\n",
            "sphinxcontrib-devhelp         1.0.2\n",
            "sphinxcontrib-htmlhelp        2.0.1\n",
            "sphinxcontrib-jsmath          1.0.1\n",
            "sphinxcontrib-qthelp          1.0.3\n",
            "sphinxcontrib-serializinghtml 1.1.5\n",
            "SQLAlchemy                    1.4.47\n",
            "sqlparse                      0.4.3\n",
            "srsly                         2.4.6\n",
            "statsmodels                   0.13.5\n",
            "sympy                         1.11.1\n",
            "tables                        3.7.0\n",
            "tabulate                      0.8.10\n",
            "tangled-up-in-unicode         0.2.0\n",
            "tblib                         1.7.0\n",
            "tenacity                      8.2.2\n",
            "tensorboard                   2.12.0\n",
            "tensorboard-data-server       0.7.0\n",
            "tensorboard-plugin-wit        1.8.1\n",
            "tensorflow                    2.12.0\n",
            "tensorflow-datasets           4.8.3\n",
            "tensorflow-decision-forests   0.2.0\n",
            "tensorflow-estimator          2.12.0\n",
            "tensorflow-gcs-config         2.11.0\n",
            "tensorflow-hub                0.13.0\n",
            "tensorflow-io-gcs-filesystem  0.31.0\n",
            "tensorflow-metadata           1.12.0\n",
            "tensorflow-probability        0.19.0\n",
            "termcolor                     2.2.0\n",
            "terminado                     0.17.1\n",
            "text-unidecode                1.3\n",
            "textblob                      0.17.1\n",
            "thinc                         8.1.9\n",
            "threadpoolctl                 3.1.0\n",
            "tifffile                      2023.3.15\n",
            "tinycss2                      1.2.1\n",
            "toml                          0.10.2\n",
            "tomli                         2.0.1\n",
            "toolz                         0.12.0\n",
            "torch                         1.13.1+cu116\n",
            "torchaudio                    0.13.1+cu116\n",
            "torchsummary                  1.5.1\n",
            "torchtext                     0.14.1\n",
            "torchvision                   0.14.1+cu116\n",
            "tornado                       6.2\n",
            "tqdm                          4.65.0\n",
            "traitlets                     5.7.1\n",
            "tweepy                        4.13.0\n",
            "typer                         0.7.0\n",
            "typing_extensions             4.5.0\n",
            "tzdata                        2022.7\n",
            "tzlocal                       4.3\n",
            "uritemplate                   4.1.1\n",
            "urllib3                       1.26.15\n",
            "vega-datasets                 0.9.0\n",
            "visions                       0.7.4\n",
            "wasabi                        1.1.1\n",
            "wcwidth                       0.2.6\n",
            "webencodings                  0.5.1\n",
            "Werkzeug                      2.2.3\n",
            "wheel                         0.40.0\n",
            "widgetsnbextension            3.6.2\n",
            "wordcloud                     1.8.2.2\n",
            "wrapt                         1.14.1\n",
            "xarray                        2022.12.0\n",
            "xarray-einstats               0.5.1\n",
            "xgboost                       1.7.4\n",
            "xkit                          0.0.0\n",
            "xlrd                          2.0.1\n",
            "xlwt                          1.3.0\n",
            "yellowbrick                   1.5\n",
            "zict                          2.2.0\n",
            "zipp                          3.15.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "0E_rUixg1hqx"
      },
      "outputs": [],
      "source": [
        "#@title **ðŸ“Setting Up** Directories\n",
        "#\n",
        "# functions for clipping a single raster to multiple rasters of various shapes\n",
        "from osgeo import gdal\n",
        "temp_directory = \"/content/temp/\"\n",
        "save_directory = \"/content/gdrive/MyDrive/OUT/data/data20230320inputs/\"\n",
        "!mkdir -p {temp_directory} {save_directory} \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LDjd-xzZ2qb6"
      },
      "source": [
        "##**ðŸ“œ calculation from ML model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C3H2KLBD1hqx"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "ds = gdal.Open(path_list[0])\n",
        "box_list = get_slice_bboxes(ds.RasterYSize , ds.RasterXSize)\n",
        "\n",
        "count = 0\n",
        "\n",
        "for box in box_list:\n",
        "  print(box, type(box_list))\n",
        "  count = count + 1\n",
        "  #clipping of original image to box size\n",
        "  for k in path_list:\n",
        "    here_image = k\n",
        "    print(here_image)\n",
        "    vvv = here_image[-7:-4]\n",
        "    gdal.Translate(str(temp_directory) + str(vvv) + \".\" + str(count) + '.tif', here_image , srcWin = [box[0], box[1], box[3]-box[1], box[2]-box[0]] )\n",
        "  \n",
        "\n",
        "  #>> files are of their original sizes are kept in a folder with their respective extensions as bands b1, b2, b3 , b4 , b5 ....  and kept as to be listed as image list in a variable.\n",
        "  image_dir = temp_directory\n",
        "  prefix = \"\"\n",
        "  end = [\"B11\", \"B12\", \"B02\", \"B03\", \"B04\", \"B05\", \"B06\", \"B07\", \"B8A\", \"B08\"]\n",
        "  DayOY = \"_doy\\[0-9]+_aid0001\"\n",
        "  fileExt = r'.tif'\n",
        "  expression_b1 = prefix+end[0]\n",
        "  expression_b2 = prefix+end[1]\n",
        "  expression_b3 = prefix+end[2]\n",
        "  expression_b4 = prefix+end[3]\n",
        "  expression_b5 = prefix+end[4]\n",
        "  expression_b6 = prefix+end[5]\n",
        "  expression_b7 = prefix+end[6]\n",
        "  expression_b8 = prefix+end[7]\n",
        "  expression_b9 = prefix+end[8]\n",
        "  expression_b10 = prefix+end[9]\n",
        "\n",
        "  imgs_list_b1 = [f for f in os.listdir(image_dir) if f.__contains__(expression_b1)]\n",
        "\n",
        "  imgs_list_b1.sort(reverse=True)    \n",
        "\n",
        "\n",
        "  temp_path = os.path.join(image_dir, imgs_list_b1[0])\n",
        "  temp_path_list = [temp_path.replace(expression_b1, expression_b1),\n",
        "              temp_path.replace(expression_b1, expression_b2),\n",
        "              temp_path.replace(expression_b1, expression_b3),\n",
        "              temp_path.replace(expression_b1, expression_b4),\n",
        "              temp_path.replace(expression_b1, expression_b5),\n",
        "              temp_path.replace(expression_b1, expression_b6),\n",
        "              temp_path.replace(expression_b1, expression_b7),\n",
        "              temp_path.replace(expression_b1, expression_b8),\n",
        "              temp_path.replace(expression_b1, expression_b9),\n",
        "              temp_path.replace(expression_b1, expression_b10)]\n",
        "\n",
        "  lon , lat = [] , []  \n",
        "  v1 =[]\n",
        "\n",
        "  print(box[3]-box[1], box[2]-box[0])\n",
        "\n",
        "  for i in temp_path_list:\n",
        "    pathout = i\n",
        "    print(pathout)\n",
        "    \n",
        "    if(temp_path_list.index(i)==0):\n",
        "      v1 = tif2array(pathout, 0)[0].reshape(-1,1)\n",
        "      # Open tif file\n",
        "      dsk = gdal.Open(pathout)\n",
        "      # GDAL affine transform parameters, According to gdal documentation xoff/yoff are image left corner, a/e are pixel wight/height and b/d is rotation and is zero if image is north up. \n",
        "      xoff, a, b, yoff, d, e = dsk.GetGeoTransform()\n",
        "      print(xoff, a, b, yoff, d, e)\n",
        "      def pixel2coord(x, y):\n",
        "        # \"\"Returns global coordinates from pixel x, y coords\"\"\n",
        "        xp = a * x + b * y + xoff\n",
        "        yp = d * x + e * y + yoff\n",
        "        return xp, yp\n",
        "\n",
        "      # get columns and rows of your image from gdalinfo\n",
        "      rows = dsk.RasterYSize \n",
        "      colms = dsk.RasterXSize \n",
        "      print(rows, colms)\n",
        "      for row in  range(0,rows):\n",
        "        for col in  range(0,colms): \n",
        "          lat.append(pixel2coord(col,row)[0])\n",
        "          lon.append(pixel2coord(col,row)[1])\n",
        "    else:\n",
        "      v1 = np.append(v1, tif2array(pathout, 0)[0].reshape(-1,1), axis = 1)\n",
        "  # agging latitude \"lat\" & longitde \"lon\" column at the end\n",
        "  v1 = np.column_stack((v1, np.column_stack((lat, lon))))\n",
        "\n",
        "\n",
        "  arr = v1\n",
        "\n",
        "  # convert array into dataframe\n",
        "  DF = pd.DataFrame(arr)\n",
        "  # DF.columns = d\n",
        "    # print(DF)\n",
        "  height =[]\n",
        "  print(len(height), len(DF[0]), len(arr))\n",
        "\n",
        "  for values in range(0, len(DF[0])):\n",
        "    examples = {\n",
        "    \"b11\" : [np.array(DF[0][values])],\n",
        "    \"b12\" : [np.array(DF[1][values])],\n",
        "    \"b2\" : [np.array(DF[2][values])],\n",
        "    \"b3\" : [np.array(DF[3][values])],\n",
        "    \"b4\" : [np.array(DF[4][values])],\n",
        "    \"b5\" : [np.array(DF[5][values])],\n",
        "    \"b6\" : [np.array(DF[6][values])],\n",
        "    \"b7\" : [np.array(DF[7][values])],\n",
        "    \"b8a\" : [np.array(DF[8][values])],\n",
        "    \"b8\" : [np.array(DF[9][values])],\n",
        "    \"lat\" : [np.array(DF[10][values])],\n",
        "    \"lon\" : [np.array(DF[11][values])],\n",
        "    }\n",
        "    ######################$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$<<< tensorflow model\n",
        "    \n",
        "    a = np.array(model.predict_step(examples))\n",
        "    ######################$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$<<< tensorflow model\n",
        "\n",
        "    height.append(a[0][0])\n",
        "  # print(np.asarray(height))\n",
        "  height = np.column_stack((np.column_stack((lat, lon)), height))\n",
        "  print(len(height))\n",
        "  # saving the predicted heght data to panda dataframe\n",
        "  DHeight = pd.DataFrame(height)\n",
        "  # DF.columns = d\n",
        "  # DHeight\n",
        "  # save the dataframe as a csv file\n",
        "  save_dir = \"/content/height/\"\n",
        "  !mkdir -p {save_dir}\n",
        "  DHeight.to_csv(str(save_dir) + \"height_\" + str(count) + \".csv\")\n",
        "  #delete files in temp_directory after processing\n",
        "  !rm -r {temp_directory}/*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rFhHQuue7ESc"
      },
      "outputs": [],
      "source": [
        "tfdf.model_plotter.plot_model_in_colab(model, tree_idx=0)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "e-uTZc27fBVW",
        "IGvjOhfq25Hx",
        "EaCOuudi2UCJ"
      ],
      "provenance": [],
      "authorship_tag": "ABX9TyMdMKkKh7iXouKhEXkhK2EQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}