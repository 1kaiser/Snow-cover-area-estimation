{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/1kaiser/Snow-cover-area-estimation/blob/main/tiff2array.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yPdly86dtDqc"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qKTN6C1btYsH"
      },
      "outputs": [],
      "source": [
        "!cp -r /content/gdrive/MyDrive/OUT/data/data20230320 /content/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GNadjcbGhnwN"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "image_dir = r'/content/data20230320/'\n",
        "\n",
        "#############################################################################>> files are of their original sizes are kept in a folder with their respective extensions as bands b1, b2, b3 , b4 , b5 ....  and kept as to be listed as image list in a variable.\n",
        "prefix = \"\"\n",
        "end = [\"B11\", \"B12\", \"B02\", \"B03\", \"B04\", \"B05\", \"B06\", \"B07\", \"B8A\", \"B08\"]\n",
        "DayOY = \"_doy\\[0-9]+_aid0001\"\n",
        "fileExt = r'.tif'\n",
        "expression_b1 = prefix+end[0]\n",
        "expression_b2 = prefix+end[1]\n",
        "expression_b3 = prefix+end[2]\n",
        "expression_b4 = prefix+end[3]\n",
        "expression_b5 = prefix+end[4]\n",
        "expression_b6 = prefix+end[5]\n",
        "expression_b7 = prefix+end[6]\n",
        "expression_b8 = prefix+end[7]\n",
        "expression_b9 = prefix+end[8]\n",
        "expression_b10 = prefix+end[9]\n",
        "\n",
        "imgs_list_b1 = [f for f in os.listdir(image_dir) if f.__contains__(expression_b1)]\n",
        "\n",
        "imgs_list_b1.sort(reverse=True)    \n",
        "print(imgs_list_b1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UTqVV7ENkmAy"
      },
      "outputs": [],
      "source": [
        "path = os.path.join(image_dir, imgs_list_b1[0])\n",
        "path_list = [path.replace(expression_b1, expression_b1),\n",
        "             path.replace(expression_b1, expression_b2),\n",
        "             path.replace(expression_b1, expression_b3),\n",
        "             path.replace(expression_b1, expression_b4),\n",
        "             path.replace(expression_b1, expression_b5),\n",
        "             path.replace(expression_b1, expression_b6),\n",
        "             path.replace(expression_b1, expression_b7),\n",
        "             path.replace(expression_b1, expression_b8),\n",
        "             path.replace(expression_b1, expression_b9),\n",
        "             path.replace(expression_b1, expression_b10)]\n",
        "\n",
        "path_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vJMBYkichBM8"
      },
      "outputs": [],
      "source": [
        "\n",
        "path_list[0][-7:-4]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KoOTRHJmrlKR"
      },
      "outputs": [],
      "source": [
        "#this function is for getting the four corners of all the square boxes possible out of the complete image size >>>\n",
        "def get_slice_bboxes( image_height: int, image_width: int, slice_height: int = 2000 , slice_width: int = 2000, overlap_height_ratio: float = 0.0, overlap_width_ratio: float = 0.0 ):\n",
        "  slice_bboxes = []\n",
        "  y_max = y_min = 0\n",
        "\n",
        "  if slice_height and slice_width:\n",
        "      y_overlap = int(overlap_height_ratio * slice_height)\n",
        "      x_overlap = int(overlap_width_ratio * slice_width)\n",
        "  else:\n",
        "      raise ValueError(\"Compute type is not auto and slice width and height are not provided.\")\n",
        "\n",
        "  while y_max < image_height:\n",
        "      x_min = x_max = 0\n",
        "      y_max = y_min + slice_height\n",
        "      while x_max < image_width:\n",
        "          x_max = x_min + slice_width\n",
        "          if y_max > image_height or x_max > image_width:\n",
        "              xmax = min(image_width, x_max)\n",
        "              ymax = min(image_height, y_max)\n",
        "              xmin = max(0, xmax - slice_width)\n",
        "              ymin = max(0, ymax - slice_height)\n",
        "              slice_bboxes.append([xmin, ymin, xmax, ymax])\n",
        "          else:\n",
        "              slice_bboxes.append([x_min, y_min, x_max, y_max])\n",
        "          x_min = x_max - x_overlap\n",
        "      y_min = y_max - y_overlap\n",
        "  return slice_bboxes\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-uTZc27fBVW"
      },
      "source": [
        "##extraction of clips from original image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "biq2rXg3fF3k"
      },
      "source": [
        "pre requisite"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zrFu1SXavti-"
      },
      "outputs": [],
      "source": [
        "#\n",
        "# functions for clipping a single raster to multiple rasters of various shapes\n",
        "from osgeo import gdal\n",
        "temp_directory = \"/content/temp/\"\n",
        "save_directory = \"/content/gdrive/MyDrive/OUT/data/data20230320inputs/\"\n",
        "!mkdir -p {temp_directory} {save_directory} \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "03V3tNvD1QM-"
      },
      "source": [
        "###band 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b7wm7n3i1KHA"
      },
      "outputs": [],
      "source": [
        "here_image = path_list[0]\n",
        "print(here_image)\n",
        "\n",
        "vvv = here_image[-7:-4]\n",
        "ds = gdal.Open(here_image)\n",
        "box_list = get_slice_bboxes(ds.RasterYSize , ds.RasterXSize)\n",
        "\n",
        "count = 0\n",
        "\n",
        "for box in box_list:\n",
        "  print(box, type(box_list))\n",
        "  count = count + 1\n",
        "  gdal.Translate(str(temp_directory) + str(vvv) + \".\" + str(count) + '.tif', here_image ,srcWin = box )\n",
        "  !mv {temp_directory}/* {save_directory} "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VLrHv25t1Uol"
      },
      "source": [
        "###band 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MgqW1G3H1Wvz"
      },
      "outputs": [],
      "source": [
        "here_image = path_list[1]\n",
        "print(here_image)\n",
        "\n",
        "vvv = here_image[-7:-4]\n",
        "ds = gdal.Open(here_image)\n",
        "box_list = get_slice_bboxes(ds.RasterYSize , ds.RasterXSize)\n",
        "\n",
        "count = 0\n",
        "\n",
        "for box in box_list:\n",
        "  print(box, type(box_list))\n",
        "  count = count + 1\n",
        "  gdal.Translate(str(temp_directory) + str(vvv) + \".\" + str(count) + '.tif', here_image , srcWin = box )\n",
        "  !mv {temp_directory}/* {save_directory} "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tR_V9IZM1WKc"
      },
      "source": [
        "###band 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E_I-Ixzk1a3Z"
      },
      "outputs": [],
      "source": [
        "here_image = path_list[2]\n",
        "print(here_image)\n",
        "\n",
        "vvv = here_image[-7:-4]\n",
        "ds = gdal.Open(here_image)\n",
        "box_list = get_slice_bboxes(ds.RasterYSize , ds.RasterXSize)\n",
        "\n",
        "count = 0\n",
        "\n",
        "for box in box_list:\n",
        "  print(box, type(box_list))\n",
        "  count = count + 1\n",
        "  gdal.Translate(str(temp_directory) + str(vvv) + \".\" + str(count) + '.tif', here_image ,srcWin = box )\n",
        "  !mv {temp_directory}/* {save_directory} "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DPR_VjGe2L3-"
      },
      "source": [
        "###band 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jqeno17U2LTL"
      },
      "outputs": [],
      "source": [
        "here_image = path_list[3]\n",
        "print(here_image)\n",
        "\n",
        "vvv = here_image[-7:-4]\n",
        "ds = gdal.Open(here_image)\n",
        "box_list = get_slice_bboxes(ds.RasterYSize , ds.RasterXSize)\n",
        "\n",
        "count = 0\n",
        "\n",
        "for box in box_list:\n",
        "  print(box, type(box_list))\n",
        "  count = count + 1\n",
        "  gdal.Translate(str(temp_directory) + str(vvv) + \".\" + str(count) + '.tif', here_image ,srcWin = box )\n",
        "  !mv {temp_directory}/* {save_directory} "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9oaEGMPM2SJ-"
      },
      "source": [
        "###band 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u9EO93G72Tk5"
      },
      "outputs": [],
      "source": [
        "here_image = path_list[4]\n",
        "print(here_image)\n",
        "\n",
        "vvv = here_image[-7:-4]\n",
        "ds = gdal.Open(here_image)\n",
        "box_list = get_slice_bboxes(ds.RasterYSize , ds.RasterXSize)\n",
        "\n",
        "count = 0\n",
        "\n",
        "for box in box_list:\n",
        "  print(box, type(box_list))\n",
        "  count = count + 1\n",
        "  gdal.Translate(str(temp_directory) + str(vvv) + \".\" + str(count) + '.tif', here_image ,srcWin = box )\n",
        "  !mv {temp_directory}/* {save_directory} "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NkrfYdV42VSZ"
      },
      "source": [
        "###band 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-pazktaj2Wp1"
      },
      "outputs": [],
      "source": [
        "here_image = path_list[5]\n",
        "print(here_image)\n",
        "\n",
        "vvv = here_image[-7:-4]\n",
        "ds = gdal.Open(here_image)\n",
        "box_list = get_slice_bboxes(ds.RasterYSize , ds.RasterXSize)\n",
        "\n",
        "count = 0\n",
        "\n",
        "for box in box_list:\n",
        "  print(box, type(box_list))\n",
        "  count = count + 1\n",
        "  gdal.Translate(str(temp_directory) + str(vvv) + \".\" + str(count) + '.tif', here_image ,srcWin = box )\n",
        "  !mv {temp_directory}/* {save_directory} "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_e40XDPN2gEX"
      },
      "source": [
        "###band 6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n2I0dHcK2frI"
      },
      "outputs": [],
      "source": [
        "here_image = path_list[6]\n",
        "print(here_image)\n",
        "\n",
        "vvv = here_image[-7:-4]\n",
        "ds = gdal.Open(here_image)\n",
        "box_list = get_slice_bboxes(ds.RasterYSize , ds.RasterXSize)\n",
        "\n",
        "count = 0\n",
        "\n",
        "for box in box_list:\n",
        "  print(box, type(box_list))\n",
        "  count = count + 1\n",
        "  gdal.Translate(str(temp_directory) + str(vvv) + \".\" + str(count) + '.tif', here_image ,srcWin = box )\n",
        "  !mv {temp_directory}/* {save_directory} "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0QkYs09O2kZV"
      },
      "source": [
        "###band 7"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NZD5h3u02leQ"
      },
      "outputs": [],
      "source": [
        "here_image = path_list[7]\n",
        "print(here_image)\n",
        "\n",
        "vvv = here_image[-7:-4]\n",
        "ds = gdal.Open(here_image)\n",
        "box_list = get_slice_bboxes(ds.RasterYSize , ds.RasterXSize)\n",
        "\n",
        "count = 0\n",
        "\n",
        "for box in box_list:\n",
        "  print(box, type(box_list))\n",
        "  count = count + 1\n",
        "  gdal.Translate(str(temp_directory) + str(vvv) + \".\" + str(count) + '.tif', here_image ,srcWin = box )\n",
        "  !mv {temp_directory}/* {save_directory} "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ff8eG_Ja2nJn"
      },
      "source": [
        "###band 8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iSONd7M62oTU"
      },
      "outputs": [],
      "source": [
        "here_image = path_list[8]\n",
        "print(here_image)\n",
        "\n",
        "vvv = here_image[-7:-4]\n",
        "ds = gdal.Open(here_image)\n",
        "box_list = get_slice_bboxes(ds.RasterYSize , ds.RasterXSize)\n",
        "\n",
        "count = 0\n",
        "\n",
        "for box in box_list:\n",
        "  print(box, type(box_list))\n",
        "  count = count + 1\n",
        "  gdal.Translate(str(temp_directory) + str(vvv) + \".\" + str(count) + '.tif', here_image ,srcWin = box )\n",
        "  !mv {temp_directory}/* {save_directory} "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YX3UVG702p6Q"
      },
      "source": [
        "###band 9"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wGOb_VRX2rRO"
      },
      "outputs": [],
      "source": [
        "here_image = path_list[9]\n",
        "print(here_image)\n",
        "\n",
        "vvv = here_image[-7:-4]\n",
        "ds = gdal.Open(here_image)\n",
        "box_list = get_slice_bboxes(ds.RasterYSize , ds.RasterXSize)\n",
        "\n",
        "count = 0\n",
        "\n",
        "for box in box_list:\n",
        "  print(box, type(box_list))\n",
        "  count = count + 1\n",
        "  gdal.Translate(str(temp_directory) + str(vvv) + \".\" + str(count) + '.tif', here_image ,srcWin = box )\n",
        "  !mv {temp_directory}/* {save_directory} "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IGvjOhfq25Hx"
      },
      "source": [
        "## tensorflow band data extraction from model created from google sheets "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3lUV96TiqTux"
      },
      "outputs": [],
      "source": [
        "#\n",
        "#$$$$$$$$$$$$$$$$$%%%%%%%%%%%%%% tif2raster\n",
        "#\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import os.path\n",
        "import re\n",
        "\n",
        "from osgeo import gdal\n",
        "from osgeo import gdal_array\n",
        "from osgeo import osr\n",
        "\n",
        "def get_gain_band(input_file):\n",
        "    \"\"\"get GAIN_BAND from meta file (*.tif.txt)\"\"\"\n",
        "     # define file name of *.tif.txt\n",
        "    ifile_txt = re.sub(r'.tif', '.tif.txt', input_file)\n",
        "    ld = open(ifile_txt)\n",
        "    lines = ld.readlines()\n",
        "    ld.close()\n",
        "    \n",
        "    gain_band = []\n",
        "    for line in lines:\n",
        "        if line.find(\"GAIN_BAND\") >= 0:\n",
        "             gain_band.append(float((re.split(' ', line)[1]).strip()))\n",
        "    return gain_band\n",
        "\n",
        "def tif2array(input_file, calc_gain=True):\n",
        "    \"\"\"\n",
        "    read GeoTiff and convert to numpy.ndarray.\n",
        "    Inputs:\n",
        "        input_file (str) : the name of input GeoTiff file.\n",
        "        calc_gain (bool) : wheter calc GAIN to DN  or not (defaul:True).\n",
        "    return:\n",
        "        image(np.array) : image for each bands\n",
        "        dataset : for gdal's data drive.\n",
        "    \"\"\"\n",
        "    dataset = gdal.Open(input_file, gdal.GA_ReadOnly)\n",
        "    # Allocate our array using the first band's datatype\n",
        "    image_datatype = dataset.GetRasterBand(1).DataType\n",
        "    image = np.zeros((dataset.RasterYSize, dataset.RasterXSize, dataset.RasterCount),\n",
        "                     dtype=float)\n",
        "    \n",
        "    if calc_gain == True:\n",
        "        # get gain\n",
        "        gain = get_gain_band(input_file)\n",
        "    \n",
        "    # Loop over all bands in dataset\n",
        "    for b in range(dataset.RasterCount):\n",
        "        # Remember, GDAL index is on 1, but Python is on 0 -- so we add 1 for our GDAL calls\n",
        "        band = dataset.GetRasterBand(b + 1)\n",
        "        # Read in the band's data into the third dimension of our array\n",
        "        if calc_gain == True:\n",
        "            # calc gain value for each bands\n",
        "            image[:, :, b] = band.ReadAsArray() * gain[b]\n",
        "        else:\n",
        "            image[:, :, b] = band.ReadAsArray()\n",
        "    return image, dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CbZUMzKd_PO-"
      },
      "source": [
        "setting up for tif2array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4p1zGV-z-jWr"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "image_dir = r'/content/gdrive/MyDrive/OUT/data/data20230320inputs/'\n",
        "\n",
        "#############################################################################>> files are of their original sizes are kept in a folder with their respective extensions as bands b1, b2, b3 , b4 , b5 ....  and kept as to be listed as image list in a variable.\n",
        "prefix = \"\"\n",
        "end = [\"B11\", \"B12\", \"B02\", \"B03\", \"B04\", \"B05\", \"B06\", \"B07\", \"B8A\", \"B08\"]\n",
        "DayOY = \"_doy\\[0-9]+_aid0001\"\n",
        "fileExt = r'.tif'\n",
        "expression_b1 = prefix+end[0]\n",
        "expression_b2 = prefix+end[1]\n",
        "expression_b3 = prefix+end[2]\n",
        "expression_b4 = prefix+end[3]\n",
        "expression_b5 = prefix+end[4]\n",
        "expression_b6 = prefix+end[5]\n",
        "expression_b7 = prefix+end[6]\n",
        "expression_b8 = prefix+end[7]\n",
        "expression_b9 = prefix+end[8]\n",
        "expression_b10 = prefix+end[9]\n",
        "\n",
        "imgs_list_b1 = [f for f in os.listdir(image_dir) if f.__contains__(expression_b1)]\n",
        "\n",
        "imgs_list_b1.sort(reverse=True)    \n",
        "print(imgs_list_b1)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qmznxvEmjXoF"
      },
      "outputs": [],
      "source": [
        "#extraction of band values from clips to DATAFRAME for to be processing inside the model\n",
        "\n",
        "from osgeo import gdal\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "######################$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$<<< tensorflow model\n",
        "#Copy and execute the following code in a new Google Colab notebook launch to run the model.\n",
        "!python -m pip install tensorflow tensorflow_decision_forests -U -qq\n",
        "\n",
        "# Transfer the model from Google Drive to Colab\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\")\n",
        "!cp \"/content/gdrive/My Drive/simple_ml_for_sheets/Ice height from bands\" ydf_model\n",
        "  \n",
        "# Prepare and load the model with TensorFlow\n",
        "import tensorflow as tf\n",
        "import tensorflow_decision_forests as tfdf\n",
        "\n",
        "tfdf.keras.yggdrasil_model_to_keras_model(\"ydf_model\", \"tfdf_model\")\n",
        "model = tf.keras.models.load_model(\"tfdf_model\")\n",
        "######################$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$<<< tensorflow model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2512KHSgEqrJ"
      },
      "outputs": [],
      "source": [
        "path = os.path.join(image_dir, imgs_list_b1[6])\n",
        "path_list = [path.replace(expression_b1, expression_b1),\n",
        "            path.replace(expression_b1, expression_b2),\n",
        "            path.replace(expression_b1, expression_b3),\n",
        "            path.replace(expression_b1, expression_b4),\n",
        "            path.replace(expression_b1, expression_b5),\n",
        "            path.replace(expression_b1, expression_b6),\n",
        "            path.replace(expression_b1, expression_b7),\n",
        "            path.replace(expression_b1, expression_b8),\n",
        "            path.replace(expression_b1, expression_b9),\n",
        "            path.replace(expression_b1, expression_b10)]\n",
        "path_list[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4dcId8Lbl9E9"
      },
      "outputs": [],
      "source": [
        "!cp -r {path_list[0]} /content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mPkE6j0QjBPH"
      },
      "outputs": [],
      "source": [
        "os.path.getsize(path_list[10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zj0a0QuMgMcA"
      },
      "outputs": [],
      "source": [
        "for image_no in range(0, len(imgs_list_b1)):\n",
        "  path = os.path.join(image_dir, imgs_list_b1[image_no])\n",
        "  path_list = [path.replace(expression_b1, expression_b1),\n",
        "              path.replace(expression_b1, expression_b2),\n",
        "              path.replace(expression_b1, expression_b3),\n",
        "              path.replace(expression_b1, expression_b4),\n",
        "              path.replace(expression_b1, expression_b5),\n",
        "              path.replace(expression_b1, expression_b6),\n",
        "              path.replace(expression_b1, expression_b7),\n",
        "              path.replace(expression_b1, expression_b8),\n",
        "              path.replace(expression_b1, expression_b9),\n",
        "              path.replace(expression_b1, expression_b10)]\n",
        "\n",
        "  print(path_list)\n",
        "  for i in path_list:\n",
        "    os.path.getsize(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PyRqQ37pLHS7"
      },
      "outputs": [],
      "source": [
        "gdal.Open(path_list[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "24qshMGyLEgb"
      },
      "outputs": [],
      "source": [
        "v1 = tif2array(\"/content/gdrive/MyDrive/OUT/data/data20230320inputs/B03.6.tif\", 0)[0].reshape(-1,1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YwKtSRMqxW1P"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "for image_no in range(0, len(imgs_list_b1)):\n",
        "  path = os.path.join(image_dir, imgs_list_b1[image_no])\n",
        "  path_list = [path.replace(expression_b1, expression_b1),\n",
        "              path.replace(expression_b1, expression_b2),\n",
        "              path.replace(expression_b1, expression_b3),\n",
        "              path.replace(expression_b1, expression_b4),\n",
        "              path.replace(expression_b1, expression_b5),\n",
        "              path.replace(expression_b1, expression_b6),\n",
        "              path.replace(expression_b1, expression_b7),\n",
        "              path.replace(expression_b1, expression_b8),\n",
        "              path.replace(expression_b1, expression_b9),\n",
        "              path.replace(expression_b1, expression_b10)]\n",
        "\n",
        "  lon , lat = [] , []  \n",
        "  v1 =[]\n",
        "\n",
        "  for i in path_list:\n",
        "    pathout = i\n",
        "    print(pathout)\n",
        "    \n",
        "    if(path_list.index(i)==0):\n",
        "      v1 = tif2array(pathout, 0)[0].reshape(-1,1)\n",
        "      # Open tif file\n",
        "      ds = gdal.Open(pathout)\n",
        "      # GDAL affine transform parameters, According to gdal documentation xoff/yoff are image left corner, a/e are pixel wight/height and b/d is rotation and is zero if image is north up. \n",
        "      xoff, a, b, yoff, d, e = ds.GetGeoTransform()\n",
        "      print(xoff, a, b, yoff, d, e)\n",
        "      def pixel2coord(x, y):\n",
        "        # \"\"Returns global coordinates from pixel x, y coords\"\"\n",
        "        xp = a * x + b * y + xoff\n",
        "        yp = d * x + e * y + yoff\n",
        "        return xp, yp\n",
        "\n",
        "      # get columns and rows of your image from gdalinfo\n",
        "      rows = ds.RasterYSize \n",
        "      colms = ds.RasterXSize \n",
        "      for row in  range(0,rows):\n",
        "        for col in  range(0,colms): \n",
        "          lat.append(pixel2coord(col,row)[0])\n",
        "          lon.append(pixel2coord(col,row)[1])\n",
        "    else:\n",
        "      v1 = np.append(v1, tif2array(pathout, 0)[0].reshape(-1,1), axis = 1)\n",
        "  # agging latitude \"lat\" & longitde \"lon\" column at the end\n",
        "  v1 = np.column_stack((v1, np.column_stack((lat, lon))))\n",
        "\n",
        "\n",
        "  arr = v1\n",
        "  # convert array into dataframe\n",
        "  DF = pd.DataFrame(arr)\n",
        "  # DF.columns = d\n",
        "    # print(DF)\n",
        "  height =[]\n",
        "  for values in range(0, len(DF[0])):\n",
        "    examples = {\n",
        "    \"b11\" : [np.array(DF[0][values])],\n",
        "    \"b12\" : [np.array(DF[1][values])],\n",
        "    \"b2\" : [np.array(DF[2][values])],\n",
        "    \"b3\" : [np.array(DF[3][values])],\n",
        "    \"b4\" : [np.array(DF[4][values])],\n",
        "    \"b5\" : [np.array(DF[5][values])],\n",
        "    \"b6\" : [np.array(DF[6][values])],\n",
        "    \"b7\" : [np.array(DF[7][values])],\n",
        "    \"b8a\" : [np.array(DF[8][values])],\n",
        "    \"b8\" : [np.array(DF[9][values])],\n",
        "    \"lat\" : [np.array(DF[10][values])],\n",
        "    \"lon\" : [np.array(DF[11][values])],\n",
        "    }\n",
        "######################$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$<<< tensorflow model\n",
        "\n",
        "    a = np.array(model.predict_step(examples))\n",
        "######################$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$<<< tensorflow model\n",
        "\n",
        "    height.append(a[0][0])\n",
        "  print(np.asarray(height))\n",
        "  print(height)\n",
        "  height = np.column_stack((np.column_stack((lat, lon)), height))\n",
        "  # saving the predicted heght data to panda dataframe\n",
        "  DHeight = pd.DataFrame(height)\n",
        "  # DF.columns = d\n",
        "  DHeight\n",
        "  # save the dataframe as a csv file\n",
        "  DHeight.to_csv(\"height_\" + str(image_no) + \".csv\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C_iDHZ121eNv"
      },
      "source": [
        "# final processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EaCOuudi2UCJ"
      },
      "source": [
        "##**💽 google drive connection**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VNIB-zUW2PjJ"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MbDz761i2PjK"
      },
      "outputs": [],
      "source": [
        "!cp -r /content/gdrive/MyDrive/OUT/data/data20230320 /content/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_5VIz4CW2PjK"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "image_dir = r'/content/data20230320/'\n",
        "\n",
        "#############################################################################>> files are of their original sizes are kept in a folder with their respective extensions as bands b1, b2, b3 , b4 , b5 ....  and kept as to be listed as image list in a variable.\n",
        "prefix = \"\"\n",
        "end = [\"B11\", \"B12\", \"B02\", \"B03\", \"B04\", \"B05\", \"B06\", \"B07\", \"B8A\", \"B08\"]\n",
        "DayOY = \"_doy\\[0-9]+_aid0001\"\n",
        "fileExt = r'.tif'\n",
        "expression_b1 = prefix+end[0]\n",
        "expression_b2 = prefix+end[1]\n",
        "expression_b3 = prefix+end[2]\n",
        "expression_b4 = prefix+end[3]\n",
        "expression_b5 = prefix+end[4]\n",
        "expression_b6 = prefix+end[5]\n",
        "expression_b7 = prefix+end[6]\n",
        "expression_b8 = prefix+end[7]\n",
        "expression_b9 = prefix+end[8]\n",
        "expression_b10 = prefix+end[9]\n",
        "\n",
        "imgs_list_b1 = [f for f in os.listdir(image_dir) if f.__contains__(expression_b1)]\n",
        "\n",
        "imgs_list_b1.sort(reverse=True)    \n",
        "print(imgs_list_b1)\n",
        "\n",
        "path = os.path.join(image_dir, imgs_list_b1[0])\n",
        "path_list = [path.replace(expression_b1, expression_b1),\n",
        "             path.replace(expression_b1, expression_b2),\n",
        "             path.replace(expression_b1, expression_b3),\n",
        "             path.replace(expression_b1, expression_b4),\n",
        "             path.replace(expression_b1, expression_b5),\n",
        "             path.replace(expression_b1, expression_b6),\n",
        "             path.replace(expression_b1, expression_b7),\n",
        "             path.replace(expression_b1, expression_b8),\n",
        "             path.replace(expression_b1, expression_b9),\n",
        "             path.replace(expression_b1, expression_b10)]\n",
        "\n",
        "path_list"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sSLCc1yf2dm5"
      },
      "source": [
        "##**🌟loading prequisites**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z2IIkkAf1hqx"
      },
      "outputs": [],
      "source": [
        "#@title **pre** requisite funcrions **1️⃣tif2array, 2️⃣get_slice_bboxes**\n",
        "#\n",
        "#$$$$$$$$$$$$$$$$$%%%%%%%%%%%%%% tif2raster\n",
        "#\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import os.path\n",
        "import re\n",
        "\n",
        "from osgeo import gdal\n",
        "from osgeo import gdal_array\n",
        "from osgeo import osr\n",
        "\n",
        "def get_gain_band(input_file):\n",
        "    \"\"\"get GAIN_BAND from meta file (*.tif.txt)\"\"\"\n",
        "     # define file name of *.tif.txt\n",
        "    ifile_txt = re.sub(r'.tif', '.tif.txt', input_file)\n",
        "    ld = open(ifile_txt)\n",
        "    lines = ld.readlines()\n",
        "    ld.close()\n",
        "    \n",
        "    gain_band = []\n",
        "    for line in lines:\n",
        "        if line.find(\"GAIN_BAND\") >= 0:\n",
        "             gain_band.append(float((re.split(' ', line)[1]).strip()))\n",
        "    return gain_band\n",
        "\n",
        "def tif2array(input_file, calc_gain=True):\n",
        "    \"\"\"\n",
        "    read GeoTiff and convert to numpy.ndarray.\n",
        "    Inputs:\n",
        "        input_file (str) : the name of input GeoTiff file.\n",
        "        calc_gain (bool) : wheter calc GAIN to DN  or not (defaul:True).\n",
        "    return:\n",
        "        image(np.array) : image for each bands\n",
        "        dataset : for gdal's data drive.\n",
        "    \"\"\"\n",
        "    dataset = gdal.Open(input_file, gdal.GA_ReadOnly)\n",
        "    # Allocate our array using the first band's datatype\n",
        "    image_datatype = dataset.GetRasterBand(1).DataType\n",
        "    image = np.zeros((dataset.RasterYSize, dataset.RasterXSize, dataset.RasterCount),\n",
        "                     dtype=float)\n",
        "    \n",
        "    if calc_gain == True:\n",
        "        # get gain\n",
        "        gain = get_gain_band(input_file)\n",
        "    \n",
        "    # Loop over all bands in dataset\n",
        "    for b in range(dataset.RasterCount):\n",
        "        # Remember, GDAL index is on 1, but Python is on 0 -- so we add 1 for our GDAL calls\n",
        "        band = dataset.GetRasterBand(b + 1)\n",
        "        # Read in the band's data into the third dimension of our array\n",
        "        if calc_gain == True:\n",
        "            # calc gain value for each bands\n",
        "            image[:, :, b] = band.ReadAsArray() * gain[b]\n",
        "        else:\n",
        "            image[:, :, b] = band.ReadAsArray()\n",
        "    return image, dataset\n",
        "\n",
        "#this function is for getting the four corners of all the square boxes possible out of the complete image size >>>\n",
        "def get_slice_bboxes( image_height: int, image_width: int, slice_height: int = 10 , slice_width: int = 10, overlap_height_ratio: float = 0.0, overlap_width_ratio: float = 0.0 ):\n",
        "  slice_bboxes = []\n",
        "  y_max = y_min = 0\n",
        "\n",
        "  if slice_height and slice_width:\n",
        "      y_overlap = int(overlap_height_ratio * slice_height)\n",
        "      x_overlap = int(overlap_width_ratio * slice_width)\n",
        "  else:\n",
        "      raise ValueError(\"Compute type is not auto and slice width and height are not provided.\")\n",
        "\n",
        "  while y_max < image_height:\n",
        "      x_min = x_max = 0\n",
        "      y_max = y_min + slice_height\n",
        "      while x_max < image_width:\n",
        "          x_max = x_min + slice_width\n",
        "          if y_max > image_height or x_max > image_width:\n",
        "              xmax = min(image_width, x_max)\n",
        "              ymax = min(image_height, y_max)\n",
        "              xmin = max(0, xmax - slice_width)\n",
        "              ymin = max(0, ymax - slice_height)\n",
        "              slice_bboxes.append([xmin, ymin, xmax, ymax])\n",
        "          else:\n",
        "              slice_bboxes.append([x_min, y_min, x_max, y_max])\n",
        "          x_min = x_max - x_overlap\n",
        "      y_min = y_max - y_overlap\n",
        "  return slice_bboxes\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "xAPZQNU91hqx"
      },
      "outputs": [],
      "source": [
        "#@title **🎛️** Tensorflow  **tensorflow_decision_forests**  library loading\n",
        "#extraction of band values from clips to DATAFRAME for to be processing inside the model\n",
        "\n",
        "from osgeo import gdal\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "######################$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$<<< tensorflow model\n",
        "#Copy and execute the following code in a new Google Colab notebook launch to run the model.\n",
        "!python -m pip install tensorflow tensorflow_decision_forests -U -qq\n",
        "\n",
        "# Transfer the model from Google Drive to Colab\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\")\n",
        "!cp \"/content/gdrive/My Drive/simple_ml_for_sheets/Ice height from bands\" ydf_model\n",
        "  \n",
        "# Prepare and load the model with TensorFlow\n",
        "import tensorflow as tf\n",
        "import tensorflow_decision_forests as tfdf\n",
        "\n",
        "tfdf.keras.yggdrasil_model_to_keras_model(\"ydf_model\", \"tfdf_model\")\n",
        "model = tf.keras.models.load_model(\"tfdf_model\")\n",
        "######################$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$<<< tensorflow model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "0E_rUixg1hqx"
      },
      "outputs": [],
      "source": [
        "#@title **📐Setting Up** Directories\n",
        "#\n",
        "# functions for clipping a single raster to multiple rasters of various shapes\n",
        "from osgeo import gdal\n",
        "temp_directory = \"/content/temp/\"\n",
        "save_directory = \"/content/gdrive/MyDrive/OUT/data/data20230320inputs/\"\n",
        "!mkdir -p {temp_directory} {save_directory} \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LDjd-xzZ2qb6"
      },
      "source": [
        "##**📜 calculation from ML model**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "get_slice_bboxes(20,20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0NNvZj2hj3OX",
        "outputId": "1ad57574-f94c-4856-a834-8e4a9321f02c"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[0, 0, 10, 10], [10, 0, 20, 10], [0, 10, 10, 20], [10, 10, 20, 20]]"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "C3H2KLBD1hqx",
        "outputId": "23c9a02b-36a1-4054-e25a-328e763df4e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0, 0, 10, 10] <class 'list'>\n",
            "/content/data20230320/download.B11.tif\n",
            "/content/data20230320/download.B12.tif\n",
            "/content/data20230320/download.B02.tif\n",
            "/content/data20230320/download.B03.tif\n",
            "/content/data20230320/download.B04.tif\n",
            "/content/data20230320/download.B05.tif\n",
            "/content/data20230320/download.B06.tif\n",
            "/content/data20230320/download.B07.tif\n",
            "/content/data20230320/download.B8A.tif\n",
            "/content/data20230320/download.B08.tif\n",
            "/content/temp/B11.6.tif\n",
            "75.98417797030655 8.983152841195216e-05 0.0 32.41678500579388 0.0 -8.9831528411952e-05\n",
            "10 60\n",
            "/content/temp/B12.6.tif\n",
            "/content/temp/B02.6.tif\n",
            "/content/temp/B03.6.tif\n",
            "/content/temp/B04.6.tif\n",
            "/content/temp/B05.6.tif\n",
            "/content/temp/B06.6.tif\n",
            "/content/temp/B07.6.tif\n",
            "/content/temp/B8A.6.tif\n",
            "/content/temp/B08.6.tif\n",
            "0 600 600\n",
            "600\n",
            "[10, 0, 20, 10] <class 'list'>\n",
            "/content/data20230320/download.B11.tif\n",
            "/content/data20230320/download.B12.tif\n",
            "/content/data20230320/download.B02.tif\n",
            "/content/data20230320/download.B03.tif\n",
            "/content/data20230320/download.B04.tif\n",
            "/content/data20230320/download.B05.tif\n",
            "/content/data20230320/download.B06.tif\n",
            "/content/data20230320/download.B07.tif\n",
            "/content/data20230320/download.B8A.tif\n",
            "/content/data20230320/download.B08.tif\n",
            "/content/temp/B11.2.tif\n",
            "75.98058470917007 8.983152841195216e-05 0.0 32.41678500579388 0.0 -8.9831528411952e-05\n",
            "10 20\n",
            "/content/temp/B12.2.tif\n",
            "/content/temp/B02.2.tif\n",
            "/content/temp/B03.2.tif\n",
            "/content/temp/B04.2.tif\n",
            "/content/temp/B05.2.tif\n",
            "/content/temp/B06.2.tif\n",
            "/content/temp/B07.2.tif\n",
            "/content/temp/B8A.2.tif\n",
            "/content/temp/B08.2.tif\n",
            "0 200 200\n",
            "200\n",
            "[20, 0, 30, 10] <class 'list'>\n",
            "/content/data20230320/download.B11.tif\n",
            "/content/data20230320/download.B12.tif\n",
            "/content/data20230320/download.B02.tif\n",
            "/content/data20230320/download.B03.tif\n",
            "/content/data20230320/download.B04.tif\n",
            "/content/data20230320/download.B05.tif\n",
            "/content/data20230320/download.B06.tif\n",
            "/content/data20230320/download.B07.tif\n",
            "/content/data20230320/download.B8A.tif\n",
            "/content/data20230320/download.B08.tif\n",
            "/content/temp/B11.3.tif\n",
            "75.98148302445419 8.983152841195216e-05 0.0 32.41678500579388 0.0 -8.9831528411952e-05\n",
            "10 30\n",
            "/content/temp/B12.3.tif\n",
            "/content/temp/B02.3.tif\n",
            "/content/temp/B03.3.tif\n",
            "/content/temp/B04.3.tif\n",
            "/content/temp/B05.3.tif\n",
            "/content/temp/B06.3.tif\n",
            "/content/temp/B07.3.tif\n",
            "/content/temp/B8A.3.tif\n",
            "/content/temp/B08.3.tif\n",
            "0 300 300\n",
            "300\n",
            "[30, 0, 40, 10] <class 'list'>\n",
            "/content/data20230320/download.B11.tif\n",
            "/content/data20230320/download.B12.tif\n",
            "/content/data20230320/download.B02.tif\n",
            "/content/data20230320/download.B03.tif\n",
            "/content/data20230320/download.B04.tif\n",
            "/content/data20230320/download.B05.tif\n",
            "/content/data20230320/download.B06.tif\n",
            "/content/data20230320/download.B07.tif\n",
            "/content/data20230320/download.B8A.tif\n",
            "/content/data20230320/download.B08.tif\n",
            "/content/temp/B11.4.tif\n",
            "75.98238133973831 8.983152841195216e-05 0.0 32.41678500579388 0.0 -8.9831528411952e-05\n",
            "10 40\n",
            "/content/temp/B12.4.tif\n",
            "/content/temp/B02.4.tif\n",
            "/content/temp/B03.4.tif\n",
            "/content/temp/B04.4.tif\n",
            "/content/temp/B05.4.tif\n",
            "/content/temp/B06.4.tif\n",
            "/content/temp/B07.4.tif\n",
            "/content/temp/B8A.4.tif\n",
            "/content/temp/B08.4.tif\n",
            "0 400 400\n",
            "400\n",
            "[40, 0, 50, 10] <class 'list'>\n",
            "/content/data20230320/download.B11.tif\n",
            "/content/data20230320/download.B12.tif\n",
            "/content/data20230320/download.B02.tif\n",
            "/content/data20230320/download.B03.tif\n",
            "/content/data20230320/download.B04.tif\n",
            "/content/data20230320/download.B05.tif\n",
            "/content/data20230320/download.B06.tif\n",
            "/content/data20230320/download.B07.tif\n",
            "/content/data20230320/download.B8A.tif\n",
            "/content/data20230320/download.B08.tif\n",
            "/content/temp/B11.5.tif\n",
            "75.98327965502243 8.983152841195216e-05 0.0 32.41678500579388 0.0 -8.9831528411952e-05\n",
            "10 50\n",
            "/content/temp/B12.5.tif\n",
            "/content/temp/B02.5.tif\n",
            "/content/temp/B03.5.tif\n",
            "/content/temp/B04.5.tif\n",
            "/content/temp/B05.5.tif\n",
            "/content/temp/B06.5.tif\n",
            "/content/temp/B07.5.tif\n",
            "/content/temp/B8A.5.tif\n",
            "/content/temp/B08.5.tif\n",
            "0 500 500\n",
            "500\n",
            "[50, 0, 60, 10] <class 'list'>\n",
            "/content/data20230320/download.B11.tif\n",
            "/content/data20230320/download.B12.tif\n",
            "/content/data20230320/download.B02.tif\n",
            "/content/data20230320/download.B03.tif\n",
            "/content/data20230320/download.B04.tif\n",
            "/content/data20230320/download.B05.tif\n",
            "/content/data20230320/download.B06.tif\n",
            "/content/data20230320/download.B07.tif\n",
            "/content/data20230320/download.B8A.tif\n",
            "/content/data20230320/download.B08.tif\n",
            "/content/temp/B11.6.tif\n",
            "75.98417797030655 8.983152841195216e-05 0.0 32.41678500579388 0.0 -8.9831528411952e-05\n",
            "10 60\n",
            "/content/temp/B12.6.tif\n",
            "/content/temp/B02.6.tif\n",
            "/content/temp/B03.6.tif\n",
            "/content/temp/B04.6.tif\n",
            "/content/temp/B05.6.tif\n",
            "/content/temp/B06.6.tif\n",
            "/content/temp/B07.6.tif\n",
            "/content/temp/B8A.6.tif\n",
            "/content/temp/B08.6.tif\n",
            "0 600 600\n",
            "600\n",
            "[60, 0, 70, 10] <class 'list'>\n",
            "/content/data20230320/download.B11.tif\n",
            "/content/data20230320/download.B12.tif\n",
            "/content/data20230320/download.B02.tif\n",
            "/content/data20230320/download.B03.tif\n",
            "/content/data20230320/download.B04.tif\n",
            "/content/data20230320/download.B05.tif\n",
            "/content/data20230320/download.B06.tif\n",
            "/content/data20230320/download.B07.tif\n",
            "/content/data20230320/download.B8A.tif\n",
            "/content/data20230320/download.B08.tif\n",
            "/content/temp/B11.7.tif\n",
            "75.98507628559068 8.983152841195216e-05 0.0 32.41678500579388 0.0 -8.9831528411952e-05\n",
            "10 70\n",
            "/content/temp/B12.7.tif\n",
            "/content/temp/B02.7.tif\n",
            "/content/temp/B03.7.tif\n",
            "/content/temp/B04.7.tif\n",
            "/content/temp/B05.7.tif\n",
            "/content/temp/B06.7.tif\n",
            "/content/temp/B07.7.tif\n",
            "/content/temp/B8A.7.tif\n",
            "/content/temp/B08.7.tif\n",
            "0 700 700\n",
            "700\n",
            "[70, 0, 80, 10] <class 'list'>\n",
            "/content/data20230320/download.B11.tif\n",
            "/content/data20230320/download.B12.tif\n",
            "/content/data20230320/download.B02.tif\n",
            "/content/data20230320/download.B03.tif\n",
            "/content/data20230320/download.B04.tif\n",
            "/content/data20230320/download.B05.tif\n",
            "/content/data20230320/download.B06.tif\n",
            "/content/data20230320/download.B07.tif\n",
            "/content/data20230320/download.B8A.tif\n",
            "/content/data20230320/download.B08.tif\n",
            "/content/temp/B11.8.tif\n",
            "75.9859746008748 8.983152841195216e-05 0.0 32.41678500579388 0.0 -8.9831528411952e-05\n",
            "10 80\n",
            "/content/temp/B12.8.tif\n",
            "/content/temp/B02.8.tif\n",
            "/content/temp/B03.8.tif\n",
            "/content/temp/B04.8.tif\n",
            "/content/temp/B05.8.tif\n",
            "/content/temp/B06.8.tif\n",
            "/content/temp/B07.8.tif\n",
            "/content/temp/B8A.8.tif\n",
            "/content/temp/B08.8.tif\n",
            "0 800 800\n",
            "800\n",
            "[80, 0, 90, 10] <class 'list'>\n",
            "/content/data20230320/download.B11.tif\n",
            "/content/data20230320/download.B12.tif\n",
            "/content/data20230320/download.B02.tif\n",
            "/content/data20230320/download.B03.tif\n",
            "/content/data20230320/download.B04.tif\n",
            "/content/data20230320/download.B05.tif\n",
            "/content/data20230320/download.B06.tif\n",
            "/content/data20230320/download.B07.tif\n",
            "/content/data20230320/download.B8A.tif\n",
            "/content/data20230320/download.B08.tif\n",
            "/content/temp/B11.9.tif\n",
            "75.98687291615892 8.983152841195216e-05 0.0 32.41678500579388 0.0 -8.9831528411952e-05\n",
            "10 90\n",
            "/content/temp/B12.9.tif\n",
            "/content/temp/B02.9.tif\n",
            "/content/temp/B03.9.tif\n",
            "/content/temp/B04.9.tif\n",
            "/content/temp/B05.9.tif\n",
            "/content/temp/B06.9.tif\n",
            "/content/temp/B07.9.tif\n",
            "/content/temp/B8A.9.tif\n",
            "/content/temp/B08.9.tif\n",
            "0 900 900\n",
            "900\n",
            "[90, 0, 100, 10] <class 'list'>\n",
            "/content/data20230320/download.B11.tif\n",
            "/content/data20230320/download.B12.tif\n",
            "/content/data20230320/download.B02.tif\n",
            "/content/data20230320/download.B03.tif\n",
            "/content/data20230320/download.B04.tif\n",
            "/content/data20230320/download.B05.tif\n",
            "/content/data20230320/download.B06.tif\n",
            "/content/data20230320/download.B07.tif\n",
            "/content/data20230320/download.B8A.tif\n",
            "/content/data20230320/download.B08.tif\n",
            "/content/temp/B11.10.tif\n",
            "75.98777123144303 8.983152841195216e-05 0.0 32.41678500579388 0.0 -8.9831528411952e-05\n",
            "10 100\n",
            "/content/temp/B12.10.tif\n",
            "/content/temp/B02.10.tif\n",
            "/content/temp/B03.10.tif\n",
            "/content/temp/B04.10.tif\n",
            "/content/temp/B05.10.tif\n",
            "/content/temp/B06.10.tif\n",
            "/content/temp/B07.10.tif\n",
            "/content/temp/B8A.10.tif\n",
            "/content/temp/B08.10.tif\n",
            "0 1000 1000\n",
            "1000\n",
            "[100, 0, 110, 10] <class 'list'>\n",
            "/content/data20230320/download.B11.tif\n",
            "/content/data20230320/download.B12.tif\n",
            "/content/data20230320/download.B02.tif\n",
            "/content/data20230320/download.B03.tif\n",
            "/content/data20230320/download.B04.tif\n",
            "/content/data20230320/download.B05.tif\n",
            "/content/data20230320/download.B06.tif\n",
            "/content/data20230320/download.B07.tif\n",
            "/content/data20230320/download.B8A.tif\n",
            "/content/data20230320/download.B08.tif\n",
            "/content/temp/B11.11.tif\n",
            "75.98866954672715 8.983152841195216e-05 0.0 32.41678500579388 0.0 -8.9831528411952e-05\n",
            "10 110\n",
            "/content/temp/B12.11.tif\n",
            "/content/temp/B02.11.tif\n",
            "/content/temp/B03.11.tif\n",
            "/content/temp/B04.11.tif\n",
            "/content/temp/B05.11.tif\n",
            "/content/temp/B06.11.tif\n",
            "/content/temp/B07.11.tif\n",
            "/content/temp/B8A.11.tif\n",
            "/content/temp/B08.11.tif\n",
            "0 1100 1100\n",
            "1100\n",
            "[110, 0, 120, 10] <class 'list'>\n",
            "/content/data20230320/download.B11.tif\n",
            "/content/data20230320/download.B12.tif\n",
            "/content/data20230320/download.B02.tif\n",
            "/content/data20230320/download.B03.tif\n",
            "/content/data20230320/download.B04.tif\n",
            "/content/data20230320/download.B05.tif\n",
            "/content/data20230320/download.B06.tif\n",
            "/content/data20230320/download.B07.tif\n",
            "/content/data20230320/download.B8A.tif\n",
            "/content/data20230320/download.B08.tif\n",
            "/content/temp/B11.12.tif\n",
            "75.98956786201127 8.983152841195216e-05 0.0 32.41678500579388 0.0 -8.9831528411952e-05\n",
            "10 120\n",
            "/content/temp/B12.12.tif\n",
            "/content/temp/B02.12.tif\n",
            "/content/temp/B03.12.tif\n",
            "/content/temp/B04.12.tif\n",
            "/content/temp/B05.12.tif\n",
            "/content/temp/B06.12.tif\n",
            "/content/temp/B07.12.tif\n",
            "/content/temp/B8A.12.tif\n",
            "/content/temp/B08.12.tif\n",
            "0 1200 1200\n",
            "1200\n",
            "[120, 0, 130, 10] <class 'list'>\n",
            "/content/data20230320/download.B11.tif\n",
            "/content/data20230320/download.B12.tif\n",
            "/content/data20230320/download.B02.tif\n",
            "/content/data20230320/download.B03.tif\n",
            "/content/data20230320/download.B04.tif\n",
            "/content/data20230320/download.B05.tif\n",
            "/content/data20230320/download.B06.tif\n",
            "/content/data20230320/download.B07.tif\n",
            "/content/data20230320/download.B8A.tif\n",
            "/content/data20230320/download.B08.tif\n",
            "/content/temp/B11.13.tif\n",
            "75.99046617729539 8.983152841195216e-05 0.0 32.41678500579388 0.0 -8.9831528411952e-05\n",
            "10 130\n",
            "/content/temp/B12.13.tif\n",
            "/content/temp/B02.13.tif\n",
            "/content/temp/B03.13.tif\n",
            "/content/temp/B04.13.tif\n",
            "/content/temp/B05.13.tif\n",
            "/content/temp/B06.13.tif\n",
            "/content/temp/B07.13.tif\n",
            "/content/temp/B8A.13.tif\n",
            "/content/temp/B08.13.tif\n",
            "0 1300 1300\n",
            "1300\n",
            "[130, 0, 140, 10] <class 'list'>\n",
            "/content/data20230320/download.B11.tif\n",
            "/content/data20230320/download.B12.tif\n",
            "/content/data20230320/download.B02.tif\n",
            "/content/data20230320/download.B03.tif\n",
            "/content/data20230320/download.B04.tif\n",
            "/content/data20230320/download.B05.tif\n",
            "/content/data20230320/download.B06.tif\n",
            "/content/data20230320/download.B07.tif\n",
            "/content/data20230320/download.B8A.tif\n",
            "/content/data20230320/download.B08.tif\n",
            "/content/temp/B11.14.tif\n",
            "75.9913644925795 8.983152841195216e-05 0.0 32.41678500579388 0.0 -8.9831528411952e-05\n",
            "10 140\n",
            "/content/temp/B12.14.tif\n",
            "/content/temp/B02.14.tif\n",
            "/content/temp/B03.14.tif\n",
            "/content/temp/B04.14.tif\n",
            "/content/temp/B05.14.tif\n",
            "/content/temp/B06.14.tif\n",
            "/content/temp/B07.14.tif\n",
            "/content/temp/B8A.14.tif\n",
            "/content/temp/B08.14.tif\n",
            "0 1400 1400\n",
            "1400\n",
            "[140, 0, 150, 10] <class 'list'>\n",
            "/content/data20230320/download.B11.tif\n",
            "/content/data20230320/download.B12.tif\n",
            "/content/data20230320/download.B02.tif\n",
            "/content/data20230320/download.B03.tif\n",
            "/content/data20230320/download.B04.tif\n",
            "/content/data20230320/download.B05.tif\n",
            "/content/data20230320/download.B06.tif\n",
            "/content/data20230320/download.B07.tif\n",
            "/content/data20230320/download.B8A.tif\n",
            "/content/data20230320/download.B08.tif\n",
            "/content/temp/B11.15.tif\n",
            "75.99226280786363 8.983152841195216e-05 0.0 32.41678500579388 0.0 -8.9831528411952e-05\n",
            "10 150\n",
            "/content/temp/B12.15.tif\n",
            "/content/temp/B02.15.tif\n",
            "/content/temp/B03.15.tif\n",
            "/content/temp/B04.15.tif\n",
            "/content/temp/B05.15.tif\n",
            "/content/temp/B06.15.tif\n",
            "/content/temp/B07.15.tif\n",
            "/content/temp/B8A.15.tif\n",
            "/content/temp/B08.15.tif\n",
            "0 1500 1500\n",
            "1500\n",
            "[150, 0, 160, 10] <class 'list'>\n",
            "/content/data20230320/download.B11.tif\n",
            "/content/data20230320/download.B12.tif\n",
            "/content/data20230320/download.B02.tif\n",
            "/content/data20230320/download.B03.tif\n",
            "/content/data20230320/download.B04.tif\n",
            "/content/data20230320/download.B05.tif\n",
            "/content/data20230320/download.B06.tif\n",
            "/content/data20230320/download.B07.tif\n",
            "/content/data20230320/download.B8A.tif\n",
            "/content/data20230320/download.B08.tif\n",
            "/content/temp/B11.16.tif\n",
            "75.99316112314774 8.983152841195216e-05 0.0 32.41678500579388 0.0 -8.9831528411952e-05\n",
            "10 160\n",
            "/content/temp/B12.16.tif\n",
            "/content/temp/B02.16.tif\n",
            "/content/temp/B03.16.tif\n",
            "/content/temp/B04.16.tif\n",
            "/content/temp/B05.16.tif\n",
            "/content/temp/B06.16.tif\n",
            "/content/temp/B07.16.tif\n",
            "/content/temp/B8A.16.tif\n",
            "/content/temp/B08.16.tif\n",
            "0 1600 1600\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-62-cb8f9c8b03b6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;31m######################$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$<<< tensorflow model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m     \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexamples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m     \u001b[0;31m######################$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$<<< tensorflow model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict_step\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   2077\u001b[0m         \"\"\"\n\u001b[1;32m   2078\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_adapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_x_y_sample_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2079\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2080\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2081\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmake_predict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    559\u001b[0m             \u001b[0mlayout_map_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_subclass_model_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_layout_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mdoc_controls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdoc_in_current_and_subclasses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1130\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_dtype_object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m                 ):\n\u001b[0;32m-> 1132\u001b[0;31m                     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0mbound_signature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_keras_call_info_injected\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/saving/legacy/saved_model/utils.py\u001b[0m in \u001b[0;36mreturn_outputs_and_add_losses\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/saving/legacy/saved_model/utils.py\u001b[0m in \u001b[0;36mwrap_with_training_arg\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    188\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnew_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mnew_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m         return control_flow_util.smart_cond(\n\u001b[0m\u001b[1;32m    191\u001b[0m             \u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m             \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mreplace_training_and_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/utils/control_flow_util.py\u001b[0m in \u001b[0;36msmart_cond\u001b[0;34m(pred, true_fn, false_fn, name)\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcond\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrue_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfalse_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfalse_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m     return tf.__internal__.smart_cond.smart_cond(\n\u001b[0m\u001b[1;32m    109\u001b[0m         \u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrue_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfalse_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfalse_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/framework/smart_cond.py\u001b[0m in \u001b[0;36msmart_cond\u001b[0;34m(pred, true_fn, false_fn, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mtrue_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfalse_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     return control_flow_ops.cond(pred, true_fn=true_fn, false_fn=false_fn,\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/saving/legacy/saved_model/utils.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    191\u001b[0m             \u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m             \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mreplace_training_and_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m             \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mreplace_training_and_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m         )\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/saving/legacy/saved_model/utils.py\u001b[0m in \u001b[0;36mreplace_training_and_call\u001b[0;34m(training)\u001b[0m\n\u001b[1;32m    186\u001b[0m                 \u001b[0;34m\"training\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs_in_args\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m             )\n\u001b[0;32m--> 188\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnew_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mnew_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         return control_flow_util.smart_cond(\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    878\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    918\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 919\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    920\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mALLOW_DYNAMIC_VARIABLE_CREATION\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    921\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    132\u001b[0m       (concrete_function,\n\u001b[1;32m    133\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m--> 134\u001b[0;31m     return concrete_function._call_flat(\n\u001b[0m\u001b[1;32m    135\u001b[0m         filtered_flat_args, captured_inputs=concrete_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1743\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1745\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1746\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    376\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 378\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    379\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     53\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "ds = gdal.Open(path_list[0])\n",
        "box_list = get_slice_bboxes(ds.RasterYSize , ds.RasterXSize)\n",
        "\n",
        "count = 0\n",
        "\n",
        "for box in box_list:\n",
        "  print(box, type(box_list))\n",
        "  count = count + 1\n",
        "  #clipping of original image to box size\n",
        "  for k in path_list:\n",
        "    here_image = k\n",
        "    print(here_image)\n",
        "    vvv = here_image[-7:-4]\n",
        "    gdal.Translate(str(temp_directory) + str(vvv) + \".\" + str(count) + '.tif', here_image ,srcWin = box )\n",
        "  \n",
        "\n",
        "  #>> files are of their original sizes are kept in a folder with their respective extensions as bands b1, b2, b3 , b4 , b5 ....  and kept as to be listed as image list in a variable.\n",
        "  image_dir = temp_directory\n",
        "  prefix = \"\"\n",
        "  end = [\"B11\", \"B12\", \"B02\", \"B03\", \"B04\", \"B05\", \"B06\", \"B07\", \"B8A\", \"B08\"]\n",
        "  DayOY = \"_doy\\[0-9]+_aid0001\"\n",
        "  fileExt = r'.tif'\n",
        "  expression_b1 = prefix+end[0]\n",
        "  expression_b2 = prefix+end[1]\n",
        "  expression_b3 = prefix+end[2]\n",
        "  expression_b4 = prefix+end[3]\n",
        "  expression_b5 = prefix+end[4]\n",
        "  expression_b6 = prefix+end[5]\n",
        "  expression_b7 = prefix+end[6]\n",
        "  expression_b8 = prefix+end[7]\n",
        "  expression_b9 = prefix+end[8]\n",
        "  expression_b10 = prefix+end[9]\n",
        "\n",
        "  imgs_list_b1 = [f for f in os.listdir(image_dir) if f.__contains__(expression_b1)]\n",
        "\n",
        "  imgs_list_b1.sort(reverse=True)    \n",
        "\n",
        "\n",
        "  temp_path = os.path.join(image_dir, imgs_list_b1[0])\n",
        "  temp_path_list = [temp_path.replace(expression_b1, expression_b1),\n",
        "              temp_path.replace(expression_b1, expression_b2),\n",
        "              temp_path.replace(expression_b1, expression_b3),\n",
        "              temp_path.replace(expression_b1, expression_b4),\n",
        "              temp_path.replace(expression_b1, expression_b5),\n",
        "              temp_path.replace(expression_b1, expression_b6),\n",
        "              temp_path.replace(expression_b1, expression_b7),\n",
        "              temp_path.replace(expression_b1, expression_b8),\n",
        "              temp_path.replace(expression_b1, expression_b9),\n",
        "              temp_path.replace(expression_b1, expression_b10)]\n",
        "\n",
        "  lon , lat = [] , []  \n",
        "  v1 =[]\n",
        "\n",
        "  for i in temp_path_list:\n",
        "    pathout = i\n",
        "    print(pathout)\n",
        "    \n",
        "    if(temp_path_list.index(i)==0):\n",
        "      v1 = tif2array(pathout, 0)[0].reshape(-1,1)\n",
        "      # Open tif file\n",
        "      ds = gdal.Open(pathout)\n",
        "      # GDAL affine transform parameters, According to gdal documentation xoff/yoff are image left corner, a/e are pixel wight/height and b/d is rotation and is zero if image is north up. \n",
        "      xoff, a, b, yoff, d, e = ds.GetGeoTransform()\n",
        "      print(xoff, a, b, yoff, d, e)\n",
        "      def pixel2coord(x, y):\n",
        "        # \"\"Returns global coordinates from pixel x, y coords\"\"\n",
        "        xp = a * x + b * y + xoff\n",
        "        yp = d * x + e * y + yoff\n",
        "        return xp, yp\n",
        "\n",
        "      # get columns and rows of your image from gdalinfo\n",
        "      rows = ds.RasterYSize \n",
        "      colms = ds.RasterXSize \n",
        "      print(rows, colms)\n",
        "      for row in  range(0,rows):\n",
        "        for col in  range(0,colms): \n",
        "          lat.append(pixel2coord(col,row)[0])\n",
        "          lon.append(pixel2coord(col,row)[1])\n",
        "    else:\n",
        "      v1 = np.append(v1, tif2array(pathout, 0)[0].reshape(-1,1), axis = 1)\n",
        "  # agging latitude \"lat\" & longitde \"lon\" column at the end\n",
        "  v1 = np.column_stack((v1, np.column_stack((lat, lon))))\n",
        "\n",
        "\n",
        "  arr = v1\n",
        "\n",
        "  # convert array into dataframe\n",
        "  DF = pd.DataFrame(arr)\n",
        "  # DF.columns = d\n",
        "    # print(DF)\n",
        "  height =[]\n",
        "  print(len(height),  len(DF[0]), len(arr))\n",
        "\n",
        "  for values in range(0, len(DF[0])):\n",
        "    examples = {\n",
        "    \"b11\" : [np.array(DF[0][values])],\n",
        "    \"b12\" : [np.array(DF[1][values])],\n",
        "    \"b2\" : [np.array(DF[2][values])],\n",
        "    \"b3\" : [np.array(DF[3][values])],\n",
        "    \"b4\" : [np.array(DF[4][values])],\n",
        "    \"b5\" : [np.array(DF[5][values])],\n",
        "    \"b6\" : [np.array(DF[6][values])],\n",
        "    \"b7\" : [np.array(DF[7][values])],\n",
        "    \"b8a\" : [np.array(DF[8][values])],\n",
        "    \"b8\" : [np.array(DF[9][values])],\n",
        "    \"lat\" : [np.array(DF[10][values])],\n",
        "    \"lon\" : [np.array(DF[11][values])],\n",
        "    }\n",
        "    ######################$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$<<< tensorflow model\n",
        "    \n",
        "    a = np.array(model.predict_step(examples))\n",
        "    ######################$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$<<< tensorflow model\n",
        "\n",
        "    height.append(a[0][0])\n",
        "  # print(np.asarray(height))\n",
        "  height = np.column_stack((np.column_stack((lat, lon)), height))\n",
        "  print(len(height))\n",
        "  # saving the predicted heght data to panda dataframe\n",
        "  DHeight = pd.DataFrame(height)\n",
        "  # DF.columns = d\n",
        "  # DHeight\n",
        "  # save the dataframe as a csv file\n",
        "  save_dir = \"/content/height/\"\n",
        "  !mkdir -p {save_dir}\n",
        "  DHeight.to_csv(str(save_dir) + \"height_\" + str(count) + \".csv\")\n",
        "  #delete files in temp_directory after processing\n",
        "  !rm -r {temp_directory}/*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rFhHQuue7ESc"
      },
      "outputs": [],
      "source": [
        "tfdf.model_plotter.plot_model_in_colab(model, tree_idx=0)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "e-uTZc27fBVW",
        "IGvjOhfq25Hx",
        "EaCOuudi2UCJ"
      ],
      "provenance": [],
      "authorship_tag": "ABX9TyN6FZ2Wu47kWtNb/04pBlIZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}