{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/1kaiser/Snow-cover-area-estimation/blob/main/tiff2array.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yPdly86dtDqc",
        "outputId": "35f7aea2-0d25-44d2-db44-8bc6331e34ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "qKTN6C1btYsH"
      },
      "outputs": [],
      "source": [
        "!cp -r /content/gdrive/MyDrive/OUT/data/data20230320 /content/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GNadjcbGhnwN",
        "outputId": "fecfcbb1-8a2e-47d9-9212-8cc2210cc6d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['download.B11.tif']\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "image_dir = r'/content/data20230320/'\n",
        "\n",
        "#############################################################################>> files are of their original sizes are kept in a folder with their respective extensions as bands b1, b2, b3 , b4 , b5 ....  and kept as to be listed as image list in a variable.\n",
        "prefix = \"\"\n",
        "end = [\"B11\", \"B12\", \"B02\", \"B03\", \"B04\", \"B05\", \"B06\", \"B07\", \"B8A\", \"B08\"]\n",
        "DayOY = \"_doy\\[0-9]+_aid0001\"\n",
        "fileExt = r'.tif'\n",
        "expression_b1 = prefix+end[0]\n",
        "expression_b2 = prefix+end[1]\n",
        "expression_b3 = prefix+end[2]\n",
        "expression_b4 = prefix+end[3]\n",
        "expression_b5 = prefix+end[4]\n",
        "expression_b6 = prefix+end[5]\n",
        "expression_b7 = prefix+end[6]\n",
        "expression_b8 = prefix+end[7]\n",
        "expression_b9 = prefix+end[8]\n",
        "expression_b10 = prefix+end[9]\n",
        "\n",
        "imgs_list_b1 = [f for f in os.listdir(image_dir) if f.__contains__(expression_b1)]\n",
        "\n",
        "imgs_list_b1.sort(reverse=True)    \n",
        "print(imgs_list_b1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UTqVV7ENkmAy",
        "outputId": "39f21e98-ba82-49ab-ff6d-ab2fdd48fc49"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/data20230320/download.B11.tif',\n",
              " '/content/data20230320/download.B12.tif',\n",
              " '/content/data20230320/download.B02.tif',\n",
              " '/content/data20230320/download.B03.tif',\n",
              " '/content/data20230320/download.B04.tif',\n",
              " '/content/data20230320/download.B05.tif',\n",
              " '/content/data20230320/download.B06.tif',\n",
              " '/content/data20230320/download.B07.tif',\n",
              " '/content/data20230320/download.B8A.tif',\n",
              " '/content/data20230320/download.B08.tif']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "path = os.path.join(image_dir, imgs_list_b1[0])\n",
        "path_list = [path.replace(expression_b1, expression_b1),\n",
        "             path.replace(expression_b1, expression_b2),\n",
        "             path.replace(expression_b1, expression_b3),\n",
        "             path.replace(expression_b1, expression_b4),\n",
        "             path.replace(expression_b1, expression_b5),\n",
        "             path.replace(expression_b1, expression_b6),\n",
        "             path.replace(expression_b1, expression_b7),\n",
        "             path.replace(expression_b1, expression_b8),\n",
        "             path.replace(expression_b1, expression_b9),\n",
        "             path.replace(expression_b1, expression_b10)]\n",
        "\n",
        "path_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "vJMBYkichBM8",
        "outputId": "bfc6702d-6e5d-4614-a39f-f4229c02c234"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'B11'"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "path_list[0][-7:-4]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "KoOTRHJmrlKR"
      },
      "outputs": [],
      "source": [
        "#this function is for getting the four corners of all the square boxes possible out of the complete image size >>>\n",
        "def get_slice_bboxes( image_height: int, image_width: int, slice_height: int = 2000 , slice_width: int = 2000, overlap_height_ratio: float = 0.0, overlap_width_ratio: float = 0.0 ):\n",
        "  slice_bboxes = []\n",
        "  y_max = y_min = 0\n",
        "\n",
        "  if slice_height and slice_width:\n",
        "      y_overlap = int(overlap_height_ratio * slice_height)\n",
        "      x_overlap = int(overlap_width_ratio * slice_width)\n",
        "  else:\n",
        "      raise ValueError(\"Compute type is not auto and slice width and height are not provided.\")\n",
        "\n",
        "  while y_max < image_height:\n",
        "      x_min = x_max = 0\n",
        "      y_max = y_min + slice_height\n",
        "      while x_max < image_width:\n",
        "          x_max = x_min + slice_width\n",
        "          if y_max > image_height or x_max > image_width:\n",
        "              xmax = min(image_width, x_max)\n",
        "              ymax = min(image_height, y_max)\n",
        "              xmin = max(0, xmax - slice_width)\n",
        "              ymin = max(0, ymax - slice_height)\n",
        "              slice_bboxes.append([xmin, ymin, xmax, ymax])\n",
        "          else:\n",
        "              slice_bboxes.append([x_min, y_min, x_max, y_max])\n",
        "          x_min = x_max - x_overlap\n",
        "      y_min = y_max - y_overlap\n",
        "  return slice_bboxes\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##extraction of clips from original image"
      ],
      "metadata": {
        "id": "e-uTZc27fBVW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "pre requisite"
      ],
      "metadata": {
        "id": "biq2rXg3fF3k"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "zrFu1SXavti-"
      },
      "outputs": [],
      "source": [
        "#\n",
        "# functions for clipping a single raster to multiple rasters of various shapes\n",
        "from osgeo import gdal\n",
        "temp_directory = \"/content/temp/\"\n",
        "save_directory = \"/content/gdrive/MyDrive/OUT/data/data20230320inputs/\"\n",
        "!mkdir -p {temp_directory} {save_directory} \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###band 0"
      ],
      "metadata": {
        "id": "03V3tNvD1QM-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "here_image = path_list[0]\n",
        "print(here_image)\n",
        "\n",
        "vvv = here_image[-7:-4]\n",
        "ds = gdal.Open(here_image)\n",
        "box_list = get_slice_bboxes(ds.RasterYSize , ds.RasterXSize)\n",
        "\n",
        "count = 0\n",
        "\n",
        "for box in box_list:\n",
        "  print(box, type(box_list))\n",
        "  count = count + 1\n",
        "  gdal.Translate(str(temp_directory) + str(vvv) + \".\" + str(count) + '.tif', here_image ,srcWin = box )\n",
        "  !mv {temp_directory}/* {save_directory} "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b7wm7n3i1KHA",
        "outputId": "01c31d8d-cf45-4dc2-8b52-e6297ae73600"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/data20230320/download.B11.tif\n",
            "[0, 0, 2000, 2000] <class 'list'>\n",
            "[2000, 0, 4000, 2000] <class 'list'>\n",
            "[4000, 0, 6000, 2000] <class 'list'>\n",
            "[6000, 0, 8000, 2000] <class 'list'>\n",
            "[8000, 0, 10000, 2000] <class 'list'>\n",
            "[10000, 0, 12000, 2000] <class 'list'>\n",
            "[12000, 0, 14000, 2000] <class 'list'>\n",
            "[14000, 0, 16000, 2000] <class 'list'>\n",
            "[16000, 0, 18000, 2000] <class 'list'>\n",
            "[18000, 0, 20000, 2000] <class 'list'>\n",
            "[19006, 0, 21006, 2000] <class 'list'>\n",
            "[0, 2000, 2000, 4000] <class 'list'>\n",
            "[2000, 2000, 4000, 4000] <class 'list'>\n",
            "[4000, 2000, 6000, 4000] <class 'list'>\n",
            "[6000, 2000, 8000, 4000] <class 'list'>\n",
            "[8000, 2000, 10000, 4000] <class 'list'>\n",
            "[10000, 2000, 12000, 4000] <class 'list'>\n",
            "[12000, 2000, 14000, 4000] <class 'list'>\n",
            "[14000, 2000, 16000, 4000] <class 'list'>\n",
            "[16000, 2000, 18000, 4000] <class 'list'>\n",
            "[18000, 2000, 20000, 4000] <class 'list'>\n",
            "[19006, 2000, 21006, 4000] <class 'list'>\n",
            "[0, 4000, 2000, 6000] <class 'list'>\n",
            "[2000, 4000, 4000, 6000] <class 'list'>\n",
            "[4000, 4000, 6000, 6000] <class 'list'>\n",
            "[6000, 4000, 8000, 6000] <class 'list'>\n",
            "[8000, 4000, 10000, 6000] <class 'list'>\n",
            "[10000, 4000, 12000, 6000] <class 'list'>\n",
            "[12000, 4000, 14000, 6000] <class 'list'>\n",
            "[14000, 4000, 16000, 6000] <class 'list'>\n",
            "[16000, 4000, 18000, 6000] <class 'list'>\n",
            "[18000, 4000, 20000, 6000] <class 'list'>\n",
            "[19006, 4000, 21006, 6000] <class 'list'>\n",
            "[0, 6000, 2000, 8000] <class 'list'>\n",
            "[2000, 6000, 4000, 8000] <class 'list'>\n",
            "[4000, 6000, 6000, 8000] <class 'list'>\n",
            "[6000, 6000, 8000, 8000] <class 'list'>\n",
            "[8000, 6000, 10000, 8000] <class 'list'>\n",
            "[10000, 6000, 12000, 8000] <class 'list'>\n",
            "[12000, 6000, 14000, 8000] <class 'list'>\n",
            "[14000, 6000, 16000, 8000] <class 'list'>\n",
            "[16000, 6000, 18000, 8000] <class 'list'>\n",
            "[18000, 6000, 20000, 8000] <class 'list'>\n",
            "[19006, 6000, 21006, 8000] <class 'list'>\n",
            "[0, 8000, 2000, 10000] <class 'list'>\n",
            "[2000, 8000, 4000, 10000] <class 'list'>\n",
            "[4000, 8000, 6000, 10000] <class 'list'>\n",
            "[6000, 8000, 8000, 10000] <class 'list'>\n",
            "[8000, 8000, 10000, 10000] <class 'list'>\n",
            "[10000, 8000, 12000, 10000] <class 'list'>\n",
            "[12000, 8000, 14000, 10000] <class 'list'>\n",
            "[14000, 8000, 16000, 10000] <class 'list'>\n",
            "[16000, 8000, 18000, 10000] <class 'list'>\n",
            "[18000, 8000, 20000, 10000] <class 'list'>\n",
            "[19006, 8000, 21006, 10000] <class 'list'>\n",
            "[0, 8722, 2000, 10722] <class 'list'>\n",
            "[2000, 8722, 4000, 10722] <class 'list'>\n",
            "[4000, 8722, 6000, 10722] <class 'list'>\n",
            "[6000, 8722, 8000, 10722] <class 'list'>\n",
            "[8000, 8722, 10000, 10722] <class 'list'>\n",
            "[10000, 8722, 12000, 10722] <class 'list'>\n",
            "[12000, 8722, 14000, 10722] <class 'list'>\n",
            "[14000, 8722, 16000, 10722] <class 'list'>\n",
            "[16000, 8722, 18000, 10722] <class 'list'>\n",
            "[18000, 8722, 20000, 10722] <class 'list'>\n",
            "[19006, 8722, 21006, 10722] <class 'list'>\n",
            "mv: invalid option -- 'r'\n",
            "Try 'mv --help' for more information.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###band 1"
      ],
      "metadata": {
        "id": "VLrHv25t1Uol"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "here_image = path_list[1]\n",
        "print(here_image)\n",
        "\n",
        "vvv = here_image[-7:-4]\n",
        "ds = gdal.Open(here_image)\n",
        "box_list = get_slice_bboxes(ds.RasterYSize , ds.RasterXSize)\n",
        "\n",
        "count = 0\n",
        "\n",
        "for box in box_list:\n",
        "  print(box, type(box_list))\n",
        "  count = count + 1\n",
        "  gdal.Translate(str(temp_directory) + str(vvv) + \".\" + str(count) + '.tif', here_image , srcWin = box )\n",
        "  !mv {temp_directory}/* {save_directory} "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MgqW1G3H1Wvz",
        "outputId": "47159d69-076b-4cdd-d081-0002ab363a4b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/data20230320/download.B12.tif\n",
            "[0, 0, 2000, 2000] <class 'list'>\n",
            "[2000, 0, 4000, 2000] <class 'list'>\n",
            "[4000, 0, 6000, 2000] <class 'list'>\n",
            "[6000, 0, 8000, 2000] <class 'list'>\n",
            "[8000, 0, 10000, 2000] <class 'list'>\n",
            "[10000, 0, 12000, 2000] <class 'list'>\n",
            "[12000, 0, 14000, 2000] <class 'list'>\n",
            "[14000, 0, 16000, 2000] <class 'list'>\n",
            "[16000, 0, 18000, 2000] <class 'list'>\n",
            "[18000, 0, 20000, 2000] <class 'list'>\n",
            "[19006, 0, 21006, 2000] <class 'list'>\n",
            "[0, 2000, 2000, 4000] <class 'list'>\n",
            "[2000, 2000, 4000, 4000] <class 'list'>\n",
            "[4000, 2000, 6000, 4000] <class 'list'>\n",
            "[6000, 2000, 8000, 4000] <class 'list'>\n",
            "[8000, 2000, 10000, 4000] <class 'list'>\n",
            "[10000, 2000, 12000, 4000] <class 'list'>\n",
            "[12000, 2000, 14000, 4000] <class 'list'>\n",
            "[14000, 2000, 16000, 4000] <class 'list'>\n",
            "[16000, 2000, 18000, 4000] <class 'list'>\n",
            "[18000, 2000, 20000, 4000] <class 'list'>\n",
            "[19006, 2000, 21006, 4000] <class 'list'>\n",
            "[0, 4000, 2000, 6000] <class 'list'>\n",
            "[2000, 4000, 4000, 6000] <class 'list'>\n",
            "[4000, 4000, 6000, 6000] <class 'list'>\n",
            "[6000, 4000, 8000, 6000] <class 'list'>\n",
            "[8000, 4000, 10000, 6000] <class 'list'>\n",
            "[10000, 4000, 12000, 6000] <class 'list'>\n",
            "[12000, 4000, 14000, 6000] <class 'list'>\n",
            "[14000, 4000, 16000, 6000] <class 'list'>\n",
            "[16000, 4000, 18000, 6000] <class 'list'>\n",
            "[18000, 4000, 20000, 6000] <class 'list'>\n",
            "[19006, 4000, 21006, 6000] <class 'list'>\n",
            "[0, 6000, 2000, 8000] <class 'list'>\n",
            "[2000, 6000, 4000, 8000] <class 'list'>\n",
            "[4000, 6000, 6000, 8000] <class 'list'>\n",
            "[6000, 6000, 8000, 8000] <class 'list'>\n",
            "[8000, 6000, 10000, 8000] <class 'list'>\n",
            "[10000, 6000, 12000, 8000] <class 'list'>\n",
            "[12000, 6000, 14000, 8000] <class 'list'>\n",
            "[14000, 6000, 16000, 8000] <class 'list'>\n",
            "[16000, 6000, 18000, 8000] <class 'list'>\n",
            "[18000, 6000, 20000, 8000] <class 'list'>\n",
            "[19006, 6000, 21006, 8000] <class 'list'>\n",
            "[0, 8000, 2000, 10000] <class 'list'>\n",
            "[2000, 8000, 4000, 10000] <class 'list'>\n",
            "[4000, 8000, 6000, 10000] <class 'list'>\n",
            "[6000, 8000, 8000, 10000] <class 'list'>\n",
            "[8000, 8000, 10000, 10000] <class 'list'>\n",
            "[10000, 8000, 12000, 10000] <class 'list'>\n",
            "[12000, 8000, 14000, 10000] <class 'list'>\n",
            "[14000, 8000, 16000, 10000] <class 'list'>\n",
            "[16000, 8000, 18000, 10000] <class 'list'>\n",
            "[18000, 8000, 20000, 10000] <class 'list'>\n",
            "[19006, 8000, 21006, 10000] <class 'list'>\n",
            "[0, 8722, 2000, 10722] <class 'list'>\n",
            "[2000, 8722, 4000, 10722] <class 'list'>\n",
            "[4000, 8722, 6000, 10722] <class 'list'>\n",
            "[6000, 8722, 8000, 10722] <class 'list'>\n",
            "[8000, 8722, 10000, 10722] <class 'list'>\n",
            "[10000, 8722, 12000, 10722] <class 'list'>\n",
            "[12000, 8722, 14000, 10722] <class 'list'>\n",
            "[14000, 8722, 16000, 10722] <class 'list'>\n",
            "[16000, 8722, 18000, 10722] <class 'list'>\n",
            "[18000, 8722, 20000, 10722] <class 'list'>\n",
            "[19006, 8722, 21006, 10722] <class 'list'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###band 2"
      ],
      "metadata": {
        "id": "tR_V9IZM1WKc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "here_image = path_list[2]\n",
        "print(here_image)\n",
        "\n",
        "vvv = here_image[-7:-4]\n",
        "ds = gdal.Open(here_image)\n",
        "box_list = get_slice_bboxes(ds.RasterYSize , ds.RasterXSize)\n",
        "\n",
        "count = 0\n",
        "\n",
        "for box in box_list:\n",
        "  print(box, type(box_list))\n",
        "  count = count + 1\n",
        "  gdal.Translate(str(temp_directory) + str(vvv) + \".\" + str(count) + '.tif', here_image ,srcWin = box )\n",
        "  !mv {temp_directory}/* {save_directory} "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E_I-Ixzk1a3Z",
        "outputId": "09b0c5ea-cef5-461e-b322-3e5edb7bebec"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/data20230320/download.B02.tif\n",
            "[0, 0, 2000, 2000] <class 'list'>\n",
            "[2000, 0, 4000, 2000] <class 'list'>\n",
            "[4000, 0, 6000, 2000] <class 'list'>\n",
            "[6000, 0, 8000, 2000] <class 'list'>\n",
            "[8000, 0, 10000, 2000] <class 'list'>\n",
            "[10000, 0, 12000, 2000] <class 'list'>\n",
            "[12000, 0, 14000, 2000] <class 'list'>\n",
            "[14000, 0, 16000, 2000] <class 'list'>\n",
            "[16000, 0, 18000, 2000] <class 'list'>\n",
            "[18000, 0, 20000, 2000] <class 'list'>\n",
            "[19006, 0, 21006, 2000] <class 'list'>\n",
            "[0, 2000, 2000, 4000] <class 'list'>\n",
            "[2000, 2000, 4000, 4000] <class 'list'>\n",
            "[4000, 2000, 6000, 4000] <class 'list'>\n",
            "[6000, 2000, 8000, 4000] <class 'list'>\n",
            "[8000, 2000, 10000, 4000] <class 'list'>\n",
            "[10000, 2000, 12000, 4000] <class 'list'>\n",
            "[12000, 2000, 14000, 4000] <class 'list'>\n",
            "[14000, 2000, 16000, 4000] <class 'list'>\n",
            "[16000, 2000, 18000, 4000] <class 'list'>\n",
            "[18000, 2000, 20000, 4000] <class 'list'>\n",
            "[19006, 2000, 21006, 4000] <class 'list'>\n",
            "[0, 4000, 2000, 6000] <class 'list'>\n",
            "[2000, 4000, 4000, 6000] <class 'list'>\n",
            "[4000, 4000, 6000, 6000] <class 'list'>\n",
            "[6000, 4000, 8000, 6000] <class 'list'>\n",
            "[8000, 4000, 10000, 6000] <class 'list'>\n",
            "[10000, 4000, 12000, 6000] <class 'list'>\n",
            "[12000, 4000, 14000, 6000] <class 'list'>\n",
            "[14000, 4000, 16000, 6000] <class 'list'>\n",
            "[16000, 4000, 18000, 6000] <class 'list'>\n",
            "[18000, 4000, 20000, 6000] <class 'list'>\n",
            "[19006, 4000, 21006, 6000] <class 'list'>\n",
            "[0, 6000, 2000, 8000] <class 'list'>\n",
            "[2000, 6000, 4000, 8000] <class 'list'>\n",
            "[4000, 6000, 6000, 8000] <class 'list'>\n",
            "[6000, 6000, 8000, 8000] <class 'list'>\n",
            "[8000, 6000, 10000, 8000] <class 'list'>\n",
            "[10000, 6000, 12000, 8000] <class 'list'>\n",
            "[12000, 6000, 14000, 8000] <class 'list'>\n",
            "[14000, 6000, 16000, 8000] <class 'list'>\n",
            "[16000, 6000, 18000, 8000] <class 'list'>\n",
            "[18000, 6000, 20000, 8000] <class 'list'>\n",
            "[19006, 6000, 21006, 8000] <class 'list'>\n",
            "[0, 8000, 2000, 10000] <class 'list'>\n",
            "[2000, 8000, 4000, 10000] <class 'list'>\n",
            "[4000, 8000, 6000, 10000] <class 'list'>\n",
            "[6000, 8000, 8000, 10000] <class 'list'>\n",
            "[8000, 8000, 10000, 10000] <class 'list'>\n",
            "[10000, 8000, 12000, 10000] <class 'list'>\n",
            "[12000, 8000, 14000, 10000] <class 'list'>\n",
            "[14000, 8000, 16000, 10000] <class 'list'>\n",
            "[16000, 8000, 18000, 10000] <class 'list'>\n",
            "[18000, 8000, 20000, 10000] <class 'list'>\n",
            "[19006, 8000, 21006, 10000] <class 'list'>\n",
            "[0, 8722, 2000, 10722] <class 'list'>\n",
            "[2000, 8722, 4000, 10722] <class 'list'>\n",
            "[4000, 8722, 6000, 10722] <class 'list'>\n",
            "[6000, 8722, 8000, 10722] <class 'list'>\n",
            "[8000, 8722, 10000, 10722] <class 'list'>\n",
            "[10000, 8722, 12000, 10722] <class 'list'>\n",
            "[12000, 8722, 14000, 10722] <class 'list'>\n",
            "[14000, 8722, 16000, 10722] <class 'list'>\n",
            "[16000, 8722, 18000, 10722] <class 'list'>\n",
            "[18000, 8722, 20000, 10722] <class 'list'>\n",
            "[19006, 8722, 21006, 10722] <class 'list'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###band 3"
      ],
      "metadata": {
        "id": "DPR_VjGe2L3-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "here_image = path_list[3]\n",
        "print(here_image)\n",
        "\n",
        "vvv = here_image[-7:-4]\n",
        "ds = gdal.Open(here_image)\n",
        "box_list = get_slice_bboxes(ds.RasterYSize , ds.RasterXSize)\n",
        "\n",
        "count = 0\n",
        "\n",
        "for box in box_list:\n",
        "  print(box, type(box_list))\n",
        "  count = count + 1\n",
        "  gdal.Translate(str(temp_directory) + str(vvv) + \".\" + str(count) + '.tif', here_image ,srcWin = box )\n",
        "  !mv {temp_directory}/* {save_directory} "
      ],
      "metadata": {
        "id": "jqeno17U2LTL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###band 4"
      ],
      "metadata": {
        "id": "9oaEGMPM2SJ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "here_image = path_list[4]\n",
        "print(here_image)\n",
        "\n",
        "vvv = here_image[-7:-4]\n",
        "ds = gdal.Open(here_image)\n",
        "box_list = get_slice_bboxes(ds.RasterYSize , ds.RasterXSize)\n",
        "\n",
        "count = 0\n",
        "\n",
        "for box in box_list:\n",
        "  print(box, type(box_list))\n",
        "  count = count + 1\n",
        "  gdal.Translate(str(temp_directory) + str(vvv) + \".\" + str(count) + '.tif', here_image ,srcWin = box )\n",
        "  !mv {temp_directory}/* {save_directory} "
      ],
      "metadata": {
        "id": "u9EO93G72Tk5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###band 5"
      ],
      "metadata": {
        "id": "NkrfYdV42VSZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "here_image = path_list[5]\n",
        "print(here_image)\n",
        "\n",
        "vvv = here_image[-7:-4]\n",
        "ds = gdal.Open(here_image)\n",
        "box_list = get_slice_bboxes(ds.RasterYSize , ds.RasterXSize)\n",
        "\n",
        "count = 0\n",
        "\n",
        "for box in box_list:\n",
        "  print(box, type(box_list))\n",
        "  count = count + 1\n",
        "  gdal.Translate(str(temp_directory) + str(vvv) + \".\" + str(count) + '.tif', here_image ,srcWin = box )\n",
        "  !mv {temp_directory}/* {save_directory} "
      ],
      "metadata": {
        "id": "-pazktaj2Wp1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###band 6"
      ],
      "metadata": {
        "id": "_e40XDPN2gEX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "here_image = path_list[6]\n",
        "print(here_image)\n",
        "\n",
        "vvv = here_image[-7:-4]\n",
        "ds = gdal.Open(here_image)\n",
        "box_list = get_slice_bboxes(ds.RasterYSize , ds.RasterXSize)\n",
        "\n",
        "count = 0\n",
        "\n",
        "for box in box_list:\n",
        "  print(box, type(box_list))\n",
        "  count = count + 1\n",
        "  gdal.Translate(str(temp_directory) + str(vvv) + \".\" + str(count) + '.tif', here_image ,srcWin = box )\n",
        "  !mv {temp_directory}/* {save_directory} "
      ],
      "metadata": {
        "id": "n2I0dHcK2frI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###band 7"
      ],
      "metadata": {
        "id": "0QkYs09O2kZV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "here_image = path_list[7]\n",
        "print(here_image)\n",
        "\n",
        "vvv = here_image[-7:-4]\n",
        "ds = gdal.Open(here_image)\n",
        "box_list = get_slice_bboxes(ds.RasterYSize , ds.RasterXSize)\n",
        "\n",
        "count = 0\n",
        "\n",
        "for box in box_list:\n",
        "  print(box, type(box_list))\n",
        "  count = count + 1\n",
        "  gdal.Translate(str(temp_directory) + str(vvv) + \".\" + str(count) + '.tif', here_image ,srcWin = box )\n",
        "  !mv {temp_directory}/* {save_directory} "
      ],
      "metadata": {
        "id": "NZD5h3u02leQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###band 8"
      ],
      "metadata": {
        "id": "ff8eG_Ja2nJn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "here_image = path_list[8]\n",
        "print(here_image)\n",
        "\n",
        "vvv = here_image[-7:-4]\n",
        "ds = gdal.Open(here_image)\n",
        "box_list = get_slice_bboxes(ds.RasterYSize , ds.RasterXSize)\n",
        "\n",
        "count = 0\n",
        "\n",
        "for box in box_list:\n",
        "  print(box, type(box_list))\n",
        "  count = count + 1\n",
        "  gdal.Translate(str(temp_directory) + str(vvv) + \".\" + str(count) + '.tif', here_image ,srcWin = box )\n",
        "  !mv {temp_directory}/* {save_directory} "
      ],
      "metadata": {
        "id": "iSONd7M62oTU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###band 9"
      ],
      "metadata": {
        "id": "YX3UVG702p6Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "here_image = path_list[9]\n",
        "print(here_image)\n",
        "\n",
        "vvv = here_image[-7:-4]\n",
        "ds = gdal.Open(here_image)\n",
        "box_list = get_slice_bboxes(ds.RasterYSize , ds.RasterXSize)\n",
        "\n",
        "count = 0\n",
        "\n",
        "for box in box_list:\n",
        "  print(box, type(box_list))\n",
        "  count = count + 1\n",
        "  gdal.Translate(str(temp_directory) + str(vvv) + \".\" + str(count) + '.tif', here_image ,srcWin = box )\n",
        "  !mv {temp_directory}/* {save_directory} "
      ],
      "metadata": {
        "id": "wGOb_VRX2rRO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## tensorflow band data extraction from model created from google sheets "
      ],
      "metadata": {
        "id": "IGvjOhfq25Hx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "3lUV96TiqTux"
      },
      "outputs": [],
      "source": [
        "#\n",
        "#$$$$$$$$$$$$$$$$$%%%%%%%%%%%%%% tif2raster\n",
        "#\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import os.path\n",
        "import re\n",
        "\n",
        "from osgeo import gdal\n",
        "from osgeo import gdal_array\n",
        "from osgeo import osr\n",
        "\n",
        "def get_gain_band(input_file):\n",
        "    \"\"\"get GAIN_BAND from meta file (*.tif.txt)\"\"\"\n",
        "     # define file name of *.tif.txt\n",
        "    ifile_txt = re.sub(r'.tif', '.tif.txt', input_file)\n",
        "    ld = open(ifile_txt)\n",
        "    lines = ld.readlines()\n",
        "    ld.close()\n",
        "    \n",
        "    gain_band = []\n",
        "    for line in lines:\n",
        "        if line.find(\"GAIN_BAND\") >= 0:\n",
        "             gain_band.append(float((re.split(' ', line)[1]).strip()))\n",
        "    return gain_band\n",
        "\n",
        "def tif2array(input_file, calc_gain=True):\n",
        "    \"\"\"\n",
        "    read GeoTiff and convert to numpy.ndarray.\n",
        "    Inputs:\n",
        "        input_file (str) : the name of input GeoTiff file.\n",
        "        calc_gain (bool) : wheter calc GAIN to DN  or not (defaul:True).\n",
        "    return:\n",
        "        image(np.array) : image for each bands\n",
        "        dataset : for gdal's data drive.\n",
        "    \"\"\"\n",
        "    dataset = gdal.Open(input_file, gdal.GA_ReadOnly)\n",
        "    # Allocate our array using the first band's datatype\n",
        "    image_datatype = dataset.GetRasterBand(1).DataType\n",
        "    image = np.zeros((dataset.RasterYSize, dataset.RasterXSize, dataset.RasterCount),\n",
        "                     dtype=float)\n",
        "    \n",
        "    if calc_gain == True:\n",
        "        # get gain\n",
        "        gain = get_gain_band(input_file)\n",
        "    \n",
        "    # Loop over all bands in dataset\n",
        "    for b in range(dataset.RasterCount):\n",
        "        # Remember, GDAL index is on 1, but Python is on 0 -- so we add 1 for our GDAL calls\n",
        "        band = dataset.GetRasterBand(b + 1)\n",
        "        # Read in the band's data into the third dimension of our array\n",
        "        if calc_gain == True:\n",
        "            # calc gain value for each bands\n",
        "            image[:, :, b] = band.ReadAsArray() * gain[b]\n",
        "        else:\n",
        "            image[:, :, b] = band.ReadAsArray()\n",
        "    return image, dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CbZUMzKd_PO-"
      },
      "source": [
        "setting up for tif2array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "4p1zGV-z-jWr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1576f010-3d77-4cf5-b4bc-d39107272cb4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['B11.9.tif', 'B11.8.tif', 'B11.7.tif', 'B11.6.tif', 'B11.5.tif', 'B11.4.tif', 'B11.3.tif', 'B11.22.tif', 'B11.21.tif', 'B11.20.tif', 'B11.2.tif', 'B11.19.tif', 'B11.18.tif', 'B11.17.tif', 'B11.16.tif', 'B11.15.tif', 'B11.14.tif', 'B11.13.tif', 'B11.12.tif', 'B11.11.tif', 'B11.10.tif', 'B11.1.tif']\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "image_dir = r'/content/gdrive/MyDrive/OUT/data/data20230320inputs/'\n",
        "\n",
        "#############################################################################>> files are of their original sizes are kept in a folder with their respective extensions as bands b1, b2, b3 , b4 , b5 ....  and kept as to be listed as image list in a variable.\n",
        "prefix = \"\"\n",
        "end = [\"B11\", \"B12\", \"B02\", \"B03\", \"B04\", \"B05\", \"B06\", \"B07\", \"B8A\", \"B08\"]\n",
        "DayOY = \"_doy\\[0-9]+_aid0001\"\n",
        "fileExt = r'.tif'\n",
        "expression_b1 = prefix+end[0]\n",
        "expression_b2 = prefix+end[1]\n",
        "expression_b3 = prefix+end[2]\n",
        "expression_b4 = prefix+end[3]\n",
        "expression_b5 = prefix+end[4]\n",
        "expression_b6 = prefix+end[5]\n",
        "expression_b7 = prefix+end[6]\n",
        "expression_b8 = prefix+end[7]\n",
        "expression_b9 = prefix+end[8]\n",
        "expression_b10 = prefix+end[9]\n",
        "\n",
        "imgs_list_b1 = [f for f in os.listdir(image_dir) if f.__contains__(expression_b1)]\n",
        "\n",
        "imgs_list_b1.sort(reverse=True)    \n",
        "print(imgs_list_b1)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#extraction of band values from clips to DATAFRAME for to be processing inside the model\n",
        "\n",
        "from osgeo import gdal\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "######################$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$<<< tensorflow model\n",
        "#Copy and execute the following code in a new Google Colab notebook launch to run the model.\n",
        "!python -m pip install tensorflow tensorflow_decision_forests -U -qq\n",
        "\n",
        "# Transfer the model from Google Drive to Colab\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\")\n",
        "!cp \"/content/gdrive/My Drive/simple_ml_for_sheets/Ice height from bands\" ydf_model\n",
        "  \n",
        "# Prepare and load the model with TensorFlow\n",
        "import tensorflow as tf\n",
        "import tensorflow_decision_forests as tfdf\n",
        "\n",
        "tfdf.keras.yggdrasil_model_to_keras_model(\"ydf_model\", \"tfdf_model\")\n",
        "model = tf.keras.models.load_model(\"tfdf_model\")\n",
        "######################$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$<<< tensorflow model\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qmznxvEmjXoF",
        "outputId": "89663359-bce3-412c-9c99-a14da958d773"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m588.3/588.3 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.5/16.5 MB\u001b[0m \u001b[31m69.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDrive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:TensorFlow Decision Forests 1.2.0 is compatible with the following TensorFlow Versions: ['2.11.0']. However, TensorFlow 2.11.1 was detected. This can cause issues with the TF API and symbols in the custom C++ ops. See the TF and TF-DF compatibility table at https://github.com/tensorflow/decision-forests/blob/main/documentation/known_issues.md#compatibility-table.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.9/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
            "Instructions for updating:\n",
            "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
            "WARNING:tensorflow:AutoGraph could not transform <function simple_ml_inference_op_with_handle at 0x7fba235b4ca0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: could not get source code\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: AutoGraph could not transform <function simple_ml_inference_op_with_handle at 0x7fba235b4ca0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: could not get source code\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as call_get_leaves, _update_step_xla while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = os.path.join(image_dir, imgs_list_b1[6])\n",
        "path_list = [path.replace(expression_b1, expression_b1),\n",
        "            path.replace(expression_b1, expression_b2),\n",
        "            path.replace(expression_b1, expression_b3),\n",
        "            path.replace(expression_b1, expression_b4),\n",
        "            path.replace(expression_b1, expression_b5),\n",
        "            path.replace(expression_b1, expression_b6),\n",
        "            path.replace(expression_b1, expression_b7),\n",
        "            path.replace(expression_b1, expression_b8),\n",
        "            path.replace(expression_b1, expression_b9),\n",
        "            path.replace(expression_b1, expression_b10)]\n",
        "path_list[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "2512KHSgEqrJ",
        "outputId": "b63ae6a3-cfb0-48a4-9809-c22d6caba4f8"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/gdrive/MyDrive/OUT/data/data20230320inputs/B11.3.tif'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r {path_list[0]} /content"
      ],
      "metadata": {
        "id": "4dcId8Lbl9E9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.path.getsize(path_list[10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "id": "mPkE6j0QjBPH",
        "outputId": "ae79b3ff-35f2-4144-fcf7-674f716fafc0"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-d2994d79f6fa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetsize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for image_no in range(0, len(imgs_list_b1)):\n",
        "  path = os.path.join(image_dir, imgs_list_b1[image_no])\n",
        "  path_list = [path.replace(expression_b1, expression_b1),\n",
        "              path.replace(expression_b1, expression_b2),\n",
        "              path.replace(expression_b1, expression_b3),\n",
        "              path.replace(expression_b1, expression_b4),\n",
        "              path.replace(expression_b1, expression_b5),\n",
        "              path.replace(expression_b1, expression_b6),\n",
        "              path.replace(expression_b1, expression_b7),\n",
        "              path.replace(expression_b1, expression_b8),\n",
        "              path.replace(expression_b1, expression_b9),\n",
        "              path.replace(expression_b1, expression_b10)]\n",
        "\n",
        "  print(path_list)\n",
        "  for i in path_list:\n",
        "    os.path.getsize(i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 376
        },
        "id": "Zj0a0QuMgMcA",
        "outputId": "c3cf157d-c7e8-48d3-c6be-729bd68b6b21"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['/content/gdrive/MyDrive/OUT/data/data20230320inputs/B11.9.tif', '/content/gdrive/MyDrive/OUT/data/data20230320inputs/B12.9.tif', '/content/gdrive/MyDrive/OUT/data/data20230320inputs/B02.9.tif', '/content/gdrive/MyDrive/OUT/data/data20230320inputs/B03.9.tif', '/content/gdrive/MyDrive/OUT/data/data20230320inputs/B04.9.tif', '/content/gdrive/MyDrive/OUT/data/data20230320inputs/B05.9.tif', '/content/gdrive/MyDrive/OUT/data/data20230320inputs/B06.9.tif', '/content/gdrive/MyDrive/OUT/data/data20230320inputs/B07.9.tif', '/content/gdrive/MyDrive/OUT/data/data20230320inputs/B8A.9.tif', '/content/gdrive/MyDrive/OUT/data/data20230320inputs/B08.9.tif']\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-f78057e684eb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpath_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetsize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/lib/python3.9/genericpath.py\u001b[0m in \u001b[0;36mgetsize\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgetsize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;34m\"\"\"Return the size of a file, reported by os.stat().\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mst_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/gdrive/MyDrive/OUT/data/data20230320inputs/B03.9.tif'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gdal.Open(path_list[0])"
      ],
      "metadata": {
        "id": "PyRqQ37pLHS7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "v1 = tif2array(\"/content/gdrive/MyDrive/OUT/data/data20230320inputs/B03.6.tif\", 0)[0].reshape(-1,1)"
      ],
      "metadata": {
        "id": "24qshMGyLEgb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "YwKtSRMqxW1P",
        "outputId": "ae7c81b7-d039-4434-fcf9-99b30b3800cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/OUT/data/data20230320inputs/B11.9.tif\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-e83f69fbe362>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m       \u001b[0mv1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtif2array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpathout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m       \u001b[0;31m# Open tif file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m       \u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgdal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpathout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-23-8ed430747d57>\u001b[0m in \u001b[0;36mtif2array\u001b[0;34m(input_file, calc_gain)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgdal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgdal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGA_ReadOnly\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;31m# Allocate our array using the first band's datatype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0mimage_datatype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGetRasterBand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataType\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m     image = np.zeros((dataset.RasterYSize, dataset.RasterXSize, dataset.RasterCount),\n\u001b[1;32m     42\u001b[0m                      dtype=float)\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'GetRasterBand'"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "for image_no in range(0, len(imgs_list_b1)):\n",
        "  path = os.path.join(image_dir, imgs_list_b1[image_no])\n",
        "  path_list = [path.replace(expression_b1, expression_b1),\n",
        "              path.replace(expression_b1, expression_b2),\n",
        "              path.replace(expression_b1, expression_b3),\n",
        "              path.replace(expression_b1, expression_b4),\n",
        "              path.replace(expression_b1, expression_b5),\n",
        "              path.replace(expression_b1, expression_b6),\n",
        "              path.replace(expression_b1, expression_b7),\n",
        "              path.replace(expression_b1, expression_b8),\n",
        "              path.replace(expression_b1, expression_b9),\n",
        "              path.replace(expression_b1, expression_b10)]\n",
        "\n",
        "  lon , lat = [] , []  \n",
        "  v1 =[]\n",
        "\n",
        "  for i in path_list:\n",
        "    pathout = i\n",
        "    print(pathout)\n",
        "    \n",
        "    if(path_list.index(i)==0):\n",
        "      v1 = tif2array(pathout, 0)[0].reshape(-1,1)\n",
        "      # Open tif file\n",
        "      ds = gdal.Open(pathout)\n",
        "      # GDAL affine transform parameters, According to gdal documentation xoff/yoff are image left corner, a/e are pixel wight/height and b/d is rotation and is zero if image is north up. \n",
        "      xoff, a, b, yoff, d, e = ds.GetGeoTransform()\n",
        "      print(xoff, a, b, yoff, d, e)\n",
        "      def pixel2coord(x, y):\n",
        "        # \"\"Returns global coordinates from pixel x, y coords\"\"\n",
        "        xp = a * x + b * y + xoff\n",
        "        yp = d * x + e * y + yoff\n",
        "        return xp, yp\n",
        "\n",
        "      # get columns and rows of your image from gdalinfo\n",
        "      rows = ds.RasterYSize \n",
        "      colms = ds.RasterXSize \n",
        "      for row in  range(0,rows):\n",
        "        for col in  range(0,colms): \n",
        "          lat.append(pixel2coord(col,row)[0])\n",
        "          lon.append(pixel2coord(col,row)[1])\n",
        "    else:\n",
        "      v1 = np.append(v1, tif2array(pathout, 0)[0].reshape(-1,1), axis = 1)\n",
        "  # agging latitude \"lat\" & longitde \"lon\" column at the end\n",
        "  v1 = np.column_stack((v1, np.column_stack((lat, lon))))\n",
        "\n",
        "\n",
        "  arr = v1\n",
        "  # convert array into dataframe\n",
        "  DF = pd.DataFrame(arr)\n",
        "  # DF.columns = d\n",
        "    # print(DF)\n",
        "  height =[]\n",
        "  for values in range(0, len(DF[0])):\n",
        "    examples = {\n",
        "    \"b11\" : [np.array(DF[0][values])],\n",
        "    \"b12\" : [np.array(DF[1][values])],\n",
        "    \"b2\" : [np.array(DF[2][values])],\n",
        "    \"b3\" : [np.array(DF[3][values])],\n",
        "    \"b4\" : [np.array(DF[4][values])],\n",
        "    \"b5\" : [np.array(DF[5][values])],\n",
        "    \"b6\" : [np.array(DF[6][values])],\n",
        "    \"b7\" : [np.array(DF[7][values])],\n",
        "    \"b8a\" : [np.array(DF[8][values])],\n",
        "    \"b8\" : [np.array(DF[9][values])],\n",
        "    \"lat\" : [np.array(DF[10][values])],\n",
        "    \"lon\" : [np.array(DF[11][values])],\n",
        "    }\n",
        "######################$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$<<< tensorflow model\n",
        "\n",
        "    a = np.array(model.predict_step(examples))\n",
        "######################$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$<<< tensorflow model\n",
        "\n",
        "    height.append(a[0][0])\n",
        "  print(np.asarray(height))\n",
        "  print(height)\n",
        "  height = np.column_stack((np.column_stack((lat, lon)), height))\n",
        "  # saving the predicted heght data to panda dataframe\n",
        "  DHeight = pd.DataFrame(height)\n",
        "  # DF.columns = d\n",
        "  DHeight\n",
        "  # save the dataframe as a csv file\n",
        "  DHeight.to_csv(\"height_\" + str(image_no) + \".csv\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# final processing"
      ],
      "metadata": {
        "id": "C_iDHZ121eNv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**💽 google drive connection**"
      ],
      "metadata": {
        "id": "EaCOuudi2UCJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35f7aea2-0d25-44d2-db44-8bc6331e34ad",
        "id": "VNIB-zUW2PjJ"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MbDz761i2PjK"
      },
      "outputs": [],
      "source": [
        "!cp -r /content/gdrive/MyDrive/OUT/data/data20230320 /content/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61b95456-9021-427c-957e-f66a567adb79",
        "id": "_5VIz4CW2PjK"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['download.B11.tif']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/data20230320/download.B11.tif',\n",
              " '/content/data20230320/download.B12.tif',\n",
              " '/content/data20230320/download.B02.tif',\n",
              " '/content/data20230320/download.B03.tif',\n",
              " '/content/data20230320/download.B04.tif',\n",
              " '/content/data20230320/download.B05.tif',\n",
              " '/content/data20230320/download.B06.tif',\n",
              " '/content/data20230320/download.B07.tif',\n",
              " '/content/data20230320/download.B8A.tif',\n",
              " '/content/data20230320/download.B08.tif']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "import os\n",
        "image_dir = r'/content/data20230320/'\n",
        "\n",
        "#############################################################################>> files are of their original sizes are kept in a folder with their respective extensions as bands b1, b2, b3 , b4 , b5 ....  and kept as to be listed as image list in a variable.\n",
        "prefix = \"\"\n",
        "end = [\"B11\", \"B12\", \"B02\", \"B03\", \"B04\", \"B05\", \"B06\", \"B07\", \"B8A\", \"B08\"]\n",
        "DayOY = \"_doy\\[0-9]+_aid0001\"\n",
        "fileExt = r'.tif'\n",
        "expression_b1 = prefix+end[0]\n",
        "expression_b2 = prefix+end[1]\n",
        "expression_b3 = prefix+end[2]\n",
        "expression_b4 = prefix+end[3]\n",
        "expression_b5 = prefix+end[4]\n",
        "expression_b6 = prefix+end[5]\n",
        "expression_b7 = prefix+end[6]\n",
        "expression_b8 = prefix+end[7]\n",
        "expression_b9 = prefix+end[8]\n",
        "expression_b10 = prefix+end[9]\n",
        "\n",
        "imgs_list_b1 = [f for f in os.listdir(image_dir) if f.__contains__(expression_b1)]\n",
        "\n",
        "imgs_list_b1.sort(reverse=True)    \n",
        "print(imgs_list_b1)\n",
        "\n",
        "path = os.path.join(image_dir, imgs_list_b1[0])\n",
        "path_list = [path.replace(expression_b1, expression_b1),\n",
        "             path.replace(expression_b1, expression_b2),\n",
        "             path.replace(expression_b1, expression_b3),\n",
        "             path.replace(expression_b1, expression_b4),\n",
        "             path.replace(expression_b1, expression_b5),\n",
        "             path.replace(expression_b1, expression_b6),\n",
        "             path.replace(expression_b1, expression_b7),\n",
        "             path.replace(expression_b1, expression_b8),\n",
        "             path.replace(expression_b1, expression_b9),\n",
        "             path.replace(expression_b1, expression_b10)]\n",
        "\n",
        "path_list"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**🌟loading prequisites**"
      ],
      "metadata": {
        "id": "sSLCc1yf2dm5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "cellView": "form",
        "id": "z2IIkkAf1hqx"
      },
      "outputs": [],
      "source": [
        "#@title **pre** requisite funcrions **1️⃣tif2array, 2️⃣get_slice_bboxes**\n",
        "#\n",
        "#$$$$$$$$$$$$$$$$$%%%%%%%%%%%%%% tif2raster\n",
        "#\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import os.path\n",
        "import re\n",
        "\n",
        "from osgeo import gdal\n",
        "from osgeo import gdal_array\n",
        "from osgeo import osr\n",
        "\n",
        "def get_gain_band(input_file):\n",
        "    \"\"\"get GAIN_BAND from meta file (*.tif.txt)\"\"\"\n",
        "     # define file name of *.tif.txt\n",
        "    ifile_txt = re.sub(r'.tif', '.tif.txt', input_file)\n",
        "    ld = open(ifile_txt)\n",
        "    lines = ld.readlines()\n",
        "    ld.close()\n",
        "    \n",
        "    gain_band = []\n",
        "    for line in lines:\n",
        "        if line.find(\"GAIN_BAND\") >= 0:\n",
        "             gain_band.append(float((re.split(' ', line)[1]).strip()))\n",
        "    return gain_band\n",
        "\n",
        "def tif2array(input_file, calc_gain=True):\n",
        "    \"\"\"\n",
        "    read GeoTiff and convert to numpy.ndarray.\n",
        "    Inputs:\n",
        "        input_file (str) : the name of input GeoTiff file.\n",
        "        calc_gain (bool) : wheter calc GAIN to DN  or not (defaul:True).\n",
        "    return:\n",
        "        image(np.array) : image for each bands\n",
        "        dataset : for gdal's data drive.\n",
        "    \"\"\"\n",
        "    dataset = gdal.Open(input_file, gdal.GA_ReadOnly)\n",
        "    # Allocate our array using the first band's datatype\n",
        "    image_datatype = dataset.GetRasterBand(1).DataType\n",
        "    image = np.zeros((dataset.RasterYSize, dataset.RasterXSize, dataset.RasterCount),\n",
        "                     dtype=float)\n",
        "    \n",
        "    if calc_gain == True:\n",
        "        # get gain\n",
        "        gain = get_gain_band(input_file)\n",
        "    \n",
        "    # Loop over all bands in dataset\n",
        "    for b in range(dataset.RasterCount):\n",
        "        # Remember, GDAL index is on 1, but Python is on 0 -- so we add 1 for our GDAL calls\n",
        "        band = dataset.GetRasterBand(b + 1)\n",
        "        # Read in the band's data into the third dimension of our array\n",
        "        if calc_gain == True:\n",
        "            # calc gain value for each bands\n",
        "            image[:, :, b] = band.ReadAsArray() * gain[b]\n",
        "        else:\n",
        "            image[:, :, b] = band.ReadAsArray()\n",
        "    return image, dataset\n",
        "\n",
        "#this function is for getting the four corners of all the square boxes possible out of the complete image size >>>\n",
        "def get_slice_bboxes( image_height: int, image_width: int, slice_height: int = 500 , slice_width: int = 500, overlap_height_ratio: float = 0.0, overlap_width_ratio: float = 0.0 ):\n",
        "  slice_bboxes = []\n",
        "  y_max = y_min = 0\n",
        "\n",
        "  if slice_height and slice_width:\n",
        "      y_overlap = int(overlap_height_ratio * slice_height)\n",
        "      x_overlap = int(overlap_width_ratio * slice_width)\n",
        "  else:\n",
        "      raise ValueError(\"Compute type is not auto and slice width and height are not provided.\")\n",
        "\n",
        "  while y_max < image_height:\n",
        "      x_min = x_max = 0\n",
        "      y_max = y_min + slice_height\n",
        "      while x_max < image_width:\n",
        "          x_max = x_min + slice_width\n",
        "          if y_max > image_height or x_max > image_width:\n",
        "              xmax = min(image_width, x_max)\n",
        "              ymax = min(image_height, y_max)\n",
        "              xmin = max(0, xmax - slice_width)\n",
        "              ymin = max(0, ymax - slice_height)\n",
        "              slice_bboxes.append([xmin, ymin, xmax, ymax])\n",
        "          else:\n",
        "              slice_bboxes.append([x_min, y_min, x_max, y_max])\n",
        "          x_min = x_max - x_overlap\n",
        "      y_min = y_max - y_overlap\n",
        "  return slice_bboxes\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title **🎛️** Tensorflow  **tensorflow_decision_forests**  library loading\n",
        "#extraction of band values from clips to DATAFRAME for to be processing inside the model\n",
        "\n",
        "from osgeo import gdal\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "######################$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$<<< tensorflow model\n",
        "#Copy and execute the following code in a new Google Colab notebook launch to run the model.\n",
        "!python -m pip install tensorflow tensorflow_decision_forests -U -qq\n",
        "\n",
        "# Transfer the model from Google Drive to Colab\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\")\n",
        "!cp \"/content/gdrive/My Drive/simple_ml_for_sheets/Ice height from bands\" ydf_model\n",
        "  \n",
        "# Prepare and load the model with TensorFlow\n",
        "import tensorflow as tf\n",
        "import tensorflow_decision_forests as tfdf\n",
        "\n",
        "tfdf.keras.yggdrasil_model_to_keras_model(\"ydf_model\", \"tfdf_model\")\n",
        "model = tf.keras.models.load_model(\"tfdf_model\")\n",
        "######################$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$<<< tensorflow model\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "xAPZQNU91hqx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "cellView": "form",
        "id": "0E_rUixg1hqx"
      },
      "outputs": [],
      "source": [
        "#@title **📐Setting Up** Directories\n",
        "#\n",
        "# functions for clipping a single raster to multiple rasters of various shapes\n",
        "from osgeo import gdal\n",
        "temp_directory = \"/content/temp/\"\n",
        "save_directory = \"/content/gdrive/MyDrive/OUT/data/data20230320inputs/\"\n",
        "!mkdir -p {temp_directory} {save_directory} \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**📜 calculation from ML model**"
      ],
      "metadata": {
        "id": "LDjd-xzZ2qb6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "ds = gdal.Open(path_list[0])\n",
        "box_list = get_slice_bboxes(ds.RasterYSize , ds.RasterXSize)\n",
        "\n",
        "count = 0\n",
        "\n",
        "for box in box_list:\n",
        "  print(box, type(box_list))\n",
        "  count = count + 1\n",
        "  #clipping of original image to box size\n",
        "  for k in path_list:\n",
        "    here_image = k\n",
        "    print(here_image)\n",
        "    vvv = here_image[-7:-4]\n",
        "    gdal.Translate(str(temp_directory) + str(vvv) + \".\" + str(count) + '.tif', here_image ,srcWin = box )\n",
        "  \n",
        "\n",
        "  #>> files are of their original sizes are kept in a folder with their respective extensions as bands b1, b2, b3 , b4 , b5 ....  and kept as to be listed as image list in a variable.\n",
        "  image_dir = temp_directory\n",
        "  prefix = \"\"\n",
        "  end = [\"B11\", \"B12\", \"B02\", \"B03\", \"B04\", \"B05\", \"B06\", \"B07\", \"B8A\", \"B08\"]\n",
        "  DayOY = \"_doy\\[0-9]+_aid0001\"\n",
        "  fileExt = r'.tif'\n",
        "  expression_b1 = prefix+end[0]\n",
        "  expression_b2 = prefix+end[1]\n",
        "  expression_b3 = prefix+end[2]\n",
        "  expression_b4 = prefix+end[3]\n",
        "  expression_b5 = prefix+end[4]\n",
        "  expression_b6 = prefix+end[5]\n",
        "  expression_b7 = prefix+end[6]\n",
        "  expression_b8 = prefix+end[7]\n",
        "  expression_b9 = prefix+end[8]\n",
        "  expression_b10 = prefix+end[9]\n",
        "\n",
        "  imgs_list_b1 = [f for f in os.listdir(image_dir) if f.__contains__(expression_b1)]\n",
        "\n",
        "  imgs_list_b1.sort(reverse=True)    \n",
        "\n",
        "\n",
        "  temp_path = os.path.join(image_dir, imgs_list_b1[0])\n",
        "  temp_path_list = [temp_path.replace(expression_b1, expression_b1),\n",
        "              temp_path.replace(expression_b1, expression_b2),\n",
        "              temp_path.replace(expression_b1, expression_b3),\n",
        "              temp_path.replace(expression_b1, expression_b4),\n",
        "              temp_path.replace(expression_b1, expression_b5),\n",
        "              temp_path.replace(expression_b1, expression_b6),\n",
        "              temp_path.replace(expression_b1, expression_b7),\n",
        "              temp_path.replace(expression_b1, expression_b8),\n",
        "              temp_path.replace(expression_b1, expression_b9),\n",
        "              temp_path.replace(expression_b1, expression_b10)]\n",
        "\n",
        "  lon , lat = [] , []  \n",
        "  v1 =[]\n",
        "\n",
        "  for i in temp_path_list:\n",
        "    pathout = i\n",
        "    print(pathout)\n",
        "    \n",
        "    if(temp_path_list.index(i)==0):\n",
        "      v1 = tif2array(pathout, 0)[0].reshape(-1,1)\n",
        "      # Open tif file\n",
        "      ds = gdal.Open(pathout)\n",
        "      # GDAL affine transform parameters, According to gdal documentation xoff/yoff are image left corner, a/e are pixel wight/height and b/d is rotation and is zero if image is north up. \n",
        "      xoff, a, b, yoff, d, e = ds.GetGeoTransform()\n",
        "      print(xoff, a, b, yoff, d, e)\n",
        "      def pixel2coord(x, y):\n",
        "        # \"\"Returns global coordinates from pixel x, y coords\"\"\n",
        "        xp = a * x + b * y + xoff\n",
        "        yp = d * x + e * y + yoff\n",
        "        return xp, yp\n",
        "\n",
        "      # get columns and rows of your image from gdalinfo\n",
        "      rows = ds.RasterYSize \n",
        "      colms = ds.RasterXSize \n",
        "      for row in  range(0,rows):\n",
        "        for col in  range(0,colms): \n",
        "          lat.append(pixel2coord(col,row)[0])\n",
        "          lon.append(pixel2coord(col,row)[1])\n",
        "    else:\n",
        "      v1 = np.append(v1, tif2array(pathout, 0)[0].reshape(-1,1), axis = 1)\n",
        "  # agging latitude \"lat\" & longitde \"lon\" column at the end\n",
        "  v1 = np.column_stack((v1, np.column_stack((lat, lon))))\n",
        "\n",
        "\n",
        "  arr = v1\n",
        "  # convert array into dataframe\n",
        "  DF = pd.DataFrame(arr)\n",
        "  # DF.columns = d\n",
        "    # print(DF)\n",
        "  height =[]\n",
        "  for values in range(0, len(DF[0])):\n",
        "    examples = {\n",
        "    \"b11\" : [np.array(DF[0][values])],\n",
        "    \"b12\" : [np.array(DF[1][values])],\n",
        "    \"b2\" : [np.array(DF[2][values])],\n",
        "    \"b3\" : [np.array(DF[3][values])],\n",
        "    \"b4\" : [np.array(DF[4][values])],\n",
        "    \"b5\" : [np.array(DF[5][values])],\n",
        "    \"b6\" : [np.array(DF[6][values])],\n",
        "    \"b7\" : [np.array(DF[7][values])],\n",
        "    \"b8a\" : [np.array(DF[8][values])],\n",
        "    \"b8\" : [np.array(DF[9][values])],\n",
        "    \"lat\" : [np.array(DF[10][values])],\n",
        "    \"lon\" : [np.array(DF[11][values])],\n",
        "    }\n",
        "######################$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$<<< tensorflow model\n",
        "\n",
        "    a = np.array(model.predict_step(examples))\n",
        "######################$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$<<< tensorflow model\n",
        "\n",
        "    height.append(a[0][0])\n",
        "  print(np.asarray(height))\n",
        "  print(height)\n",
        "  height = np.column_stack((np.column_stack((lat, lon)), height))\n",
        "  # saving the predicted heght data to panda dataframe\n",
        "  DHeight = pd.DataFrame(height)\n",
        "  # DF.columns = d\n",
        "  DHeight\n",
        "  # save the dataframe as a csv file\n",
        "  DHeight.to_csv(\"height_\" + str(count) + \".csv\")\n",
        "  #delete files in temp_directory after processing\n",
        "  !rm -r {temp_directory}/*"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e962374f-b7c0-4fee-9e16-2864bb2976b1",
        "id": "C3H2KLBD1hqx"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0, 0, 500, 500] <class 'list'>\n",
            "/content/data20230320/download.B11.tif\n",
            "/content/data20230320/download.B12.tif\n",
            "/content/data20230320/download.B02.tif\n",
            "/content/data20230320/download.B03.tif\n",
            "/content/data20230320/download.B04.tif\n",
            "/content/data20230320/download.B05.tif\n",
            "/content/data20230320/download.B06.tif\n",
            "/content/data20230320/download.B07.tif\n",
            "/content/data20230320/download.B8A.tif\n",
            "/content/data20230320/download.B08.tif\n",
            "/content/temp/B11.1.tif\n",
            "75.97968639388596 8.983152841195216e-05 0.0 32.41678500579388 0.0 -8.9831528411952e-05\n",
            "/content/temp/B12.1.tif\n",
            "/content/temp/B02.1.tif\n",
            "/content/temp/B03.1.tif\n",
            "/content/temp/B04.1.tif\n",
            "/content/temp/B05.1.tif\n",
            "/content/temp/B06.1.tif\n",
            "/content/temp/B07.1.tif\n",
            "/content/temp/B8A.1.tif\n",
            "/content/temp/B08.1.tif\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tfdf.model_plotter.plot_model_in_colab(model, tree_idx=0)\n"
      ],
      "metadata": {
        "id": "rFhHQuue7ESc"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP+fV0X7x3qm8u9x3c45g6z",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}